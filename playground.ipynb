{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb363a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 17:27:43.410 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/justinkim/Documents/GitHub/360capital/.venv/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Charger et redimensionner le logo\n",
    "logo = Image.open(\"360_capital_vc_logo.jpeg\")\n",
    "logo = logo.resize((64, 64))\n",
    "\n",
    "\n",
    "# Configuration de la page\n",
    "st.set_page_config(\n",
    "    page_title=\"Nettoyage Données Crunchbase\",\n",
    "    page_icon=logo,\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def get_domain(url):\n",
    "    \"\"\"Extrait le domaine d'une URL et le formate\"\"\"\n",
    "    if pd.isna(url):\n",
    "        return None\n",
    "    try:\n",
    "        domain = urlparse(url).netloc\n",
    "        domain = re.sub(r'^www\\d*\\.', '', domain).split(':')[0]\n",
    "        return domain.lower()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clean_crunchbase_data(df):\n",
    "    \"\"\"\n",
    "    Nettoie les données de levées de fonds Crunchbase\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame avec les colonnes Crunchbase\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame nettoyé avec les colonnes formatées\n",
    "    \"\"\"\n",
    "    # Créer une copie pour ne pas modifier l'original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Filtrer les types de financement non désirés\n",
    "    funding_types_to_remove = [\n",
    "        'Corporate Round',\n",
    "        'Grant',\n",
    "        'Post-IPO Debt',\n",
    "        'Equity Crowdfunding',\n",
    "        'Debt Financing',\n",
    "        'Convertible Note',\n",
    "        'Series C'\n",
    "    ]\n",
    "    \n",
    "    initial_count = len(df_clean)\n",
    "    df_clean = df_clean[~df_clean['Funding Type'].isin(funding_types_to_remove)]\n",
    "    filtered_count = initial_count - len(df_clean)\n",
    "    \n",
    "    # 2. Convertir les montants USD en devise originale\n",
    "    mask_usd = df_clean['Money Raised Currency'] == 'USD'\n",
    "    mask_has_both = pd.notna(df_clean['Money Raised']) & pd.notna(df_clean['Money Raised (in USD)'])\n",
    "    \n",
    "    # Calculer le taux de change moyen pour les lignes non-USD\n",
    "    rates = df_clean[~mask_usd & mask_has_both].apply(\n",
    "        lambda row: row['Money Raised (in USD)'] / row['Money Raised'] \n",
    "        if row['Money Raised'] != 0 else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "    avg_rate = rates.median() if len(rates) > 0 else 1.0\n",
    "    \n",
    "    # Appliquer la conversion inverse pour les montants USD\n",
    "    df_clean.loc[mask_usd & pd.isna(df_clean['Money Raised']) & pd.notna(df_clean['Money Raised (in USD)']), 'Money Raised'] = \\\n",
    "        df_clean.loc[mask_usd & pd.isna(df_clean['Money Raised']) & pd.notna(df_clean['Money Raised (in USD)']), 'Money Raised (in USD)'] / avg_rate\n",
    "    \n",
    "    # 3. Appliquer le formatage des URLs avec get_domain\n",
    "    df_clean['Website_formatted'] = df_clean['Organization Website'].apply(get_domain)\n",
    "    \n",
    "    # 3bis Changer le format des montants \n",
    "\n",
    "    df_clean['Money Raised'] = df_clean['Money Raised'].apply(lambda x: f\"€M {x:,.0f}\" if pd.notna(x) else x)  \n",
    "\n",
    "    # 4. Créer le nouveau DataFrame avec les colonnes demandées\n",
    "    df_final = pd.DataFrame({\n",
    "        'Company Name': df_clean['Organization Name'],\n",
    "        'Website 2': '',\n",
    "        'Website': df_clean['Website_formatted'],\n",
    "        'Description': df_clean['Organization Description'],\n",
    "        'Secteur': df_clean['Organization Industries'],\n",
    "        'Date annonce levée': '',\n",
    "        'Montant': df_clean['Money Raised'],\n",
    "        'Investisseurs': df_clean['Investor Names']\n",
    "    })\n",
    "    \n",
    "    # Réinitialiser l'index\n",
    "    df_final = df_final.reset_index(drop=True)\n",
    "    \n",
    "    return df_final, filtered_count\n",
    "\n",
    "\n",
    "# Interface principale\n",
    "st.title(\"Nettoyage de Données Crunchbase\")\n",
    "st.markdown(\"---\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### Instructions\n",
    "        1. Téléchargez votre fichier CSV exporté depuis Crunchbase.\n",
    "        2. Cliquez sur \"Nettoyer les données\" pour lancer le processus de nettoyage.\n",
    "        3. Téléchargez les données nettoyées au format CSV ou Excel.\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Upload du fichier\n",
    "uploaded_file = st.file_uploader(\n",
    "    \"Chargez votre fichier CSV Crunchbase\",\n",
    "    type=['csv'],\n",
    "    help=\"Le fichier doit contenir les colonnes standard de Crunchbase\"\n",
    ")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        # Lecture du fichier\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        \n",
    "        st.success(f\"✅ Fichier chargé : {len(df)} lignes détectées\")\n",
    "        \n",
    "        # Afficher un aperçu des données originales\n",
    "        with st.expander(\"Aperçu des données originales\"):\n",
    "            st.dataframe(df.head(10), use_container_width=True)\n",
    "        \n",
    "        # Bouton de nettoyage\n",
    "        if st.button(\"Nettoyer les données\", type=\"primary\", use_container_width=True):\n",
    "            with st.spinner(\"Nettoyage en cours...\"):\n",
    "                # Nettoyage\n",
    "                df_clean, filtered_count = clean_crunchbase_data(df)\n",
    "                \n",
    "                # Stocker dans session state\n",
    "                st.session_state['df_clean'] = df_clean\n",
    "                st.session_state['filtered_count'] = filtered_count\n",
    "        \n",
    "        # Afficher les résultats si disponibles\n",
    "        if 'df_clean' in st.session_state:\n",
    "            df_clean = st.session_state['df_clean']\n",
    "            filtered_count = st.session_state['filtered_count']\n",
    "            \n",
    "            st.markdown(\"---\")\n",
    "            st.success(\"Nettoyage terminé !\")\n",
    "            \n",
    "            # Statistiques\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"Lignes initiales\", len(df))\n",
    "            with col2:\n",
    "                st.metric(\"Lignes filtrées\", filtered_count)\n",
    "            with col3:\n",
    "                st.metric(\"Lignes finales\", len(df_clean))\n",
    "            \n",
    "            # Aperçu des données nettoyées\n",
    "            st.subheader(\"Données nettoyées\")\n",
    "            st.dataframe(df_clean, use_container_width=True)\n",
    "            \n",
    "            # Boutons de téléchargement\n",
    "            st.markdown(\"---\")\n",
    "            st.subheader(\"Télécharger les résultats\")\n",
    "            \n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                # CSV\n",
    "                csv = df_clean.to_csv(index=False).encode('utf-8')\n",
    "                st.download_button(\n",
    "                    label=\"Télécharger en CSV\",\n",
    "                    data=csv,\n",
    "                    file_name=\"crunchbase_cleaned.csv\",\n",
    "                    mime=\"text/csv\",\n",
    "                    use_container_width=True\n",
    "                )\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ Erreur lors du traitement du fichier : {str(e)}\")\n",
    "        st.info(\"Vérifiez que votre fichier contient bien toutes les colonnes requises.\")\n",
    "\n",
    "else:\n",
    "    st.info(\"Charger un fichier CSV\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <div style='text-align: center; color: gray;'>\n",
    "    Outil de nettoyage de données Crunchbase 360 Capital \n",
    "    </div>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "14250b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'olleh'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom(str : str):\n",
    "    n = len(str)\n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(str[i])\n",
    "        print(str[i])\n",
    "    l.reverse()\n",
    "    return((''.join(l)).strip())\n",
    "\n",
    "custom('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de153688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aezaezaaoala\n"
     ]
    }
   ],
   "source": [
    "# check palyndrome\n",
    "\n",
    "def palyiin(str):\n",
    "    if str[::-1] == str:\n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "\n",
    "str = 'alaoaazeazea'\n",
    "print(str[::-1])\n",
    "\n",
    "\n",
    "def longest_palindrome(s):\n",
    "    \"\"\"\n",
    "    Plus long substring palindrome.\n",
    "    Input: s = \"babad\"\n",
    "    Output: \"bab\" ou \"aba\"\n",
    "    \"\"\"\n",
    "    def expand_around_center(left, right):\n",
    "        while left >= 0 and right < len(s) and s[left] == s[right]:\n",
    "            left -= 1\n",
    "            right += 1\n",
    "        return right - left - 1\n",
    "    \n",
    "    if not s:\n",
    "        return \"\"\n",
    "    \n",
    "    start, end = 0, 0\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        # Palindrome impair (centre = 1 char)\n",
    "        len1 = expand_around_center(i, i)\n",
    "        # Palindrome pair (centre = 2 chars)\n",
    "        len2 = expand_around_center(i, i + 1)\n",
    "        \n",
    "        max_len = max(len1, len2)\n",
    "        \n",
    "        if max_len > end - start:\n",
    "            start = i - (max_len - 1) // 2\n",
    "            end = i + max_len // 2\n",
    "    \n",
    "    return s[start:end + 1]\n",
    "\n",
    "# Test\n",
    "print(longest_palindrome(\"babad\"))  # \"bab\" ou \"aba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19aa56be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 3})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "l = [1,1,1]\n",
    "\n",
    "print(Counter(l))\n",
    "\n",
    "# Pour un dataframe\n",
    "\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29978ad",
   "metadata": {},
   "source": [
    "Find indices of two numbers that add up to a specific target in an array.\n",
    "\n",
    "First we create a dictionary to store numbers and their indices as you iterate through the array. For each number, check if its complement (target minus the number) exists in the dictionary. If it does, return their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "adf65f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2]]\n"
     ]
    }
   ],
   "source": [
    "def sum(a, target):\n",
    "    test = a[0]\n",
    "    index = []\n",
    "    for i, value in enumerate(a):\n",
    "        if test + value == target:\n",
    "            index.append([a.index(test), i])\n",
    "        else :\n",
    "            test = value\n",
    "    return(index)\n",
    "\n",
    "print(sum([2, 7, 3, 15], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271a7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5]\n"
     ]
    }
   ],
   "source": [
    "# faire la sum de deux array numpy \n",
    "import numpy as np\n",
    "arr1 = np.array([1, 2])\n",
    "arr2 = np.array([4, 5])\n",
    "result = np.add(arr1, arr2)\n",
    "\n",
    "# extract diag \n",
    "import numpy as np\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(np.diagonal(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b32215",
   "metadata": {},
   "source": [
    "Create a Class to Represent a Person with Basic Attributes.\n",
    "\n",
    "__init__(self, name, age) initializes the Person object with a name and age.\n",
    "birthday(self) increases the person's age by 1.\n",
    "__str__(self) provides a human-readable string representation of the Person object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1448707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : Alice and Age : 12\n",
      "Name : Alice and Age : 13\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, age, name):\n",
    "        self.age = age\n",
    "        self.name = name\n",
    "    \n",
    "    def birthday(self):\n",
    "        self.age += 1\n",
    "\n",
    "    def str(self):\n",
    "        return(f\"Name : {self.name} and Age : {self.age}\")\n",
    "    \n",
    "perso = Person(12, \"Alice\")\n",
    "print(perso.str())\n",
    "perso.birthday()\n",
    "print(perso.str())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c487b9e2",
   "metadata": {},
   "source": [
    "Implement a sliding window to find the maximum sum of a subarray of a given size k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9788107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def subarray(arr, k):\n",
    "    max = 0\n",
    "    for i in range(len(arr)):\n",
    "        if max < sum(arr[i:i+k]):\n",
    "            max = sum(arr[i:i+k])\n",
    "\n",
    "    return(max)\n",
    "\n",
    "print(subarray([2, 1, 5, 1, 3, 2], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb99cb4",
   "metadata": {},
   "source": [
    " Calculate the confidence interval for a given dataset (assume normal distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55a5417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in ./.venv/lib/python3.9/site-packages (from scipy) (1.26.3)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "057a680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.614096175650322, 4.385903824349678)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    mean, std = np.mean(data), np.std(data, ddof=1)\n",
    "    z = norm.ppf((1 + confidence) / 2)\n",
    "    margin_of_error = z * (std / np.sqrt(len(data)))\n",
    "    return mean - margin_of_error, mean + margin_of_error\n",
    "\n",
    "\n",
    "print(confidence_interval([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d141d9f6",
   "metadata": {},
   "source": [
    " Implement the Chi-squared test for independence on a contingency table.\n",
    "\n",
    "Calculate the Chi-squared statistic by comparing observed and expected frequencies in the contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a021a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_squared_test(contingency_table):\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    return chi2, p\n",
    "\n",
    "\n",
    "table = [[10, 20], [20, 40]]\n",
    "print(chi_squared_test(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c900c",
   "metadata": {},
   "source": [
    "Write a function to handle missing data using multiple imputation.\n",
    "\n",
    "we use Simple Imputer to replace missing values with the mean or another strategy. Below is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5495a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.6.1 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38ae409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [1. 3.]\n",
      " [7. 6.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "def impute_missing_data(data):\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    return imputer.fit_transform(data)\n",
    "\n",
    "data = np.array([[1, 2], [np.nan, 3], [7, 6]])\n",
    "print(impute_missing_data(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee7ee8",
   "metadata": {},
   "source": [
    " Group a dataset by a column and calculate the rolling average for another column.\n",
    "\n",
    "Use pandas.groupby and rolling to calculate rolling averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a293d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Group  Value  Score\n",
      "0     A     10    1.5\n",
      "1     A     20    2.5\n",
      "2     B     30    3.5\n",
      "3     B     40    4.5\n",
      "4     C     50    5.5\n",
      "  Group  Score\n",
      "0     A    1.0\n",
      "1     B    1.0\n",
      "2     C    0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Group': ['A', 'A', 'B', 'B', 'C'],\n",
    "    'Value': [10, 20, 30, 40, 50],\n",
    "    'Score': [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "result = df.groupby('Group').agg({\n",
    "    'Score': lambda x: x.max() - x.min().min() # la colonne doit exister \n",
    "}).reset_index() # à toujours rajouter\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca3a161c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Value</th>\n",
       "      <th>Averages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group  Value  Averages\n",
       "0     A     10      10.0\n",
       "1     A     20      15.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1485680b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Value</th>\n",
       "      <th>Averages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>30</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>40</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group  Value  Averages\n",
       "0     A     10      10.0\n",
       "1     A     20      15.0\n",
       "2     B     30      30.0\n",
       "3     B     40      35.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Averages'] = df.groupby('Group')['Value'].rolling(window=2, min_periods=1).mean().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ddc45",
   "metadata": {},
   "source": [
    "Create a pivot table from raw transactional data.\n",
    "\n",
    "Use pandas.pivot_table to summarize data into a pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c011db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type         X     Y\n",
      "Category            \n",
      "A         10.0  20.0\n",
      "B         30.0   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_pivot_table(df, index, columns, values, aggfunc):\n",
    "    return pd.pivot_table(df, index=index, columns=columns, values=values, aggfunc=aggfunc)\n",
    "\n",
    "data = {'Category': ['A', 'A', 'B'], 'Type': ['X', 'Y', 'X'], 'Value': [10, 20, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "pivot_table = create_pivot_table(df, index='Category', columns='Type', values='Value', aggfunc='sum')\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60bd4c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First_name Last_name  Age      City\n",
      "0       Liam     Smith   42  New York\n",
      "1       Emma     Brown   52     Paris\n",
      "2       Noah     Davis   36    Berlin\n",
      "3     Olivia    Wilson   21    Madrid\n",
      "4        Ava    Taylor   23      Rome\n",
      "  First_name Last_name  Age      City Qualification\n",
      "0       Liam     Smith   42  New York           MBA\n",
      "1       Emma     Brown   52     Paris           PhD\n",
      "2       Noah     Davis   36    Berlin           LLB\n",
      "3     Olivia    Wilson   21    Madrid        B.Tech\n",
      "4        Ava    Taylor   23      Rome            MD\n",
      "  First_name Last_name  Age      City Qualification\n",
      "0      Lucas     Smith   42  New York           MBA\n",
      "1       Emma     Brown   52     Paris           PhD\n",
      "2     Nathan     Davis   36    Berlin           LLB\n",
      "3      Olive    Wilson   21    Madrid        B.Tech\n",
      "4        Ava    Taylor   23      Rome            MD\n",
      "  First_name Last_name  Age      City Qualification\n",
      "0      Lukas     Smith   42  New York           MBA\n",
      "1       Emma     Brown   52     Paris           PhD\n",
      "2    Nicolas     Davis   36    Berlin           LLB\n",
      "3     Sophia    Wilson   21    Madrid        B.Tech\n",
      "4        Ava    Taylor   23      Rome            MD\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = { 'First_name': ['Liam', 'Emma', 'Noah', 'Olivia', 'Ava'],\n",
    "         'Last_name': ['Smith', 'Brown', 'Davis', 'Wilson', 'Taylor'],\n",
    "         'Age': [42, 52, 36, 21, 23],\n",
    "         'City': ['New York', 'Paris', 'Berlin', 'Madrid', 'Rome'] }\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "new_vals = {\"Liam\": \"MBA\", \"Emma\": \"PhD\", \"Noah\": \"LLB\", \"Olivia\": \"B.Tech\", \"Ava\": \"MD\"}\n",
    "df[\"Qualification\"] = df[\"First_name\"].map(new_vals)\n",
    "print(df)\n",
    "\n",
    "new_vals = {\"Liam\": \"Lucas\", \"Noah\": \"Nathan\", \"Olivia\": \"Olive\"}\n",
    "df_replaced = df.replace({\"First_name\": new_vals})\n",
    "print(df_replaced)\n",
    "\n",
    "new_vals = {0: \"Lukas\", 2: \"Nicolas\", 3: \"Sophia\"}\n",
    "df[\"First_name\"].update(pd.Series(new_vals))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30576342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name            Team  Number Position   Age Height  Weight  \\\n",
      "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
      "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
      "2   John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
      "3    R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
      "4  Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
      "\n",
      "             College     Salary  \n",
      "0              Texas  7730337.0  \n",
      "1          Marquette  6796117.0  \n",
      "2  Boston University        NaN  \n",
      "3      Georgia State  1148640.0  \n",
      "4                NaN  5000000.0  \n",
      "Index(['Name', 'Team', 'Number', 'Position', 'Age', 'Height', 'Weight',\n",
      "       'College', 'Salary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zip at 0x16a122f00>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# making dataframe\n",
    "df = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\")\n",
    "\n",
    "# it was print the first 5-rows\n",
    "print(df.head())\n",
    "\n",
    "# reshape the dataframe using stack() method\n",
    "df_stacked = df.stack()\n",
    "\n",
    "print(df_stacked[0].keys())\n",
    "df_stacked[0].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5794ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Name\n",
      "1 Team\n",
      "2 Number\n",
      "3 Position\n",
      "4 Age\n",
      "5 Height\n",
      "6 Weight\n",
      "7 College\n",
      "8 Salary\n",
      "            Name            Team Number Position   Age Height Weight  \\\n",
      "0  Avery Bradley  Boston Celtics    0.0       PG  25.0    6-2  180.0   \n",
      "1    Jae Crowder  Boston Celtics   99.0       SF  25.0    6-6  235.0   \n",
      "2   John Holland  Boston Celtics   30.0       SG  27.0    6-5  205.0   \n",
      "3    R.J. Hunter  Boston Celtics   28.0       SG  22.0    6-5  185.0   \n",
      "4  Jonas Jerebko  Boston Celtics    8.0       PF  29.0   6-10  231.0   \n",
      "5   Amir Johnson  Boston Celtics   90.0       PF  29.0    6-9  240.0   \n",
      "6  Jordan Mickey  Boston Celtics   55.0       PF  21.0    6-8  235.0   \n",
      "7   Kelly Olynyk  Boston Celtics   41.0        C  25.0    7-0  238.0   \n",
      "8   Terry Rozier  Boston Celtics   12.0       PG  22.0    6-2  190.0   \n",
      "9   Marcus Smart  Boston Celtics   36.0       PG  22.0    6-4  220.0   \n",
      "\n",
      "             College      Salary  \n",
      "0              Texas   7730337.0  \n",
      "1          Marquette   6796117.0  \n",
      "2  Boston University         NaN  \n",
      "3      Georgia State   1148640.0  \n",
      "4                NaN   5000000.0  \n",
      "5                NaN  12000000.0  \n",
      "6                LSU   1170960.0  \n",
      "7            Gonzaga   2165160.0  \n",
      "8         Louisville   1824360.0  \n",
      "9     Oklahoma State   3431040.0  \n"
     ]
    }
   ],
   "source": [
    "for key, element in enumerate(df):\n",
    "    print(key, element)\n",
    "# unstack() method\n",
    "df_unstacked = df_stacked.unstack()\n",
    "print(df_unstacked.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b2416da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>7730337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Shelvin Mack</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-3</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Butler</td>\n",
       "      <td>2433333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Raul Neto</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>25.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6-1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "0    Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "3      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "4    Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "453   Shelvin Mack       Utah Jazz     8.0       PG  26.0    6-3   203.0   \n",
       "454      Raul Neto       Utah Jazz    25.0       PG  24.0    6-1   179.0   \n",
       "455   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "456    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College     Salary  \n",
       "0                Texas  7730337.0  \n",
       "1            Marquette  6796117.0  \n",
       "2    Boston University        NaN  \n",
       "3        Georgia State  1148640.0  \n",
       "4                  NaN  5000000.0  \n",
       "..                 ...        ...  \n",
       "453             Butler  2433333.0  \n",
       "454                NaN   900000.0  \n",
       "455                NaN  2900000.0  \n",
       "456             Kansas   947276.0  \n",
       "457                NaN        NaN  \n",
       "\n",
       "[458 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f45a9682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name            Team  Number Position   Age Height  Weight  \\\n",
      "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
      "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
      "2   John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
      "3    R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
      "4  Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
      "5   Amir Johnson  Boston Celtics    90.0       PF  29.0    6-9   240.0   \n",
      "6  Jordan Mickey  Boston Celtics    55.0       PF  21.0    6-8   235.0   \n",
      "7   Kelly Olynyk  Boston Celtics    41.0        C  25.0    7-0   238.0   \n",
      "8   Terry Rozier  Boston Celtics    12.0       PG  22.0    6-2   190.0   \n",
      "9   Marcus Smart  Boston Celtics    36.0       PG  22.0    6-4   220.0   \n",
      "\n",
      "             College      Salary  \n",
      "0              Texas   7730337.0  \n",
      "1          Marquette   6796117.0  \n",
      "2  Boston University         NaN  \n",
      "3      Georgia State   1148640.0  \n",
      "4                NaN   5000000.0  \n",
      "5                NaN  12000000.0  \n",
      "6                LSU   1170960.0  \n",
      "7            Gonzaga   2165160.0  \n",
      "8         Louisville   1824360.0  \n",
      "9     Oklahoma State   3431040.0  \n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "df_copy = df_copy.query('Age < 25')\n",
    "df_copy\n",
    "\n",
    "indices_to_drop = df_copy[df_copy['Weight'] < 185].index # récupérer les index\n",
    "df.drop(indices_to_drop, inplace=True)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a516d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name           Jae Crowder\n",
       "Team        Boston Celtics\n",
       "Number                99.0\n",
       "Position                SF\n",
       "Age                   25.0\n",
       "Height                 6-6\n",
       "Weight               235.0\n",
       "College          Marquette\n",
       "Salary           6796117.0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "433c782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>7730337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name            Team  Number Position   Age Height  Weight  \\\n",
       "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
       "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "\n",
       "     College     Salary  \n",
       "0      Texas  7730337.0  \n",
       "1  Marquette  6796117.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0:1] # ici les index sont des nombres mais la différence c'est qu'on peut utiliser les noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aecf7543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amir Johnson</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>90.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Chris Johnson</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>981348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Trey Lyles</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>41.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2239800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "3      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "4    Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
       "5     Amir Johnson  Boston Celtics    90.0       PF  29.0    6-9   240.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "451  Chris Johnson       Utah Jazz    23.0       SF  26.0    6-6   206.0   \n",
       "452     Trey Lyles       Utah Jazz    41.0       PF  20.0   6-10   234.0   \n",
       "455   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "456    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College      Salary  \n",
       "1            Marquette   6796117.0  \n",
       "2    Boston University         NaN  \n",
       "3        Georgia State   1148640.0  \n",
       "4                  NaN   5000000.0  \n",
       "5                  NaN  12000000.0  \n",
       "..                 ...         ...  \n",
       "451             Dayton    981348.0  \n",
       "452           Kentucky   2239800.0  \n",
       "455                NaN   2900000.0  \n",
       "456             Kansas    947276.0  \n",
       "457                NaN         NaN  \n",
       "\n",
       "[366 rows x 9 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('Position != \"PG\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "29994409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amir Johnson</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>90.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Chris Johnson</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>981348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Trey Lyles</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>41.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2239800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "3      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "4    Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
       "5     Amir Johnson  Boston Celtics    90.0       PF  29.0    6-9   240.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "451  Chris Johnson       Utah Jazz    23.0       SF  26.0    6-6   206.0   \n",
       "452     Trey Lyles       Utah Jazz    41.0       PF  20.0   6-10   234.0   \n",
       "455   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "456    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College      Salary  \n",
       "1            Marquette   6796117.0  \n",
       "2    Boston University         NaN  \n",
       "3        Georgia State   1148640.0  \n",
       "4                  NaN   5000000.0  \n",
       "5                  NaN  12000000.0  \n",
       "..                 ...         ...  \n",
       "451             Dayton    981348.0  \n",
       "452           Kentucky   2239800.0  \n",
       "455                NaN   2900000.0  \n",
       "456             Kansas    947276.0  \n",
       "457                NaN         NaN  \n",
       "\n",
       "[366 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Position'] != 'PG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33df9337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 9)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0], df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f17b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Avery Bradley', 'Boston Celtics', 0.0, 'PG', 25.0, '6-2', 180.0, 'Texas', 7730337.0]\n"
     ]
    }
   ],
   "source": [
    "row = []\n",
    "for i in range(df.shape[0]):\n",
    "    row.append(list(df.iloc[i,:]))\n",
    "\n",
    "print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafdb89f",
   "metadata": {},
   "source": [
    "insérer des élements à n'importe quel endroit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26498c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>7730337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jae Cr</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Trey Lyles</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>41.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2239800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Shelvin Mack</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-3</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Butler</td>\n",
       "      <td>2433333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "0    Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2           Jae Cr  Boston Celtics    99.0       SF  25.0      0   235.0   \n",
       "3     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "4      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "446     Trey Lyles       Utah Jazz    41.0       PF  20.0   6-10   234.0   \n",
       "447   Shelvin Mack       Utah Jazz     8.0       PG  26.0    6-3   203.0   \n",
       "448   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "449    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "450            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College     Salary  \n",
       "0                Texas  7730337.0  \n",
       "1            Marquette  6796117.0  \n",
       "2            Marquette  6796117.0  \n",
       "3    Boston University        NaN  \n",
       "4        Georgia State  1148640.0  \n",
       "..                 ...        ...  \n",
       "446           Kentucky  2239800.0  \n",
       "447             Butler  2433333.0  \n",
       "448                NaN  2900000.0  \n",
       "449             Kansas   947276.0  \n",
       "450                NaN        NaN  \n",
       "\n",
       "[451 rows x 9 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row2 = ['Jae Cr','Boston Celtics',\t99.0,\t'SF'\t,25.0,\t6-6,\t235.0\t,'Marquette',\t6796117.0]\n",
    "\n",
    "# Copy original DataFrame\n",
    "df2 = df.copy()\n",
    "\n",
    "# Insert row at position 1\n",
    "df2.loc[1.5] = new_row2\n",
    "df2 = df2.sort_index().reset_index(drop=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "df516ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Rashad Vaughn</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>20.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>202.0</td>\n",
       "      <td>UNLV</td>\n",
       "      <td>1733040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Devin Booker</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2127840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Dante Exum</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3777720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>5103120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Tyus Jones</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1282080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>15.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>220.0</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>4088019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Andre Miller</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>24.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6-3</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>250750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Kevin Garnett</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>21.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Tim Duncan</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>5250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                    Team  Number Position   Age Height  \\\n",
       "226     Rashad Vaughn         Milwaukee Bucks    20.0       SG  19.0    6-6   \n",
       "122      Devin Booker            Phoenix Suns     1.0       SG  19.0    6-6   \n",
       "445        Dante Exum               Utah Jazz    11.0       PG  20.0    6-6   \n",
       "116  D'Angelo Russell      Los Angeles Lakers     1.0       PG  20.0    6-5   \n",
       "401        Tyus Jones  Minnesota Timberwolves     1.0       PG  20.0    6-2   \n",
       "..                ...                     ...     ...      ...   ...    ...   \n",
       "261      Vince Carter       Memphis Grizzlies    15.0       SG  39.0    6-6   \n",
       "304      Andre Miller       San Antonio Spurs    24.0       PG  40.0    6-3   \n",
       "400     Kevin Garnett  Minnesota Timberwolves    21.0       PF  40.0   6-11   \n",
       "298        Tim Duncan       San Antonio Spurs    21.0        C  40.0   6-11   \n",
       "457               NaN                     NaN     NaN      NaN   NaN    NaN   \n",
       "\n",
       "     Weight         College     Salary  \n",
       "226   202.0            UNLV  1733040.0  \n",
       "122   206.0        Kentucky  2127840.0  \n",
       "445   190.0             NaN  3777720.0  \n",
       "116   195.0      Ohio State  5103120.0  \n",
       "401   195.0            Duke  1282080.0  \n",
       "..      ...             ...        ...  \n",
       "261   220.0  North Carolina  4088019.0  \n",
       "304   200.0            Utah   250750.0  \n",
       "400   240.0             NaN  8500000.0  \n",
       "298   250.0     Wake Forest  5250000.0  \n",
       "457     NaN             NaN        NaN  \n",
       "\n",
       "[450 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df.sort_values(by=['Age', 'Weight'], ascending=True)  \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9864d61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Kobe Bryant</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6-8</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22970500.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6-8</td>\n",
       "      <td>240.0</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>22875000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Dwight Howard</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>12.0</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22359364.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Chris Bosh</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>22192730.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                 Team  Number Position   Age Height  \\\n",
       "109      Kobe Bryant   Los Angeles Lakers    24.0       SF  37.0    6-6   \n",
       "169     LeBron James  Cleveland Cavaliers    23.0       SF  31.0    6-8   \n",
       "33   Carmelo Anthony      New York Knicks     7.0       SF  32.0    6-8   \n",
       "251    Dwight Howard      Houston Rockets    12.0        C  30.0   6-11   \n",
       "339       Chris Bosh           Miami Heat     1.0       PF  32.0   6-11   \n",
       "\n",
       "     Weight       College      Salary  Rank  \n",
       "109   212.0           NaN  25000000.0   1.0  \n",
       "169   250.0           NaN  22970500.0   2.0  \n",
       "33    240.0      Syracuse  22875000.0   3.0  \n",
       "251   265.0           NaN  22359364.0   4.0  \n",
       "339   235.0  Georgia Tech  22192730.0   5.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rank'] = df['Salary'].rank(method='average', ascending=False) # pour rank par rapport à une features \n",
    "df.sort_values(by='Rank').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b4ba9",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "02ac99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-4.0.1.tar.gz (434.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.2/434.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.9 (from pyspark)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-4.0.1-py2.py3-none-any.whl size=434813860 sha256=b5c5785be07adfcdddeae573b9a2b18bb5347becc5ed9da341396bacd0d7e69f\n",
      "  Stored in directory: /Users/justinkim/Library/Caches/pip/wheels/10/e6/6b/c50eb601fa827dd56a5272db5d5db360e559e527a80a665b1d\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pyspark]m1/2\u001b[0m [pyspark]\n",
      "\u001b[1A\u001b[2KSuccessfully installed py4j-0.10.9.9 pyspark-4.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, when, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# 1. Initialisation de la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExempleDataFrameSpark\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. Définition d'un schéma pour le DataFrame (optionnel, pour un contrôle précis)\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"nom\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"salaire\", DoubleType(), True),\n",
    "    StructField(\"ville\", StringType(), True)\n",
    "])\n",
    "\n",
    "# 3. Création d'un DataFrame à partir de données brutes (si pas de fichier CSV)\n",
    "data = [\n",
    "    (1, \"Alice\", 25, 50000.0, \"Paris\"),\n",
    "    (2, \"Bob\", 30, 60000.0, \"Lyon\"),\n",
    "    (3, \"Charlie\", 35, 75000.0, \"Marseille\"),\n",
    "    (4, \"David\", 28, 55000.0, \"Paris\"),\n",
    "    (5, \"Emma\", 40, 80000.0, None)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Alternativement, charger un DataFrame depuis un fichier CSV\n",
    "# df = spark.read.csv(\"path/to/data.csv\", header=True, schema=schema)\n",
    "\n",
    "# 4. Afficher le schéma du DataFrame\n",
    "print(\"Schéma du DataFrame :\")\n",
    "df.printSchema()\n",
    "\n",
    "# 5. Afficher les premières lignes\n",
    "print(\"Aperçu des données :\")\n",
    "df.show(5, truncate=False)\n",
    "\n",
    "# 6. Exemple de transformations\n",
    "# a. Filtrer les lignes où l'âge est supérieur à 30\n",
    "df_filtre = df.filter(col(\"age\") > 30)\n",
    "print(\"Personnes de plus de 30 ans :\")\n",
    "df_filtre.show()\n",
    "\n",
    "# b. Ajouter une nouvelle colonne basée sur une condition\n",
    "df = df.withColumn(\"categorie_age\", \n",
    "                   when(col(\"age\") < 30, \"Jeune\")\n",
    "                   .when(col(\"age\") <= 35, \"Adulte\")\n",
    "                   .otherwise(\"Senior\"))\n",
    "print(\"DataFrame avec nouvelle colonne :\")\n",
    "df.show()\n",
    "\n",
    "# c. Grouper et agréger : calculer le salaire moyen par ville\n",
    "df_agg = df.groupBy(\"ville\").agg(\n",
    "    avg(\"salaire\").alias(\"salaire_moyen\"),\n",
    "    count(\"id\").alias(\"nombre_personnes\")\n",
    ")\n",
    "print(\"Salaire moyen et nombre de personnes par ville :\")\n",
    "df_agg.show()\n",
    "\n",
    "# 7. Gestion des valeurs manquantes\n",
    "# Remplacer les valeurs nulles dans la colonne 'ville' par 'Inconnu'\n",
    "df = df.na.fill({\"ville\": \"Inconnu\"})\n",
    "print(\"DataFrame après remplacement des valeurs nulles :\")\n",
    "df.show()\n",
    "\n",
    "# 8. Jointure avec un autre DataFrame\n",
    "# Création d'un DataFrame pour les départements\n",
    "data_dep = [(1, \"Paris\", \"Île-de-France\"), (2, \"Lyon\", \"Auvergne-Rhône-Alpes\"), (3, \"Inconnu\", \"Inconnu\")]\n",
    "schema_dep = StructType([\n",
    "    StructField(\"id_dep\", IntegerType(), False),\n",
    "    StructField(\"ville\", StringType(), True),\n",
    "    StructField(\"region\", StringType(), True)\n",
    "])\n",
    "df_dep = spark.createDataFrame(data_dep, schema_dep)\n",
    "\n",
    "# Jointure sur la colonne 'ville'\n",
    "df_joined = df.join(df_dep, \"ville\", \"left\")\n",
    "print(\"DataFrame après jointure :\")\n",
    "df_joined.show()\n",
    "\n",
    "# 9. Sauvegarde des résultats\n",
    "# Sauvegarder le DataFrame transformé en format Parquet\n",
    "df.write.mode(\"overwrite\").parquet(\"output/transformed_data\")\n",
    "\n",
    "# Sauvegarder les résultats agrégés en CSV\n",
    "df_agg.write.mode(\"overwrite\").csv(\"output/aggregated_data\", header=True)\n",
    "\n",
    "# 10. Utilisation de SQL avec Spark\n",
    "# Créer une vue temporaire pour exécuter des requêtes SQL\n",
    "df.createOrReplaceTempView(\"personnes\")\n",
    "result_sql = spark.sql(\"\"\"\n",
    "    SELECT ville, AVG(salaire) as salaire_moyen, COUNT(*) as nombre\n",
    "    FROM personnes\n",
    "    GROUP BY ville\n",
    "    HAVING COUNT(*) > 1\n",
    "\"\"\")\n",
    "print(\"Résultat de la requête SQL :\")\n",
    "result_sql.show()\n",
    "\n",
    "# 11. Arrêter la session Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5958a93",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eeda66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "304947b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Driver  Points  Age\n",
      "0    Hamilton     408   33\n",
      "1      Vettel     320   31\n",
      "2   Raikkonen     251   39\n",
      "3  Verstappen     249   21\n",
      "4      Bottas     247   29\n",
      "5   Ricciardo     170   29\n",
      "6  Hulkenberg      69   31\n",
      "7       Perez      62   28\n",
      "8   Magnussen      56   26\n",
      "9       Sainz      53   24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data of 2018 drivers world championship\n",
    "dict1 = {'Driver': ['Hamilton', 'Vettel', 'Raikkonen',\n",
    "                    'Verstappen', 'Bottas', 'Ricciardo',\n",
    "                    'Hulkenberg', 'Perez', 'Magnussen',\n",
    "                    'Sainz', 'Alonso', 'Ocon', 'Leclerc',\n",
    "                    'Grosjean', 'Gasly', 'Vandoorne',\n",
    "                    'Ericsson', 'Stroll', 'Hartley', 'Sirotkin'],\n",
    "\n",
    "         'Points': [408, 320, 251, 249, 247, 170, 69, 62, 56,\n",
    "                    53, 50, 49, 39, 37, 29, 12, 9, 6, 4, 1],\n",
    "\n",
    "         'Age': [33, 31, 39, 21, 29, 29, 31, 28, 26, 24, 37,\n",
    "                 22, 21, 32, 22, 26, 28, 20, 29, 23]}\n",
    "\n",
    "# creating dataframe using DataFrame constructor\n",
    "df = pd.DataFrame(dict1)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "df28d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     408\n",
       "1     320\n",
       "2     251\n",
       "3     249\n",
       "4     247\n",
       "5     170\n",
       "6      69\n",
       "7      62\n",
       "8      56\n",
       "9      53\n",
       "10     50\n",
       "11     49\n",
       "12     39\n",
       "13     37\n",
       "14     29\n",
       "15     12\n",
       "16      9\n",
       "17      6\n",
       "18      4\n",
       "19      1\n",
       "Name: Points, dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Points'] \n",
    "df.Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "a7e49550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>Points</th>\n",
       "      <th>Age</th>\n",
       "      <th>Nul</th>\n",
       "      <th>Statut</th>\n",
       "      <th>stat</th>\n",
       "      <th>Score Normalisé par age</th>\n",
       "      <th>Autre point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Stroll</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Verstappen</td>\n",
       "      <td>249</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>8.517241</td>\n",
       "      <td>-3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leclerc</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ocon</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gasly</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Driver  Points  Age  Nul Statut        stat  Score Normalisé par age  \\\n",
       "17      Stroll       6   20    0    Yes  A le droit                 0.300000   \n",
       "3   Verstappen     249   21    0    Yes  A le droit                 8.517241   \n",
       "12     Leclerc      39   21    0    Yes  A le droit                 1.351351   \n",
       "11        Ocon      49   22    0    Yes  A le droit                 1.857143   \n",
       "14       Gasly      29   22    0    Yes  A le droit                 1.156250   \n",
       "\n",
       "    Autre point  \n",
       "17         19.4  \n",
       "3          -3.9  \n",
       "12         17.1  \n",
       "11         17.1  \n",
       "14         19.1  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nsmallest(5, ['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a9098",
   "metadata": {},
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP SALES\n",
    "Récupérer le produit le plus vendu df.loc[df.groupby('region')['sales'].idxmax()] \n",
    "    # 4. Leader par marché-année\n",
    "    idx_max = agg_df.groupby(['year', 'market'])['revenue'].idxmax()\n",
    "    agg_df['is_leader'] = False # CREER UNE NOUVELLE COLONNE OU MERGE \n",
    "    agg_df.loc[idx_max, 'is_leader'] = True\n",
    "\n",
    "# CATEGORY LA PLUS FREQUENTE\n",
    "Catégorie les plus fréquentes ('category', pd.Series.mode) ou  lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0])\n",
    "\n",
    "\n",
    "# DELTA TIME ENTRE UNE LIVRAISON \n",
    "days_active=('order_date', lambda x: (x.max() - x.min()).days)  (dt c'est avec une series)\n",
    "                                                                 \n",
    "+# CALCUL DUN POURCENTAGE RAJOUTE \n",
    "market_data.groupby(['market','year'])['revenue'].sum() \n",
    "NON ==>\n",
    "market_data['total_group'] = market_data.groupby(['market','year'])['revenue'].transform('sum')\n",
    "\n",
    "# Calculer le % de contribution de chaque ligne\n",
    "market_data['pct_of_group'] = market_data['revenue'] / market_data['total_group'] * 100\n",
    "\n",
    "\n",
    "# CROISSANCE YTY \n",
    "agg_df['yoy_growth'] = agg_df.groupby(['market', 'company'])['market_share'].pct_change() * 100\n",
    "\n",
    "\n",
    "# Calcul sur une colonne avec apply \n",
    "    herfindahl = agg_df.groupby(['year', 'market']).apply(\n",
    "        lambda x: (x['market_share'] ** 2).sum() / 100\n",
    "    ).reset_index(name='herfindahl_index')\n",
    "    \n",
    "    \n",
    "# RANK\n",
    "sales['rang_region'] = sales.groupby('region')['ventes'].rank(ascending=False, methode = 'dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50238897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product  region\n",
      "A        North     2\n",
      "B        South     3\n",
      "C        North     4\n",
      "Name: sales, dtype: int64\n",
      "        date region product  sales  units\n",
      "2 2024-01-02  North       A    120     12\n",
      "3 2024-01-02  South       B    180     18\n"
     ]
    }
   ],
   "source": [
    "# EXERCICE 1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-03'],\n",
    "    'region': ['North', 'South', 'North', 'South', 'North'],\n",
    "    'product': ['A', 'B', 'A', 'B', 'C'],\n",
    "    'sales': [100, 150, 120, 180, 90],\n",
    "    'units': [10, 15, 12, 18, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "df.groupby('region').agg({\n",
    "    'sales' : ['mean', 'sum'],\n",
    "    'region' : 'count'\n",
    "})\n",
    "\n",
    "\n",
    "# Récupérer le produit le plus vendu df.loc[df.groupby('region')['sales'].idxmax()]\n",
    "print(df.groupby(['product', 'region'])['sales'].idxmax())\n",
    "index_top_produit = df.groupby('region')['sales'].idxmax()\n",
    "\n",
    "\n",
    "top_prod = df.loc[index_top_produit]\n",
    "top_prod\n",
    "\n",
    "\n",
    "result = df.groupby('region').agg(\n",
    "    total_sales=('sales', 'sum'),\n",
    "    avg_sales=('sales', 'mean'),\n",
    "    num_transactions=('sales', 'count')\n",
    ").reset_index()\n",
    "top_products = df.loc[df.groupby('region')['sales'].idxmax()]\n",
    "print(top_products)\n",
    "\n",
    "\n",
    "# Merger avec les top_products\n",
    "result = result.merge(\n",
    "    top_products[['region', 'product']].rename(columns={'product': 'top_product'}),\n",
    "    on='region'\n",
    ")\n",
    "\n",
    "# EXERCICE 2\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': [1, 1, 1, 2, 2, 3, 3, 3, 3],\n",
    "    'order_date': pd.date_range('2024-01-01', periods=9, freq='D'),\n",
    "    'order_value': [100, 150, 200, 80, 120, 300, 250, 400, 350],\n",
    "    'category': ['Electronics', 'Clothing', 'Electronics', \n",
    "                 'Food', 'Food', 'Electronics', 'Electronics', 'Furniture', 'Electronics']\n",
    "})\n",
    "\n",
    "customers['order_date'] = pd.to_datetime(customers['order_date'])\n",
    "customers['days'] = customers['order_date'].dt.day\n",
    "\n",
    "    \n",
    "\n",
    "customers.groupby('customer_id').agg(\n",
    "    nb_tot_commande = ('order_value', 'count'),\n",
    "    valeur_tot_commande = ('order_value', 'sum'),\n",
    "    valeur_moy_commande = ('order_value', 'mean'),\n",
    "    cat_frequent = ('category', pd.Series.mode),\n",
    "    delta_t = ('days',lambda x : max(x)-min(x) )\n",
    ")\n",
    "\n",
    "# EXERCICE 3\n",
    "import numpy as np\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'date': pd.date_range('2023-01-01', periods=100, freq='W'),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
    "    'product': np.random.choice(['Product_A', 'Product_B', 'Product_C'], 100),\n",
    "    'sales': np.random.randint(1000, 10000, 100),\n",
    "    'profit': np.random.randint(100, 2000, 100)\n",
    "})\n",
    "sales_data['quarter'] = sales_data['date'].dt.quarter\n",
    "sales_data['year'] = sales_data['date'].dt.year\n",
    "\n",
    "table_pivot = pd.pivot_table(sales_data, index=['region','product'], columns=['year','quarter'], values='sales', aggfunc='sum',fill_value= 0, margins = True)\n",
    "sales_data['quarter_year'] = (\n",
    "sales_data['year'].astype(str) + '-Q' + \n",
    "sales_data['quarter'].astype(str)\n",
    ")\n",
    "\n",
    "# EXERCICE 4\n",
    "\n",
    "market_data = pd.DataFrame({\n",
    "    'year': [2022]*12 + [2023]*12 + [2024]*12,\n",
    "    'month': list(range(1, 13)) * 3,\n",
    "    'company': np.random.choice(['CompanyA', 'CompanyB', 'CompanyC', 'CompanyD'], 36),\n",
    "    'revenue': np.random.randint(10000, 100000, 36),\n",
    "    'market': np.random.choice(['USA', 'Europe', 'Asia'], 36)\n",
    "})\n",
    "\n",
    "market_data['market_total'] = market_data.groupby(['year', 'market'])['revenue'].transform('sum')\n",
    "\n",
    "# 2. Part de marché\n",
    "market_data['market_share'] = market_data['revenue'] / market_data['market_total'] * 100\n",
    "    \n",
    "agg_df = market_data.groupby(['year', 'market', 'company']).agg({\n",
    "    'revenue': 'sum',\n",
    "    'market_share': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Trier et calculer YoY\n",
    "agg_df = agg_df.sort_values(['market', 'company', 'year'])\n",
    "agg_df['yoy_growth'] = agg_df.groupby(['market', 'company'])['market_share'].pct_change() * 100\n",
    "\n",
    "agg_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ee02d",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "Pour chaque produit, calculer:\n",
    "1. Moving average 7 jours\n",
    "2. Moving average 30 jours\n",
    "3. Trend (différence entre MA7 et MA30)\n",
    "4. Volatilité (rolling std 7 jours)\n",
    "5. Signal: \"BUY\" si MA7 > MA30 et trend positif, \"SELL\" sinon\n",
    "6. Cumulative sales YTD (Year-to-date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b549ec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Product_A</td>\n",
       "      <td>132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>Product_C</td>\n",
       "      <td>715.442671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>Product_B</td>\n",
       "      <td>548.884322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>Product_C</td>\n",
       "      <td>564.323933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>Product_C</td>\n",
       "      <td>828.760485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>Product_B</td>\n",
       "      <td>757.807040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>Product_A</td>\n",
       "      <td>572.239515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>Product_C</td>\n",
       "      <td>648.676067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>Product_B</td>\n",
       "      <td>972.115678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>Product_A</td>\n",
       "      <td>152.557329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    product       sales\n",
       "0   2023-01-01  Product_A  132.000000\n",
       "1   2023-01-02  Product_C  715.442671\n",
       "2   2023-01-03  Product_B  548.884322\n",
       "3   2023-01-04  Product_C  564.323933\n",
       "4   2023-01-05  Product_C  828.760485\n",
       "..         ...        ...         ...\n",
       "360 2023-12-27  Product_B  757.807040\n",
       "361 2023-12-28  Product_A  572.239515\n",
       "362 2023-12-29  Product_C  648.676067\n",
       "363 2023-12-30  Product_B  972.115678\n",
       "364 2023-12-31  Product_A  152.557329\n",
       "\n",
       "[365 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXERCICE 5\n",
    "\n",
    "time_series = pd.DataFrame({\n",
    "    'date': pd.date_range('2023-01-01', periods=365, freq='D'),\n",
    "    'product': np.random.choice(['Product_A', 'Product_B', 'Product_C'], 365),\n",
    "    'sales': np.random.randint(100, 1000, 365) + \n",
    "             np.sin(np.arange(365) * 2 * np.pi / 365) * 200  # Seasonalité\n",
    "})\n",
    "\n",
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5066a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table Let's start by creating a simple pivot table. \n",
    "# Suppose you have data about different products, and you want to see the average price of each product category:\n",
    "\n",
    "pivot_table = df.pivot_table(index='Product', values='Price', aggfunc='mean')\n",
    "pivot = titanic.pivot_table(index='class', columns='sex', values=['survived', 'fare'], aggfunc='mean')\n",
    "\n",
    "# TODO: create a pivot table that summarizes the sum of toy sales by toy type and store.\n",
    "pivot_table = pd.pivot_table(df, index = 'Toy', columns='Store', values = 'Sales' , aggfunc='sum') # la aggfnc sur les values\n",
    "\n",
    "# TODO: Create a pivot table that shows the average (mean) price and quantity of products grouped by category and product type\n",
    "\n",
    "pivot_table = pd.pivot_table(df, values=['Price', 'Quantity'], index=['Category', 'Product'], aggfunc={'Price': 'mean', 'Quantity': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ea8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"IsYouthful\"] = df[\"Age\"].apply(lambda age: \"Yes\" if age < 30 else \"No\")\n",
    "\n",
    "df2 = pd.DataFrame({\"Name\": [\"Megan\"], \"Age\": [34], \"City\": [\"San Francisco\"], \"IsYouthful\": [\"No\"]})\n",
    "\n",
    "df_concatenated = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "print(df_concatenated)\n",
    "\n",
    "# Sort survivors by age\n",
    "sorted_df = survivors.sort_values('age')\n",
    "sorted_df = survivors.sort_values(['pclass', 'age'], ascending=[False, True])\n",
    "\n",
    "#create a rank \n",
    "library['rank'] = library['rating'].rank(axis = 0, method = 'dense', ascending = False) # ascendign False la plus grosse note aura rank 1\n",
    "\n",
    "# add new row avec concat\n",
    "new_row = pd.DataFrame({'Grocery Item': ['Pears'], 'Price per kg': [4.00]})\n",
    "\n",
    "grocery_df = pd.concat([grocery_df, new_row]).reset_index(drop=True)\n",
    "\n",
    "# remove row \n",
    "index_to_delete = grocery_df[grocery_df['Grocery Item'] == 'Grapes'].index\n",
    "indices_to_delete = grocery_df[grocery_df['Grocery Item'].isin(['Apples', 'Oranges'])].index\n",
    "grocery_df = grocery_df.drop(index_to_delete)\n",
    "\n",
    "print(grocery_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 21, 22, 23, 24, 26, 28, 29, 31, 32, 33, 37, 39]\n",
      "13\n",
      "Age\n",
      "29    3\n",
      "31    2\n",
      "21    2\n",
      "28    2\n",
      "26    2\n",
      "22    2\n",
      "33    1\n",
      "39    1\n",
      "24    1\n",
      "37    1\n",
      "32    1\n",
      "20    1\n",
      "23    1\n",
      "Name: count, dtype: int64\n",
      "3\n",
      "17 20\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k4/x11w534x6fx5843q4r1vdmtc0000gp/T/ipykernel_51836/211200575.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;31m# Select une colonne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/360capital/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Points'"
     ]
    }
   ],
   "source": [
    "df.shape \n",
    "\n",
    "# Select une colonne \n",
    "df.Points\n",
    "df['Points']\n",
    "\n",
    "# Select une row\n",
    "df.iloc[1]\n",
    "# Select plusieurs rows\n",
    "df.iloc[0:3]\n",
    "df.loc[0, 'column_name'] # Data in row 0 and column ‘column_name’ pour les labesls\n",
    "\n",
    "\n",
    "# Select randomly rows\n",
    "sampled_df = df.sample(frac=0.5).reset_index().drop('index', axis=1)\n",
    "\n",
    "# Select row that contains a certain string \n",
    "\n",
    "#print(df[df[\"Driver\"].str.contains(\"ami\")]) # on peut mettre un OR contient result = df[df[\"Team\"].str.contains(\"Boston\") | df[\"College\"].str.contains(\"MIT\")] \n",
    "\n",
    "# Create a list, a dict from rows\n",
    "\n",
    "#print(df.value_counts())\n",
    "#print(df.values.tolist())\n",
    "#print(df.to_numpy().tolist())\n",
    "#print(df.to_dict(orient='records')) # list of dict\n",
    "#print([list(row) for row in df.itertuples(index=False)]) # pour les grandes base de données\n",
    "\n",
    "# Drop une colonne \n",
    "#df = df.drop(df.iloc[:, 1:3], axis=1)\n",
    "#df = df.drop('Points', axis=1)\n",
    "#df.pop('col')\n",
    "# Drop columns with more than 50% missing values\n",
    "#threshold = len(df) * 0.5\n",
    "#df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Créer une colonne \n",
    "l_a_rajouter = [0 for i in range(len(df))]\n",
    "df['Nul'] = l_a_rajouter\n",
    "\n",
    "# Pour itérer sur une colonne et en créer une nouvelle avec un statut, High salary par exemple\n",
    "statut = []\n",
    "for age in df['Age']:\n",
    "    if age>18:\n",
    "        statut.append('Yes')\n",
    "df['Statut'] = statut\n",
    "\n",
    "bins = [0,18,40]\n",
    "lab = ['Non', 'A le droit']\n",
    "df['stat'] = pd.cut(df['Age'], bins = bins, labels = lab) # possible de le faire avce binning\n",
    "\n",
    "# pour itérer sur le nom des colonnes \n",
    "\n",
    "#for col in df.columns:\n",
    "    #print(col)\n",
    "\n",
    "\n",
    "# Récupérer le nom des colonnes\n",
    "\n",
    "#print(df.columns.to_list())\n",
    "#print(sorted(df.columns.values))\n",
    "#print(df.keys())\n",
    "\n",
    "# récupérer les values unique d'une colonne \n",
    "print(sorted(df['Age'].unique()))\n",
    "print(df['Age'].nunique())\n",
    "print(df['Age'].value_counts())\n",
    "print(df['Age'].value_counts().max())\n",
    "df.groupby('Age').size()\n",
    "pd.crosstab(index=df['Age'], columns='count')\n",
    "\n",
    "\n",
    "# Modifier index avec une colonne\n",
    "d = df.copy()\n",
    "d.index = d.pop(\"Driver\")\n",
    "#df.set_index('Age')\n",
    "#print(d)\n",
    "\n",
    "# Get l'index du max dans un dataframe\n",
    "\n",
    "i_min , min = 0, df['Age'][0]\n",
    "for i in range(len(df)):\n",
    "    if df['Age'][i]<min:\n",
    "        min = df['Age'][i]\n",
    "        i_min = i\n",
    "print(i_min, min)\n",
    "\n",
    "df.min()\n",
    "df[df.Points == df.Points.min()]\n",
    "\n",
    "df[['Age']].idxmax() # PLUS SIMPLE POUR LINDEX DU MAX\n",
    "df.nlargest(5, ['Age']) # Pour avoir accès au n value les plus grandes\n",
    "df.nsmallest(5, ['Age'])\n",
    "\n",
    "# Rename les colonnes \n",
    "\n",
    "df_co = df.copy()\n",
    "df_co.rename(columns={'Driver' : 'A', 'Points' : 'B' , 'Age': 'C',  'Nul': 'D',  'Statut': 'E',  'stat': 'F'}, inplace=True)\n",
    "\n",
    "l = [i for i in range(len(df_co.columns.to_list()))]\n",
    "df_co.columns = l\n",
    "\n",
    "#df_co.add_prefix('new_') \n",
    "\n",
    "# Duplicates \n",
    "df['Age'].drop_duplicates()\n",
    "unique_set = set(df['Age'])\n",
    "print(unique_set)\n",
    "\n",
    "# Créer une nouvelle colonne fonction des autres\n",
    "max = df['Points'].max() \n",
    "df[\"Score Normalisé par age\"] = df.apply(lambda x : x['Points']/x['Age'], axis = 1  )\n",
    "sorted(df[\"Score Normalisé par age\"].to_numpy(), reverse=True)\n",
    "df[\"Score Normalisé par age\"] = sorted(df[\"Score Normalisé par age\"].to_numpy(), reverse=True)\n",
    "\n",
    "df['Autre point'] = df['Age'] - (0.1 * df['Points'])\n",
    "\n",
    "\n",
    "# Data processing \n",
    "df.dropna()\n",
    "df.fillna(0)\n",
    "df.interpolate()  # Fills missing values using interpolation\n",
    "df.isnull() # ou notnull()\n",
    "\n",
    "df['column_name'] = df['column_name'].astype('int') # conversion datatype\n",
    "df['category_column'] = df['category_column'].astype('category')\n",
    "\n",
    "df.sort_values(by='column_name', ascending=False)\n",
    "\n",
    "# Memory handling \n",
    "df.memory_usage(deep=True) # indentify wich columns use le plus de mémoire\n",
    "for chunk in pd.read_csv('large_file.csv', chunksize=10000):\n",
    "    process(chunk)\n",
    "\n",
    "df['column_name'] = pd.to_numeric(df['column_name'], downcast='float')\n",
    "\n",
    "# Save un df \n",
    "df.to_excel('output.xlsx', sheet_name='Sheet1', index=False)\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "# ouvrir un json ou un html\n",
    "df.to_json('output.json')\n",
    "df.to_html('output.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c269f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011d7d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item 1', 'Item 2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df = pd.DataFrame({'Date':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'],\n",
    "                   'Product':['Umbrella', 'Mattress', 'Badminton', 'Shuttle'],\n",
    "                   'Last Price':[1200, 1500, 1600, 352],\n",
    "                   'Updated Price':[1250, 1450, 1550, 400],\n",
    "                   'Discount':[10, 10, 10, 10]})\n",
    "df\n",
    "\n",
    "Final_cost = []\n",
    "for element in df['Updated Price']:\n",
    "    if element != 'NaN' :\n",
    "        Final_cost.append(element*(0.9))\n",
    "df['Final Price'] = Final_cost\n",
    "df\n",
    "\n",
    "# Check si la colonne est présente \n",
    "if {'Updated Price', 'Discount'}.issubset(df.columns):\n",
    "    df['Final cost'] = df['Updated Price'] - (df['Updated Price']*0.1)\n",
    "\n",
    "elif {'Last Price', 'Discount'}.issubset(df.columns):\n",
    "    df['Final cost'] = df['Last Price'] - (df['Last Price']*0.1)\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame({'Date':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'],\n",
    "                   'Product':['Umbrella', 'Mattress', 'Badminton', 'Shuttle'],\n",
    "                   'Last_Price':[1200, 1500, 1600, 352],\n",
    "                   'Updated_Price':[1250, 1450, 1550, 400],\n",
    "                   'Discount':[10, 10, 10, 10]})\n",
    "\n",
    "# Create the indexes\n",
    "df.index =[f'Item {i}' for i in range(len(df))]\n",
    "\n",
    "# recherche dans les index qui satisfait une condition \n",
    "df\n",
    "df.query('Updated_Price > 1250').index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "413b8834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Updated_Price\n",
      "Product                 \n",
      "Badminton         1550.0\n",
      "Mattress          1450.0\n",
      "Shuttle            400.0\n",
      "Umbrella          1250.0\n",
      "Discount   10  All\n",
      "Product           \n",
      "Badminton   1    1\n",
      "Mattress    1    1\n",
      "Shuttle     1    1\n",
      "Umbrella    1    1\n",
      "All         4    4\n"
     ]
    }
   ],
   "source": [
    "# Exemple de pivot table : moyenne du prix mis à jour par produit\n",
    "\n",
    "pivot = df.pivot_table(index='Product', values='Updated_Price', aggfunc='mean')\n",
    "print(pivot)\n",
    "\n",
    "# crosstab pour relationship entre les variables\n",
    "crosstab = pd.crosstab(df['Product'], df['Discount'], margins=True)\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name  Age\n",
      "0    John Larter   32\n",
      "1  Robert Junior   34\n",
      "2     Jonny Depp   36\n"
     ]
    }
   ],
   "source": [
    "# Pour remplacer des valeurs dans une colonne \n",
    "# Define an incomplete dictionary\n",
    "df = pd.DataFrame({'Date':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'],\n",
    "                    'Event':['Music', 'Poetry', 'Theatre', 'Comedy'],\n",
    "                    'Cost':[10000, 5000, 15000, 2000]})\n",
    "d = {'Music': 'M', 'Poetry': 'P'}\n",
    "\n",
    "# Apply map() and handle missing values\n",
    "df['Event'] = df['Event'].map(d).fillna('Unknown')\n",
    "\n",
    "# split des tring colonnes\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['John Larter', 'Robert Junior', 'Jonny Depp'],\n",
    "    'Age': [32, 34, 36]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING DATASET \n",
    "\n",
    "# TODO: Convert the 'embarked' column to categorical type\n",
    "\n",
    "titanic['embarked'] = titanic['embarked'].astype('category')\n",
    "\n",
    "# TODO: Create a new column 'embarked_code' with encoded categories LABEL ENCODING\n",
    "titanic['embarked_code'] = titanic['embarked'].cat.codes\n",
    "\n",
    "print(titanic[['embarked', 'embarked_code']].head())\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "titanic['embarked_code'] = le.fit_transform(titanic['embarked'].fillna('missing'))\n",
    "\n",
    "# get dummies pour rajouter colonne one hot encoding\n",
    "dummies = pd.get_dummies(titanic['embarked'],prefix = 'embarked')\n",
    "print(pd.concat([titanic, dummies], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f87f2",
   "metadata": {},
   "source": [
    "# CodeSignals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adbd89c",
   "metadata": {},
   "source": [
    "🔑 Points clés Two Pointers\n",
    "✅ Utiliser quand:\n",
    "\n",
    "Array/string est trié ou peut être trié\n",
    "Besoin de trouver des paires\n",
    "Optimiser une solution O(n²)\n",
    "\n",
    "❌ Ne pas utiliser si:\n",
    "\n",
    "Array n'est pas trié ET ne peut pas être trié\n",
    "Besoin de garder l'ordre original\n",
    "Recherche plus complexe qu'une paire\n",
    "\n",
    "\n",
    "🔑 Points clés Sliding Window\n",
    "✅ Utiliser quand:\n",
    "\n",
    "Sous-array/substring contigus\n",
    "Fenêtre de taille k fixe\n",
    "Condition sur le contenu de la fenêtre\n",
    "\n",
    "❌ Ne pas utiliser si:\n",
    "\n",
    "Éléments non contigus\n",
    "Besoin d'ordre non-linéaire\n",
    "Sous-ensembles non-contigus\n",
    "\n",
    "Astuce: Si vous voyez \"sous-array\", \"substring\", \"fenêtre de taille k\" → pensez Sliding Window!\n",
    "\n",
    "🔑 Points clés Hash Map\n",
    "✅ Utiliser quand:\n",
    "\n",
    "Compter fréquences\n",
    "Recherche rapide (O(1))\n",
    "Détecter duplicatas\n",
    "Grouper par propriété\n",
    "\n",
    "❌ Éviter si:\n",
    "\n",
    "Besoin d'ordre trié\n",
    "Besoin du k-ième élément (utiliser heap)\n",
    "Contraintes d'espace strictes\n",
    "\n",
    "\n",
    "=> Binary Search \n",
    "🔑 Points clés Binary Search\n",
    "✅ Utiliser quand:\n",
    "\n",
    "Array trié\n",
    "Recherche dans range/espace monotone\n",
    "\"Trouver minimum/maximum qui satisfait X\"\n",
    "\n",
    "❌ Éviter si:\n",
    "\n",
    "Array non trié et ne peut être trié\n",
    "Recherche non-monotone\n",
    "Besoin de tous les éléments\n",
    "\n",
    "Astuce: Si vous voyez \"trié\" ou \"minimum/maximum satisfaisant condition\" → pensez Binary Search!\n",
    "### Utilise `left <= right` si :\n",
    "- ✅ Tu cherches un **élément exact**\n",
    "- ✅ Tu veux retourner `-1` si pas trouvé\n",
    "- ✅ Tu es familier avec le binary search \"classique\"\n",
    "\n",
    "### Utilise `left < right` si :\n",
    "- ✅ Tu cherches une **position** (insertion, lower_bound)\n",
    "- ✅ Tu veux **toujours** retourner une position valide\n",
    "- ✅ Le problème demande \"où insérer?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d21b0",
   "metadata": {},
   "source": [
    "You are given a list of n integers and a number k. Your task is to shuffle the array in such a way that, starting from the first element, every k-th element moves to the end of the array.\n",
    "\n",
    "For instance, if nums = [1, 2, 3, 4, 5, 6, 7, 8] and k = 3, the output should be [1, 2, 4, 5, 7, 8, 3, 6]. Here, the 3rd element 3 and the 6th element 6 (every 3rd element starting from the first) are moved to the end of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827563ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_array(nums, k): # ASTUCE CREER DEUX LISTES OU TU RECUPERES CEUX A MOVE CEUX A KEEP ET TU LES CONCAT A LA FIN\n",
    "    \"\"\"\n",
    "    Déplacer chaque k-ième élément à la fin.\n",
    "    Input: nums = [1, 2, 3, 4, 5, 6, 7, 8], k = 3\n",
    "    Output: [1, 2, 4, 5, 7, 8, 3, 6]\n",
    "    \"\"\"\n",
    "    if k <= 0 or k > len(nums):\n",
    "        return nums\n",
    "    \n",
    "    keep = []      # Éléments à garder en place\n",
    "    moved = []     # Éléments à déplacer à la fin\n",
    "    \n",
    "    for i in range(len(nums)):\n",
    "        # Chaque k-ième élément (indices k-1, 2k-1, 3k-1, ...)\n",
    "        if (i + 1) % k == 0:\n",
    "            moved.append(nums[i])\n",
    "        else:\n",
    "            keep.append(nums[i])\n",
    "    \n",
    "    # Fusionner : éléments gardés + éléments déplacés\n",
    "    return keep + moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751034f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRIX \n",
    "\n",
    "#traversé de matrice \n",
    "# Création matrice\n",
    "matrix = [[0] * cols for _ in range(rows)]\n",
    "\n",
    "# Parcourir tous les éléments\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        print(matrix[i][j])\n",
    "\n",
    "# Les 4 directions (haut, bas, gauche, droite)\n",
    "directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "def is_valid(i, j, rows, cols):\n",
    "    return 0 <= i < rows and 0 <= j < cols\n",
    "\n",
    "# Parcourir voisins\n",
    "for di, dj in directions:\n",
    "    ni, nj = i + di, j + dj\n",
    "    if is_valid(ni, nj, rows, cols):\n",
    "        # traiter voisin matrix[ni][nj]\n",
    "        \n",
    "def rotate(matrix): TRANSPOSE ET INVERSE LIGNES\n",
    "    \"\"\"\n",
    "    Rotation 90° dans sens horaire IN PLACE.\n",
    "    Input: [[1,2,3],[4,5,6],[7,8,9]]\n",
    "    Output: [[7,4,1],[8,5,2],[9,6,3]]\n",
    "    \"\"\"\n",
    "    n = len(matrix)\n",
    "    \n",
    "    # Transposer\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]\n",
    "    \n",
    "    # Inverser chaque ligne\n",
    "    for i in range(n):\n",
    "        matrix[i].reverse()\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# Test\n",
    "print(rotate([[1,2,3],[4,5,6],[7,8,9]]))\n",
    "\n",
    "def rotate_array(nums, k): clockwise en modifiant la liste initiale\n",
    "    k = k % len(nums)  # Ensure k is within the bounds of the array length\n",
    "    rotated = nums[-k:] + nums[:-k]\n",
    "    return rotated\n",
    "\n",
    "# A FAIRE SANS CREER UNE NOUVELLE LISTE ASTUCE FAIRE TROIS INVERSION UNE DE 0 A K AVEC TWO POINTERS UNE DE K+1 A N-1 ET TOUT LE TABLEA\n",
    "\n",
    "def rotate_array(arr, k):\n",
    "    \"\"\"\n",
    "    Rotation anti-horaire (vers la gauche) de k positions.\n",
    "    Input: arr = [1, 2, 3, 4, 5, 6, 7], k = 3\n",
    "    Output: [4, 5, 6, 7, 1, 2, 3]\n",
    "    \"\"\"\n",
    "    n = len(arr)\n",
    "    \n",
    "    # Cas limites\n",
    "    if n == 0 or k == 0:\n",
    "        return arr\n",
    "    \n",
    "    # Normaliser k (si k > n)\n",
    "    k = k % n\n",
    "    \n",
    "    # Si k = 0 après normalisation, pas de rotation\n",
    "    if k == 0:\n",
    "        return arr\n",
    "    \n",
    "    # Fonction helper pour inverser une portion\n",
    "    def reverse(start, end):\n",
    "        while start < end:\n",
    "            arr[start], arr[end] = arr[end], arr[start]\n",
    "            start += 1\n",
    "            end -= 1\n",
    "    \n",
    "    # Algorithme : 3 inversions\n",
    "    reverse(0, k - 1)      # Inverser les k premiers éléments\n",
    "    reverse(k, n - 1)      # Inverser le reste\n",
    "    reverse(0, n - 1)      # Inverser tout le tableau\n",
    "    \n",
    "    return arr\n",
    "\n",
    "#REVERSE GROUP K TWO POINTERS MAIS DABORD LEFT SUR UN GROUP ET RIGHT SUR LAUTRE BOUT\n",
    "def solution(arr, k):\n",
    "    \"\"\"\n",
    "    Inverser le tableau par groupes de k éléments.\n",
    "    Input: arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], k = 3\n",
    "    Output: [3, 2, 1, 6, 5, 4, 9, 8, 7, 10]\n",
    "    \"\"\"\n",
    "    n = len(arr)\n",
    "    \n",
    "    # Parcourir le tableau par groupes de k\n",
    "    for i in range(0, n, k):\n",
    "        # Déterminer les limites du groupe actuel\n",
    "        left = i\n",
    "        right = min(i + k - 1, n - 1)  # Ne pas dépasser la fin\n",
    "        \n",
    "        # Inverser ce groupe\n",
    "        while left < right:\n",
    "            arr[left], arr[right] = arr[right], arr[left]\n",
    "            left += 1\n",
    "            right -= 1\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def solution(nums): #  Product of Array Except Self astuce calculer le produit a droit de i et a gauche de i en stcokant dabord ans l avar et apres en multipliant \n",
    "    \"\"\"\n",
    "    Produit de l'array sauf self, sans division.\n",
    "    \"\"\"\n",
    "    n = len(nums)\n",
    "    answer = [1] * n\n",
    "    \n",
    "    # Calculer produit de tous à gauche\n",
    "    left_product = 1\n",
    "    for i in range(n):\n",
    "        answer[i] = left_product\n",
    "        left_product *= nums[i]\n",
    "    \n",
    "    # Multiplier par produit de tous à droite\n",
    "    right_product = 1\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        answer[i] *= right_product\n",
    "        right_product *= nums[i]\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d725e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea857a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_meeting_rooms(intervals):\n",
    "    \"\"\"\n",
    "    Nombre minimum de salles pour tous les meetings.\n",
    "    Input: [[0,30],[5,10],[15,20]]\n",
    "    Output: 2\n",
    "    \"\"\"\n",
    "    if not intervals:\n",
    "        return 0\n",
    "    \n",
    "    # Séparer starts et ends\n",
    "    starts = sorted(interval[0] for interval in intervals)\n",
    "    ends = sorted(interval[1] for interval in intervals)\n",
    "    \n",
    "    rooms = 0\n",
    "    max_rooms = 0\n",
    "    start_ptr = 0\n",
    "    end_ptr = 0\n",
    "    \n",
    "    while start_ptr < len(starts):\n",
    "        if starts[start_ptr] < ends[end_ptr]:\n",
    "            # Nouveau meeting commence\n",
    "            rooms += 1\n",
    "            max_rooms = max(max_rooms, rooms)\n",
    "            start_ptr += 1\n",
    "        else:\n",
    "            # Un meeting se termine\n",
    "            rooms -= 1\n",
    "            end_ptr += 1\n",
    "    \n",
    "    return max_rooms\n",
    "\n",
    "# Test\n",
    "print(min_meeting_rooms([[0,30],[5,10],[15,20]]))  # 2\n",
    "\n",
    "def sort_colors(nums): \"SORTING EN UN SEUL PASSAGE\"\n",
    "    \"\"\"\n",
    "    Trier array de 0, 1, 2 en un seul passage.\n",
    "    Input: [2,0,2,1,1,0]\n",
    "    Output: [0,0,1,1,2,2]\n",
    "    \"\"\"\n",
    "    # Pointeurs pour 0, 1, 2\n",
    "    left = 0        # Prochaine position pour 0\n",
    "    right = len(nums) - 1  # Prochaine position pour 2\n",
    "    current = 0\n",
    "    \n",
    "    while current <= right:\n",
    "        if nums[current] == 0:\n",
    "            nums[left], nums[current] = nums[current], nums[left]\n",
    "            left += 1\n",
    "            current += 1\n",
    "        elif nums[current] == 2:\n",
    "            nums[right], nums[current] = nums[current], nums[right]\n",
    "            right -= 1\n",
    "            # Ne pas incrémenter current (vérifier élément swappé)\n",
    "        else:  # nums[current] == 1\n",
    "            current += 1\n",
    "    \n",
    "    return nums\n",
    "\n",
    "# Test\n",
    "print(sort_colors([2,0,2,1,1,0]))  # [0,0,1,1,2,2]\n",
    "\n",
    "def can_complete_circuit(gas, cost):\n",
    "    \"\"\"\n",
    "    Trouver station de départ pour faire tour complet.\n",
    "    Input: gas = [1,2,3,4,5], cost = [3,4,5,1,2]\n",
    "    Output: 3\n",
    "    \"\"\"\n",
    "    total_tank = 0\n",
    "    curr_tank = 0\n",
    "    start = 0\n",
    "    \n",
    "    for i in range(len(gas)):\n",
    "        total_tank += gas[i] - cost[i]\n",
    "        curr_tank += gas[i] - cost[i]\n",
    "        \n",
    "        # Si tank devient négatif, recommencer d'ici\n",
    "        if curr_tank < 0:\n",
    "            start = i + 1\n",
    "            curr_tank = 0\n",
    "    \n",
    "    return start if total_tank >= 0 else -1\n",
    "\n",
    "# Test\n",
    "print(can_complete_circuit([1,2,3,4,5], [3,4,5,1,2]))  # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376d54b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2844425059.py, line 145)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[79], line 145\u001b[1;36m\u001b[0m\n\u001b[1;33m    --> IDEE DANS UN TWO POINTERS CEST WHILE LEFT < RIGHT NSUITE ON DEFINIT LA LOGIQUE DEVOLUTION DE LEFT ET RIGHT\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# HASMAP \n",
    "\n",
    "# Pattern 1: Compter fréquences\n",
    "from collections import Counter\n",
    "\n",
    "def count_frequencies(arr):\n",
    "    return Counter(arr)  # ou dict avec boucle\n",
    "\n",
    "# Pattern 2: Détection de duplicatas\n",
    "def has_duplicate(arr):\n",
    "    seen = set()\n",
    "    for num in arr:\n",
    "        if num in seen:\n",
    "            return True\n",
    "        seen.add(num)\n",
    "    return False\n",
    "\n",
    "# Pattern 3: Mapping\n",
    "def create_mapping(arr):\n",
    "    mapping = {}\n",
    "    for i, val in enumerate(arr):\n",
    "        mapping[val] = i\n",
    "    return mapping\n",
    "\n",
    "def top_k_frequent(nums, k): # COUNTER + .most_common dans un dict\n",
    "    \"\"\"\n",
    "    Trouver les k éléments les plus fréquents.\n",
    "    Input: nums = [1,1,1,2,2,3], k = 2\n",
    "    Output: [1,2]\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Compter fréquences\n",
    "    count = Counter(nums)\n",
    "    \n",
    "    # Méthode 1: utiliser most_common\n",
    "    return [num for num, freq in count.most_common(k)]\n",
    "    \n",
    "    # Méthode 2: avec heap\n",
    "    import heapq\n",
    "    return heapq.nlargest(k, count.keys(), key=count.get)\n",
    "\n",
    "# Test\n",
    "print(top_k_frequent([1,1,1,2,2,3], 2))  # [1, 2]\n",
    "\n",
    "def first_uniq_char(s):\n",
    "    \"\"\"\n",
    "    Trouver index du premier caractère unique.\n",
    "    Input: s = \"leetcode\"\n",
    "    Output: 0 (car 'l' apparaît une seule fois)\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    count = Counter(s)\n",
    "    \n",
    "    for i, char in enumerate(s):\n",
    "        if count[char] == 1:\n",
    "            return i\n",
    "    \n",
    "    return -1\n",
    "\n",
    "\n",
    "def group_anagrams(strs): #GROUP ANAGRAM ASTUCE AVEC SORTED\n",
    "    \"\"\"\n",
    "    Grouper les anagrammes ensemble.\n",
    "    Input: [\"eat\",\"tea\",\"tan\",\"ate\",\"nat\",\"bat\"]\n",
    "    Output: [[\"bat\"],[\"nat\",\"tan\"],[\"ate\",\"eat\",\"tea\"]]\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    groups = defaultdict(list)\n",
    "    \n",
    "    for s in strs:\n",
    "        # Clé: string triée (même pour tous anagrammes)\n",
    "        key = ''.join(sorted(s))\n",
    "        groups[key].append(s)\n",
    "    \n",
    "    return list(groups.values())\n",
    "\n",
    "\n",
    "# SLINDING WINDOW\n",
    "def length_of_longest_substring(s): # use of sliding window\n",
    "    \"\"\"\n",
    "    Longueur du plus long substring sans caractères répétés.\n",
    "    Input: s = \"abcabcbb\"\n",
    "    Output: 3 (\"abc\")\n",
    "    \"\"\"\n",
    "    char_set = set()\n",
    "    left = 0\n",
    "    max_length = 0\n",
    "    \n",
    "    for right in range(len(s)):\n",
    "        # Rétrécir fenêtre tant que s[right] est déjà présent\n",
    "        while s[right] in char_set:\n",
    "            char_set.remove(s[left])\n",
    "            left += 1\n",
    "        \n",
    "        # Ajouter caractère actuel\n",
    "        char_set.add(s[right])\n",
    "        max_length = max(max_length, right - left + 1)\n",
    "    \n",
    "    return max_length\n",
    "\n",
    "# Tests\n",
    "print(length_of_longest_substring(\"abcabcbb\"))  # 3\n",
    "print(length_of_longest_substring(\"bbbbb\"))     # 1\n",
    "print(length_of_longest_substring(\"pwwkew\"))    # 3\n",
    "\n",
    "\n",
    "#Minimum Window Substring\n",
    "def min_window(s, t):\n",
    "    \"\"\"\n",
    "    Plus petite fenêtre de s qui contient tous les caractères de t.\n",
    "    Input: s = \"ADOBECODEBANC\", t = \"ABC\"\n",
    "    Output: \"BANC\"\n",
    "    \"\"\"\n",
    "    if not s or not t:\n",
    "        return \"\"\n",
    "    \n",
    "    from collections import Counter\n",
    "    \n",
    "    # Compter caractères requis\n",
    "    required = Counter(t)\n",
    "    needed = len(required)\n",
    "    formed = 0\n",
    "    \n",
    "    window_counts = {}\n",
    "    \n",
    "    left = 0\n",
    "    min_len = float('inf')\n",
    "    min_left = 0\n",
    "    \n",
    "    for right in range(len(s)):\n",
    "        # Ajouter caractère de droite\n",
    "        char = s[right]\n",
    "        window_counts[char] = window_counts.get(char, 0) + 1\n",
    "        \n",
    "        if char in required and window_counts[char] == required[char]:\n",
    "            formed += 1\n",
    "        \n",
    "        # Rétrécir fenêtre tant que valide\n",
    "        while formed == needed and left <= right:\n",
    "            # Mettre à jour résultat\n",
    "            if right - left + 1 < min_len:\n",
    "                min_len = right - left + 1\n",
    "                min_left = left\n",
    "            \n",
    "            # Retirer caractère de gauche\n",
    "            char = s[left]\n",
    "            window_counts[char] -= 1\n",
    "            if char in required and window_counts[char] < required[char]:\n",
    "                formed -= 1\n",
    "            \n",
    "            left += 1\n",
    "    \n",
    "    return s[min_left:min_left + min_len] if min_len != float('inf') else \"\"\n",
    "\n",
    "# Test\n",
    "print(min_window(\"ADOBECODEBANC\", \"ABC\"))  # \"BANC\"\n",
    "\n",
    "\n",
    "# retirer duplicata dans un array trié ou pas \n",
    "\n",
    "def remove_duplicates(arr):\n",
    "    \"\"\"\n",
    "    Retirer duplicatas IN PLACE, retourner nouvelle longueur.\n",
    "    Input: [0,0,1,1,1,2,2,3,3,4]\n",
    "    Output: 5, arr devient [0,1,2,3,4,_,_,_,_,_]\n",
    "    \"\"\"\n",
    "    if not arr:\n",
    "        return 0\n",
    "    \n",
    "    # left = position où placer le prochain élément unique\n",
    "    left = 1\n",
    "    \n",
    "    for right in range(1, len(arr)):\n",
    "        if arr[right] != arr[right - 1]:\n",
    "            arr[left] = arr[right]\n",
    "            left += 1\n",
    "    \n",
    "    return left\n",
    "\n",
    "# Test\n",
    "arr = [0,0,1,1,1,2,2,3,3,4]\n",
    "length = remove_duplicates(arr)\n",
    "print(length, arr[:length])  # 5, [0, 1, 2, 3, 4]\n",
    "\n",
    "def remove_duplicates_unsorted(arr): # SI LARRAY EST PAS TRIE -> set \n",
    "    seen = set()\n",
    "    left = 0\n",
    "    for right in range(len(arr)):\n",
    "        if arr[right] not in seen:\n",
    "            seen.add(arr[right])\n",
    "            arr[left] = arr[right]\n",
    "            left += 1\n",
    "    return left\n",
    "\n",
    "\n",
    "\n",
    "def max_area(heights):\n",
    "    \"\"\"\n",
    "    Trouver la paire de lignes qui contient le plus d'eau.\n",
    "    Input: heights = [1,8,6,2,5,4,8,3,7]\n",
    "    Output: 49 (indices 1 et 8: min(8,7) * (8-1) = 7*7 = 49)\n",
    "    \"\"\"\n",
    "    left, right = 0, len(heights) - 1\n",
    "    max_water = 0\n",
    "    \n",
    "    while left < right:\n",
    "        # Largeur * hauteur minimum\n",
    "        width = right - left\n",
    "        height = min(heights[left], heights[right])\n",
    "        max_water = max(max_water, width * height)\n",
    "        \n",
    "        # Déplacer le pointeur avec la plus petite hauteur\n",
    "        if heights[left] < heights[right]:\n",
    "            left += 1\n",
    "        else:\n",
    "            right -= 1\n",
    "    \n",
    "    return max_water\n",
    "\n",
    "# Test\n",
    "print(max_area([1,8,6,2,5,4,8,3,7]))  # 49\n",
    "\n",
    "--> IDEE DANS UN TWO POINTERS CEST WHILE LEFT < RIGHT NSUITE ON DEFINIT LA LOGIQUE DEVOLUTION DE LEFT ET RIGHT\n",
    "\n",
    "# Trier strings par fréquence puis alphabétiquement\n",
    "from collections import Counter\n",
    "s = \"tree\"\n",
    "sorted(s, key=lambda x: (-Counter(s)[x], x))  # ['e', 'e', 'r', 't']\n",
    "\n",
    "# Pattern classique TWO POINTERS\n",
    "def two_pointers(arr):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    \n",
    "    while left < right:\n",
    "        if condition:\n",
    "            left += 1\n",
    "        else:\n",
    "            right -= 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Exemple: palindrome\n",
    "def is_palindrome(s):\n",
    "    left, right = 0, len(s) - 1\n",
    "    while left < right:\n",
    "        if s[left] != s[right]:\n",
    "            return False\n",
    "        left += 1\n",
    "        right -= 1\n",
    "    return True\n",
    "\n",
    "# Pattern fenêtre fixe SLIDE WINDOW SOMME MAX DUN SOUS TABLEAU\n",
    "def fixed_window(arr, k):\n",
    "    window_sum = sum(arr[:k])  # première fenêtre\n",
    "    max_sum = window_sum\n",
    "    \n",
    "    for i in range(k, len(arr)):\n",
    "        window_sum += arr[i] - arr[i-k]  # ajouter nouveau, retirer ancien\n",
    "        max_sum = max(max_sum, window_sum)\n",
    "    \n",
    "    return max_sum\n",
    "\n",
    "# Pattern fenêtre variable\n",
    "def variable_window(s):\n",
    "    window = set()\n",
    "    left = 0\n",
    "    max_len = 0\n",
    "    \n",
    "    for right in range(len(s)):\n",
    "        while s[right] in window:\n",
    "            window.remove(s[left])\n",
    "            left += 1\n",
    "        \n",
    "        window.add(s[right])\n",
    "        max_len = max(max_len, right - left + 1)\n",
    "    \n",
    "    return max_len\n",
    "\n",
    "# Pattern prefix sum SOMME CUMULEE\n",
    "def prefix_sum(arr):\n",
    "    prefix = [0] * (len(arr) + 1)\n",
    "    for i in range(len(arr)):\n",
    "        prefix[i+1] = prefix[i] + arr[i]\n",
    "    return prefix\n",
    "\n",
    "# Range sum en O(1)\n",
    "def range_sum(prefix, left, right):\n",
    "    return prefix[right+1] - prefix[left]\n",
    "\n",
    "# Exemple complet\n",
    "arr = [1, 2, 3, 4, 5]\n",
    "prefix = prefix_sum(arr)  # [0, 1, 3, 6, 10, 15]\n",
    "print(range_sum(prefix, 1, 3))  # somme de arr[1:4] = 2+3+4 = 9\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#BINARY SEARCH \n",
    "def find_peak_element(nums):\n",
    "    \"\"\"\n",
    "    Trouver index d'un pic (élément > voisins).\n",
    "    Input: nums = [1,2,3,1]\n",
    "    Output: 2 (nums[2]=3 est un pic)\n",
    "    \"\"\"\n",
    "    left, right = 0, len(nums) - 1\n",
    "    \n",
    "    while left < right:\n",
    "        mid = (left + right) // 2\n",
    "        \n",
    "        if nums[mid] > nums[mid + 1]:\n",
    "            # Pic à gauche ou mid est le pic\n",
    "            right = mid\n",
    "        else:\n",
    "            # Pic à droite\n",
    "            left = mid + 1\n",
    "    \n",
    "    return left\n",
    "\n",
    "# Test\n",
    "print(find_peak_element([1, 2, 3, 1]))  # 2\n",
    "\n",
    "def my_sqrt(x):\n",
    "    \"\"\"\n",
    "    Calculer sqrt(x) tronqué à l'entier.\n",
    "    Input: x = 8\n",
    "    Output: 2 (sqrt(8) ≈ 2.828)\n",
    "    \"\"\"\n",
    "    if x < 2:\n",
    "        return x\n",
    "    \n",
    "    left, right = 2, x // 2\n",
    "    \n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        square = mid * mid\n",
    "        \n",
    "        if square == x:\n",
    "            return mid\n",
    "        elif square < x:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    \n",
    "    return right  # Plus grand entier dont le carré ≤ x\n",
    "\n",
    "# Tests\n",
    "print(my_sqrt(4))   # 2\n",
    "print(my_sqrt(8))   # 2\n",
    "print(my_sqrt(16))  # 4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ship_within_days(weights, days):\n",
    "    \"\"\"\n",
    "    Capacité minimum du bateau pour livrer en D jours.\n",
    "    Input: weights = [1,2,3,4,5,6,7,8,9,10], days = 5\n",
    "    Output: 15\n",
    "    \"\"\"\n",
    "    def can_ship(capacity):\n",
    "        \"\"\"Vérifier si on peut livrer avec cette capacité\"\"\"\n",
    "        days_needed = 1\n",
    "        current_load = 0\n",
    "        \n",
    "        for weight in weights:\n",
    "            if current_load + weight > capacity:\n",
    "                days_needed += 1\n",
    "                current_load = 0\n",
    "            current_load += weight\n",
    "        \n",
    "        return days_needed <= days\n",
    "    \n",
    "    # Binary search sur la capacité\n",
    "    left, right = max(weights), sum(weights)\n",
    "    \n",
    "    while left < right:\n",
    "        mid = (left + right) // 2\n",
    "        if can_ship(mid):\n",
    "            right = mid\n",
    "        else:\n",
    "            left = mid + 1\n",
    "    \n",
    "    return left\n",
    "\n",
    "# Test\n",
    "print(ship_within_days([1,2,3,4,5,6,7,8,9,10], 5))  # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0859b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magicalString(n): # MAGICAL STRING\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n <= 3:\n",
    "        return 1\n",
    "    \n",
    "    # La séquence magique commence toujours par [1, 2, 2]\n",
    "    s = [1, 2, 2]\n",
    "    \n",
    "    # 'index' lit la séquence pour savoir combien générer\n",
    "    # On commence à index=2 car on a déjà les 3 premiers\n",
    "    index = 2\n",
    "    \n",
    "    # 'num' est le chiffre à générer (alterne entre 1 et 2)\n",
    "    # Commence à 1 car après [1, 2, 2], on génère des 1\n",
    "    num = 1\n",
    "    \n",
    "    while len(s) < n:\n",
    "        # Lire le nombre de fois à générer depuis s[index]\n",
    "        count = s[index]\n",
    "        \n",
    "        # Générer 'count' fois le chiffre 'num'\n",
    "        for _ in range(count):\n",
    "            s.append(num)\n",
    "            \n",
    "            # Si on a atteint n éléments, arrêter\n",
    "            if len(s) == n:\n",
    "                break\n",
    "        \n",
    "        # Alterner entre 1 et 2\n",
    "        # Astuce : 3 - 1 = 2, et 3 - 2 = 1\n",
    "        num = 3 - num\n",
    "        \n",
    "        # Avancer dans la séquence pour la prochaine lecture\n",
    "        index += 1\n",
    "    \n",
    "    # Compter les '1' dans les n premiers éléments\n",
    "    return s[:n].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Parcourir la diagonale secondaire MATRICE CARRE I , N-1-I\n",
    "    for i in range(n):\n",
    "        # La diagonale secondaire : ligne i, colonne (n-1-i)\n",
    "        value = grid[i][n-1-i]\n",
    "        \n",
    "        \n",
    "def secondary_diagonal_min_max(grid):\n",
    "    # Vérifier si la matrice est vide\n",
    "    if not grid or not grid[0]:\n",
    "        return [None, None]\n",
    "    \n",
    "    n = len(grid)\n",
    "    \n",
    "    # Initialiser min et max avec le premier élément de la diagonale\n",
    "    min_val = grid[0][n-1]\n",
    "    max_val = grid[0][n-1]\n",
    "    \n",
    "    # Parcourir la diagonale secondaire\n",
    "    for i in range(n):\n",
    "        # La diagonale secondaire : ligne i, colonne (n-1-i)\n",
    "        value = grid[i][n-1-i]\n",
    "        \n",
    "        if value < min_val:\n",
    "            min_val = value\n",
    "        if value > max_val:\n",
    "            max_val = value\n",
    "    \n",
    "    return [min_val, max_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRICE SORTED COUNT NUMBER INF A TARGET en grand 0 de n+m\n",
    "def count_less_than(matrix, target):\n",
    "    n = len(matrix)\n",
    "    m = len(matrix[0])\n",
    "    \n",
    "    # Cas limites (optionnels, pas nécessaires)\n",
    "    if target > matrix[n-1][m-1]:\n",
    "        return n * m\n",
    "    if target <= matrix[0][0]:\n",
    "        return 0\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # Commencer en haut à droite\n",
    "    row = 0\n",
    "    col = m - 1\n",
    "    \n",
    "    while row < n and col >= 0:\n",
    "        if matrix[row][col] < target:\n",
    "            # Tous les éléments à gauche de cette position sont < target\n",
    "            count += (col + 1)\n",
    "            row += 1  # Descendre à la ligne suivante\n",
    "        else:\n",
    "            # L'élément est >= target, aller à gauche\n",
    "            col -= 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# MATRICE SORTED DONT ON CHERCHE UN ELEMENT TARGET DES QUON PARLE DE COMPLEXITE NE PAS PASSER PAR FOR MAIS UN ROW ET COLUMN \n",
    "def find_row_with_target(matrix, target):\n",
    "    if not matrix or not matrix[0]:\n",
    "        return None\n",
    "    \n",
    "    n = len(matrix)      # nombre de lignes\n",
    "    m = len(matrix[0])   # nombre de colonnes\n",
    "    \n",
    "    # Commencer en haut à droite\n",
    "    row = 0\n",
    "    col = m - 1\n",
    "    \n",
    "    while row < n and col >= 0:\n",
    "        if matrix[row][col] == target:\n",
    "            return row  # Target trouvé !\n",
    "        elif matrix[row][col] < target:\n",
    "            # Le target est plus grand, descendre\n",
    "            row += 1\n",
    "        else:\n",
    "            # Le target est plus petit, aller à gauche\n",
    "            col -= 1\n",
    "    \n",
    "    return None  # Target pas trouvé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Search dicotomie LOGIQUE while left <= right: SORTED\n",
    "\n",
    "class Solution:\n",
    "    def search(self, nums: List[int], target: int) -> int:\n",
    "        # Set the left and right boundaries\n",
    "        left = 0\n",
    "        right = len(nums) - 1 # dernier element\n",
    "        \n",
    "        # Under this condition\n",
    "        while left <= right:\n",
    "            # Get the middle index and the middle value.\n",
    "            mid = (left + right) // 2\n",
    "            \n",
    "            # Case 1, return the middle index.\n",
    "            if nums[mid] == target:\n",
    "                return mid\n",
    "            # Case 2, discard the smaller half.\n",
    "            elif nums[mid] < target:\n",
    "                left = mid + 1                 \n",
    "            # Case 3, discard the larger half.         \n",
    "            else:\n",
    "                right = mid - 1\n",
    "        \n",
    "        # If we finish the search without finding target, return -1.\n",
    "        return -1\n",
    "    \n",
    "# Variante: trouver position d'insertion Cette fonction trouve la position où insérer un target dans un tableau trié pour maintenir l'ordre.\n",
    "def search_insert(arr, target):\n",
    "    left, right = 0, len(arr) # pour permettre de mettre après le dernier élément\n",
    "    \n",
    "    while left < right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid\n",
    "    \n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6b8cac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n",
      "dict_keys(['Pizza'])\n",
      "dict_keys(['Pizza', 'Burger'])\n",
      "dict_keys(['Pizza', 'Burger', 'Pasta'])\n",
      "dict_keys(['Pizza', 'Burger', 'Pasta', 'Frenchfries'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Burger'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hashmap pour faire de la recherche dans une liste set avec element in set\n",
    "\n",
    "arr = [\"Pizza\", \"Burger\", \"Pasta\",\"Frenchfries\", \"Burger\"]\n",
    "\n",
    "def solution(arr):\n",
    "    # TODO: Implement the solution here\n",
    "    n = len(arr)\n",
    "    \n",
    "    set = {}\n",
    "    \n",
    "    for i, element in enumerate(arr):\n",
    "        print(set.keys())\n",
    "        if element in set:\n",
    "            return element\n",
    "        else : \n",
    "            set[element] = i\n",
    "    \n",
    "\n",
    "             \n",
    "    return ''\n",
    "\n",
    "solution(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727117e5",
   "metadata": {},
   "source": [
    "You are given an array of integers and an integer k. Your task is to determine whether there are two distinct indices, i and j, in the array such that nums[i] = nums[j] and the absolute difference between i and j is at most k. Return True if such a pair exists and False if not.\n",
    "\n",
    "The expected time complexity is \n",
    "O\n",
    "(\n",
    "n\n",
    ")\n",
    "O(n), where \n",
    "n\n",
    "n is the length of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51e8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0 1\n",
      "{1: 0}\n",
      "1 2\n",
      "{1: 0, 2: 1}\n",
      "2 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair i j d'élement tel que leur num fasse la même chose  et qu'il soit séparé d'une distance DAU MOINS k erreur AU MOINS \n",
    "\n",
    "nums = [1,2,2,2,4]\n",
    "\n",
    "k = 2\n",
    "\n",
    "def solution(nums, k):\n",
    "    \n",
    "    if len(nums)<= 1:\n",
    "        return False\n",
    "        \n",
    "    set = {}\n",
    "    \n",
    "    for i,element in enumerate(nums):\n",
    "        print(set)\n",
    "        print(i, element)\n",
    "        if element in set and abs(set[element]-i) <= k: # AU MOINS\n",
    "            return True\n",
    "        else: \n",
    "            set[element] = i\n",
    "        \n",
    "\n",
    "    return False\n",
    "    \n",
    "solution(nums, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3cdbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two sums hash map pour complexity en grand O de n \n",
    "\n",
    "class Solution:\n",
    "    def twoSum(self, nums: List[int], target: int) -> List[int]:\n",
    "        hashmap = {}\n",
    "        for i in range(len(nums)):\n",
    "            hashmap[nums[i]] = i\n",
    "        for i in range(len(nums)):\n",
    "            complement = target - nums[i]\n",
    "            if complement in hashmap and hashmap[complement] != i:\n",
    "                return [i, hashmap[complement]]\n",
    "        # If no valid pair is found, return an empty list\n",
    "        return []\n",
    "    \n",
    "class Solution:\n",
    "    def twoSum(self, nums: List[int], target: int) -> List[int]:\n",
    "        test = 0\n",
    "\n",
    "        for index, element in enumerate(nums):\n",
    "            test = target - element\n",
    "\n",
    "            if test in nums and index != nums.index(test):\n",
    "                return [index, nums.index(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "83077cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "b = [2,3]\n",
    "b.index(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoSum(self, nums: List[int], target: int) -> List[int]:\n",
    "    hashmap = {}\n",
    "    for i in range(len(nums)):\n",
    "        hashmap[nums[i]] = i\n",
    "    for i in range(len(nums)):\n",
    "        complement = target - nums[i]\n",
    "        if complement in hashmap and hashmap[complement] != i:\n",
    "            return [i, hashmap[complement]]\n",
    "    # If no valid pair is found, return an empty list\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae50b9",
   "metadata": {},
   "source": [
    "Question: Write a Python function that takes a list of integers and returns a new list with only the unique elements from the original list, but in the same order they first appeared. You should not use any additional libraries like pandas or numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_elements(nums):\n",
    "\n",
    "    seen = set()\n",
    "\n",
    "    unique = []\n",
    "\n",
    "    for num in nums:\n",
    "\n",
    "        if num not in seen:\n",
    "\n",
    "            unique.append(num)\n",
    "\n",
    "            seen.add(num)\n",
    "\n",
    "    return unique\n",
    "\n",
    "# Example usage\n",
    "\n",
    "print(unique_elements([1, 2, 2, 3, 4, 3, 1, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb771042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a Python function that takes a list of integers and returns a new list containing only the prime numbers from the original list.\n",
    "\n",
    "\n",
    "def num_is_prime(n):\n",
    "    if n ==0 or n == 1:\n",
    "        return False\n",
    "    if n % 2 == 0 and n != 2 : \n",
    "        return False \n",
    "    for i in range(3,int(n**0.5) + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "num_is_prime(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruojnoB\n",
      "ruojnoB\n"
     ]
    }
   ],
   "source": [
    "def fizzbuzz(n=100):\n",
    "    for i in range(1, n + 1):\n",
    "        if i % 3 == 0 and i % 5 == 0:\n",
    "            print(\"FizzBuzz\")\n",
    "        elif i % 3 == 0:\n",
    "            print(\"Fizz\")\n",
    "        elif i % 5 == 0:\n",
    "            print(\"Buzz\")\n",
    "        else:\n",
    "            print(i)\n",
    "\n",
    "# Test\n",
    "#fizzbuzz()\n",
    "\n",
    "def reverse_string(s):\n",
    "    return s[::-1]  # Méthode Pythonique\n",
    "\n",
    "# Ou sans slicing (plus algorithmique) AVEC TWO POINTERSS\n",
    "def reverse_string_manual(s):\n",
    "    chars = list(s)\n",
    "    left, right = 0, len(chars) - 1\n",
    "    while left < right:\n",
    "        chars[left], chars[right] = chars[right], chars[left]\n",
    "        left += 1\n",
    "        right -= 1\n",
    "    return ''.join(chars)\n",
    "\n",
    "# Test\n",
    "print(reverse_string(\"Bonjour\"))           # \"ruojnoB\"\n",
    "print(reverse_string_manual(\"Bonjour\"))    # \"ruojnoB\"\n",
    "\n",
    "def fibonacci(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    elif n == 1:\n",
    "        return [0]\n",
    "    \n",
    "    fib = [0, 1]\n",
    "    for i in range(2, n):\n",
    "        fib.append(fib[-1] + fib[-2])\n",
    "    return fib\n",
    "\n",
    "# Test\n",
    "print(fibonacci(10))  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
    "\n",
    "def is_palindrome(s):\n",
    "    reversed_s = s[::-1]\n",
    "        return s == reversed_s\n",
    "\n",
    "def count_palindromic_substrings(s):\n",
    "count = 0\n",
    "    for i in range(len(s)):\n",
    "        for j in range(i, len(s)):\n",
    "            if s[i:j+1] == s[i:j+1][::-1]:\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03455f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANAGRAM\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def is_anagram(s1, s2):\n",
    "    return Counter(s1) == Counter(s2)\n",
    "\n",
    "def is_anagram(s1, s2):\n",
    "    if len(s1) != len(s2):\n",
    "        return False\n",
    "    \n",
    "    # Compter les occurrences de chaque caractère\n",
    "    hash = {}\n",
    "    for char in s1:\n",
    "        hash[char] = hash.get(char, 0) + 1\n",
    "    \n",
    "    # Décrémenter pour chaque caractère de s2\n",
    "    for char in s2:\n",
    "        if char in hash:  # Check les clés\n",
    "            hash[char] -= 1\n",
    "            if hash[char] < 0:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "s1 = 'cat'\n",
    "s2 = 'tac'\n",
    "is_anagram(s1,s2)\n",
    "\n",
    "\n",
    "# LIST DANAGRAMME ASTUCE POUR LES GROUPER MEME SIGNATURE SORTED DONC ON LES METS DANS UN HASH de [] list\n",
    "\n",
    "def find_anagrams(strs):\n",
    "    # Dictionnaire pour grouper les anagrammes\n",
    "    # Clé : version triée de la chaîne\n",
    "    # Valeur : liste des chaînes qui sont des anagrammes\n",
    "    anagram_groups = {}\n",
    "    \n",
    "    # Parcourir chaque chaîne\n",
    "    for s in strs:  # O(n)\n",
    "        # Trier les caractères de la chaîne pour créer une clé unique\n",
    "        sorted_str = ''.join(sorted(s)) # O(m log m)\n",
    "        print(sorted_str)\n",
    "        \n",
    "        # Ajouter la chaîne au groupe correspondant\n",
    "        if sorted_str not in anagram_groups:\n",
    "            anagram_groups[sorted_str] = []\n",
    "        anagram_groups[sorted_str].append(s)\n",
    "    \n",
    "    # Convertir le dictionnaire en liste de listes\n",
    "    result = []\n",
    "    for group in anagram_groups.values():\n",
    "        # Trier chaque groupe lexicographiquement\n",
    "        group.sort()  # O(k log k) où k est la taille du groupe\n",
    "        result.append(group)\n",
    "    \n",
    "    # Trier la liste finale par le premier élément de chaque sous-liste\n",
    "    result.sort(key=lambda x: x[0])  # O(n log n) dans le pire cas\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f33808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOMME DE DEUX ELEMENTS DANS A OU DANS B \n",
    "\n",
    "def sum_pairs(a, b, num):\n",
    "    count = 0\n",
    "    \n",
    "    # Créer un dictionnaire pour compter les occurrences des éléments de 'a'\n",
    "    freq_a = {}\n",
    "    for element in a:\n",
    "        freq_a[element] = freq_a.get(element, 0) + 1\n",
    "    \n",
    "    # Pour chaque élément de 'b', chercher son complément dans 'a'\n",
    "    for element in b:\n",
    "        complement = num - element\n",
    "        if complement in freq_a:\n",
    "            count += freq_a[complement]\n",
    "            \n",
    "    return count\n",
    "\n",
    "a , b , num = ([1, 2, 1, 1, 1], [9, 9, 9, 9, 9], 10)\n",
    "sum_pairs(a,b,num)\n",
    "\n",
    "\n",
    "# two sums\n",
    "def two_sum(nums, target):\n",
    "    # Dictionnaire pour stocker : {valeur: index}\n",
    "    hash = {}\n",
    "    \n",
    "    # Parcourir le tableau\n",
    "    for i in range(len(nums)):\n",
    "        # Calculer le complément nécessaire\n",
    "        complement = target - nums[i]\n",
    "        \n",
    "        # Vérifier si le complément existe déjà dans le hash\n",
    "        if complement in hash:\n",
    "            # Retourner les indices\n",
    "            return [hash[complement], i]\n",
    "        \n",
    "        # Ajouter l'élément actuel au hash\n",
    "        hash[nums[i]] = i\n",
    "    \n",
    "    # Aucune solution trouvée\n",
    "    return []\n",
    "\n",
    "\n",
    "# NOMBRE OCCURENCE QUE NUM AVEC DISTANCE DE K  DE PAIRE DISTINC\n",
    "def count_pairs_with_diff_k(nums, k):\n",
    "    hash = {}\n",
    "    count = 0\n",
    "    \n",
    "    # Compter la fréquence de chaque nombre\n",
    "    for num in nums:\n",
    "        hash[num] = hash.get(num, 0) + 1\n",
    "    # Parcourir les clés uniques du hash\n",
    "    for num in hash:\n",
    "        # Vérifier si num + k existe dans le hash\n",
    "        if num + k in hash :\n",
    "            count += hash[num]*hash[num+k]\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13340b",
   "metadata": {},
   "source": [
    "Write a Python script using matplotlib to create a bar chart that compares the average monthly sales data for two years. The sales data for each month should be represented as two bars side by side, one for each year. Include labels for each month, add a legend to differentiate between the two years, and title the chart ‘Comparison of Monthly Sales’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24cc536c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "sales_2020 = [200, 180, 240, 300, 280, 350, 370, 360, 390, 420, 450, 470]\n",
    "\n",
    "sales_2021 = [210, 190, 250, 310, 290, 360, 380, 370, 400, 430, 460, 480]\n",
    "\n",
    "# Creating the bar chart\n",
    "\n",
    "x = range(len(months))  # the label locations\n",
    "\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "rects1 = ax.bar(x, sales_2020, width, label='2020')\n",
    "\n",
    "rects2 = ax.bar([p + width for p in x], sales_2021, width, label='2021')\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "\n",
    "ax.set_ylabel('Sales')\n",
    "\n",
    "ax.set_title('Comparison of Monthly Sales')\n",
    "\n",
    "ax.set_xticks([p + width / 2 for p in x])\n",
    "\n",
    "ax.set_xticklabels(months)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "# Function to add labels on bars\n",
    "\n",
    "def autolabel(rects, ax):\n",
    "\n",
    "    for rect in rects:\n",
    "\n",
    "        height = rect.get_height()\n",
    "\n",
    "        ax.annotate('{}'.format(height),\n",
    "\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "\n",
    "                    textcoords=\"offset points\",\n",
    "\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1, ax)\n",
    "\n",
    "autolabel(rects2, ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65ae4cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             fare   age\n",
      "class                  \n",
      "First   84.154687  37.0\n",
      "Second  20.662183  29.0\n",
      "Third   13.675550  24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/x11w534x6fx5843q4r1vdmtc0000gp/T/ipykernel_59786/914613944.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  class_aggregated = titanic.groupby('class').agg({\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# TODO: Group by 'class' and calculate mean fare and median age\n",
    "\n",
    "class_aggregated = titanic.groupby('class').agg({\n",
    "    'fare' : 'mean',\n",
    "    'age'  : 'median'\n",
    "    \n",
    "})\n",
    "\n",
    "print(class_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "3\n",
      "7\n",
      "15\n",
      "31\n",
      "63\n",
      "127\n",
      "255\n",
      "511\n",
      "1023\n",
      "2047\n",
      "4095\n",
      "8191\n",
      "16383\n",
      "32767\n",
      "65535\n",
      "131071\n",
      "262143\n",
      "524287\n",
      "1048575\n",
      "-2\n",
      "-1\n",
      "1\n",
      "5\n",
      "13\n",
      "29\n",
      "61\n",
      "125\n",
      "253\n",
      "509\n",
      "1021\n",
      "2045\n",
      "4093\n",
      "8189\n",
      "16381\n",
      "32765\n",
      "65533\n",
      "131069\n",
      "262141\n",
      "524285\n",
      "1048573\n",
      "-4\n",
      "-3\n",
      "-1\n",
      "3\n",
      "11\n",
      "27\n",
      "59\n",
      "123\n",
      "251\n",
      "507\n",
      "1019\n",
      "2043\n",
      "4091\n",
      "8187\n",
      "16379\n",
      "32763\n",
      "65531\n",
      "131067\n",
      "262139\n",
      "524283\n",
      "1048571\n",
      "-6\n",
      "-5\n",
      "-3\n",
      "1\n",
      "9\n",
      "25\n",
      "57\n",
      "121\n",
      "249\n",
      "505\n",
      "1017\n",
      "2041\n",
      "4089\n",
      "8185\n",
      "16377\n",
      "32761\n",
      "65529\n",
      "131065\n",
      "262137\n",
      "524281\n",
      "1048569\n",
      "-8\n",
      "-7\n",
      "-5\n",
      "-1\n",
      "7\n",
      "23\n",
      "55\n",
      "119\n",
      "247\n",
      "503\n",
      "1015\n",
      "2039\n",
      "4087\n",
      "8183\n",
      "16375\n",
      "32759\n",
      "65527\n",
      "131063\n",
      "262135\n",
      "524279\n",
      "1048567\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def solution(numbers):\n",
    "   counts = defaultdict(int)\n",
    "   answer = 0\n",
    "   for element in numbers:\n",
    "       counts[element] += 1\n",
    "       for two_power in range(21):\n",
    "           second_element = (1 << two_power) - element #  a << n = a * 2**n\n",
    "           print(second_element)\n",
    "           answer += counts[second_element]\n",
    "   return answer \n",
    "\n",
    "numbers = [1, 3, 5, 7, 9]\n",
    "print(solution(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f83814",
   "metadata": {},
   "source": [
    "You have a pandas DataFrame df containing three years of hourly sales data with columns ‘Date_Time’ (datetime) and ‘Sales’ (float). Write a Python code snippet to resample this data to a weekly format and compute the total sales and average sales per week.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ea760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and loaded with data\n",
    "\n",
    "# Ensure 'Date_Time' column is in datetime format\n",
    "\n",
    "df['Date_Time'] = pd.to_datetime(df['Date_Time'])\n",
    "\n",
    "# Set 'Date_Time' as the DataFrame index\n",
    "\n",
    "df.set_index('Date_Time', inplace=True)\n",
    "\n",
    "# Resample data to weekly, calculate sum and mean of 'Sales'\n",
    "\n",
    "weekly_sales = df.resample('W').agg({'Sales': ['sum', 'mean']})\n",
    "\n",
    "# Renaming columns for clarity\n",
    "\n",
    "weekly_sales.columns = ['Total_Weekly_Sales', 'Average_Weekly_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68db216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  order_date  month\n",
      "0 2023-12-25     12\n",
      "1 2024-01-15      1\n",
      "2 2024-01-20      1\n",
      "3 2024-02-01      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample sales data with various date formats\n",
    "data = {\n",
    "    'order_date': ['2023-12-25', 'Jan 15, 2024', '2024-01-20', 'February 1, 2024']\n",
    "}\n",
    "sales = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'order_date' to datetime\n",
    "sales['order_date'] = pd.to_datetime(sales['order_date'], format='mixed')\n",
    "\n",
    "# Extract month from datetime and create a new column 'month'\n",
    "sales['month'] = sales['order_date'].dt.month\n",
    "\n",
    "print(sales)\n",
    "\n",
    "# Sales data with date information\n",
    "data = {'order_date': ['2023/01/05', '2023/02/15', '2023/03/10']}\n",
    "sales = pd.DataFrame(data)\n",
    "\n",
    "# TODO: Convert 'order_date' to datetime format\n",
    "\n",
    "sales['order_date'] = pd.to_datetime(sales['order_date'], format='mixed')\n",
    "\n",
    "# Extract month from 'order_date' \n",
    "sales['month'] = sales['order_date'].dt.month\n",
    "# TODO: Calculate days since each order date and put it into a separate days_since_order column\n",
    "current_date = datetime.now()  #CURRENT DATETIME\n",
    "sales['days_since_order'] = current_date - sales['order_date']\n",
    "\n",
    "print(sales)\n",
    "\n",
    "\n",
    "# transfomrer une string date en datetime \n",
    "\n",
    "reference_date = pd.to_datetime('2023-10-05')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc476a7d",
   "metadata": {},
   "source": [
    "Question 1: Using basic TensorFlow operations\n",
    "Prompt: Demonstrate how to create a TensorFlow constant tensor and a variable tensor. Perform a basic arithmetic operation (like addition) between them and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edafdaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Creating a constant and a variable tensor\n",
    "const_tensor = tf.constant([1, 2, 3])\n",
    "var_tensor = tf.Variable([4, 5, 6])\n",
    "# Performing addition\n",
    "result = const_tensor + var_tensor\n",
    "print(result.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc447d4",
   "metadata": {},
   "source": [
    "Using TensorFlow, create a simple neural network model to classify handwritten digits (you can use the MNIST dataset). Describe the model architecture, compile the model, and outline the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# Normalize the images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "# Building the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# Compiling the model\n",
    "model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Training the model\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "# Evaluate the model\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9335d8",
   "metadata": {},
   "source": [
    "Prompt: Write a custom loss function in TensorFlow and demonstrate how to use it in training a model. Explain in what scenarios custom loss functions are necessary and how they are integrated into the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Custom loss function\n",
    "def custom_loss_function(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "# Example model (could be any model)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(input_shape,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# Compile the model with the custom loss function\n",
    "model.compile(optimizer='adam', loss=custom_loss_function)\n",
    "# Train the model\n",
    "# model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def process_data(df_sales, df_customers):\n",
    "    merged = pd.merge(df_sales, df_customers, on='customer_id')\n",
    "    return merged.groupby('region')['total'].sum().reset_index()\n",
    "\n",
    "# Exemple ML basique (linear regression)\n",
    "import numpy as np\n",
    "def linear_regression(x, y):\n",
    "    m = np.cov(x, y)[0,1] / np.var(x)\n",
    "    b = np.mean(y) - m * np.mean(x)\n",
    "    return lambda input: m * input + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47833a",
   "metadata": {},
   "source": [
    "# Tetris pattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(field, figure):\n",
    "   height = len(field)\n",
    "   width = len(field[0])\n",
    "   figure_size = len(figure)\n",
    " \n",
    "   for column in range(width - figure_size + 1):\n",
    "       row = 1\n",
    "       while row < height - figure_size + 1:\n",
    "           can_fit = True\n",
    "           for dx in range(figure_size):\n",
    "               for dy in range(figure_size):\n",
    "                   if field[row + dx][column + dy] == 1 and figure[dx][dy] == 1:\n",
    "                       can_fit = False\n",
    "           if not can_fit:\n",
    "               break\n",
    "           row += 1\n",
    "       row -= 1\n",
    " \n",
    "       for dx in range(figure_size):\n",
    "           row_filled = True\n",
    "           for column_index in range(width):\n",
    "            if not (field[row + dx][column_index] == 1 or\n",
    "                    (column <= column_index < column + figure_size and\n",
    "                  figure[dx][column_index - column] == 1)):\n",
    "                row_filled = False\n",
    "           if row_filled:\n",
    "               return column\n",
    "   return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4637f2f",
   "metadata": {},
   "source": [
    "# Exo prépa BCG COde signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c41ea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "nums = [1, 2, 3, 4, 5]\n",
    "target = 4\n",
    "for element in nums :\n",
    "    if element < target :\n",
    "        count += element\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0954d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world hello\n"
     ]
    }
   ],
   "source": [
    "s = 'hello world'\n",
    "\n",
    "\n",
    "l = ' '.join((s.split())[::-1])\n",
    "print(l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e4cb0",
   "metadata": {},
   "source": [
    "Énoncé:\n",
    "Étant donné un array nums contenant n nombres distincts pris dans la range [0, n], trouver le seul nombre manquant dans cette range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565b732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "8\n",
      "0 0\n",
      "0 1\n",
      "1 2\n",
      "1 3\n",
      "2 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sol(nums):\n",
    "    hash = {}\n",
    "\n",
    "    lis = [x for x in range(len(nums)+1)]\n",
    "    print(lis)\n",
    "    for i,element in enumerate(nums):\n",
    "        hash[element] = i\n",
    "    \n",
    "    for element in lis:\n",
    "        if element not in hash :\n",
    "            return(element)\n",
    "\n",
    "    \n",
    "nums = [9,6,4,2,3,5,7,0,1]\n",
    "print(sol(nums))\n",
    "\n",
    "def solution(nums):\n",
    "    \"\"\"\n",
    "    Trouver le nombre manquant dans [0, n].\n",
    "    \"\"\"\n",
    "    n = len(nums)\n",
    "    \n",
    "    # Somme attendue: 0 + 1 + 2 + ... + n\n",
    "    expected_sum = n * (n + 1) // 2\n",
    "    \n",
    "    # Somme actuelle\n",
    "    actual_sum = sum(nums)\n",
    "    \n",
    "    # Le manquant\n",
    "    return expected_sum - actual_sum\n",
    "\n",
    "# Étant donné un array d'entiers `nums`, déplacer tous les `0` à la fin en gardant l'ordre relatif des éléments non-zéro. Modification **IN PLACE** (sans créer nouveau array).\n",
    "# Two pointers \n",
    "\n",
    "nums = [0, 1, 0, 3, 12]\n",
    "\n",
    "def sol2(nums):\n",
    "    \n",
    "    # Pointeur pour la position du prochain élément non-zéro\n",
    "    left = 0\n",
    "    \n",
    "    # Parcourir l'array\n",
    "    for right in range(len(nums)):\n",
    "        print(left, right)\n",
    "        if nums[right] != 0:\n",
    "            # Swap avec position left\n",
    "            nums[left], nums[right] = nums[right], nums[left]\n",
    "            left += 1\n",
    "    \n",
    "    return nums  # Pour les tests (pas nécessaire car in-place)\n",
    "\n",
    "sol2(nums)\n",
    "\n",
    "# Étant donné un array d'entiers `nums`, retourner `True` si une valeur apparaît au moins deux fois, `False` si tous les éléments sont distincts.\n",
    "\n",
    "nums = [1, 2, 3, 4]\n",
    "\n",
    "def sol3(nums):\n",
    "    from collections import Counter \n",
    "\n",
    "    dico = Counter(nums)\n",
    "\n",
    "    for element in dico.values():\n",
    "        if element > 1:\n",
    "            return True\n",
    "    return False\n",
    "    # Méthode 2: Plus concise avec un set \n",
    "    return len(nums) != len(set(nums))\n",
    "    seen = set()\n",
    "    for num in nums:\n",
    "        if num in seen:\n",
    "            return True\n",
    "        seen.add(num)\n",
    "    return False\n",
    "sol3(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver la longueur du plus long substring sans caractères répétés dans une string `s`.*\n",
    "# Utiliser sliding window avec un set pour tracker les caractères uniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040dceb1",
   "metadata": {},
   "source": [
    "# Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3165d4",
   "metadata": {},
   "source": [
    "Question: How do you decide which machine learning model to use for a specific problem? For instance, how would you approach a dataset predicting customer churn?\n",
    "\n",
    "Sample answer: When deciding on a model, I start by considering the nature of the data, the problem type (classification or regression), and the interpretability required by stakeholders. Predicting customer churn is a binary classification problem, so I might start with logistic regression for its simplicity and interpretability. I would also consider tree-based models like Random Forest or Gradient Boosting Machines for their robustness and ability to handle non-linear relationships. I typically compare a few models based on their performance metrics like accuracy, ROC-AUC, and F1-score, and validate them using techniques like cross-validation before making a final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936dec76",
   "metadata": {},
   "source": [
    "Question: What strategies do you employ to prevent overfitting in a machine learning model?\n",
    "\n",
    "Sample answer: To prevent overfitting, I use several techniques depending on the model and data. First, I might split the data into training, validation, and test sets to monitor and prevent overfitting during model training. Regularization methods such as L1 or L2 regularization are also effective, especially in regression models. For decision trees, I control overfitting by setting limits on tree depth, minimum samples per leaf, and other parameters. And ensemble methods like bagging and boosting can reduce overfitting by building more robust models from multiple learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a930a",
   "metadata": {},
   "source": [
    "Question: Describe how you evaluate the performance of a machine learning model. Can you give an example of how you’ve applied these evaluation techniques in a past project?\n",
    "\n",
    "Sample answer: I evaluate machine learning models using several key performance metrics. For classification tasks, I look at accuracy, precision, recall, F1-score, and the ROC-AUC curve. For regression, I consider metrics like RMSE and MAE. In a past project aimed at predicting real estate prices, I used RMSE to measure the average error between the predicted prices and the actual prices. I also used cross-validation to ensure that the model’s performance was consistent across different subsets of the data. These metrics helped us fine-tune the model iteratively, which led to more reliable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5adc6",
   "metadata": {},
   "source": [
    "Question: Can you describe how you would use AI to improve the predictive analytics process within a company? Specifically, how would AI enhance the accuracy and efficiency of forecasting models?\n",
    "\n",
    "Sample answer: AI can significantly enhance predictive analytics by incorporating more complex algorithms, such as deep learning, that are capable of identifying non-linear relationships and interactions that traditional models might miss. For instance, I would use recurrent neural networks (RNNs) or LSTM (Long Short-Term Memory) networks for forecasting sales data, as they are particularly good with sequences and can predict based on the historical data trends. Additionally, AI can automate the feature engineering process, using techniques like feature selection and dimensionality reduction to improve model accuracy and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd09ed",
   "metadata": {},
   "source": [
    "Question: You are tasked with designing a data collection strategy for a new app that tracks user interactions with various features. What factors would you consider when deciding what data to collect, and how would you ensure the data remains manageable and useful for analysis?\n",
    "\n",
    "Sample answer: When designing a data collection strategy for the app, I would first identify the key metrics that align with our business objectives, such as user engagement times, frequency of feature use, and user feedback scores. I would ensure that the data collected is both relevant and sufficient to inform decision-making without collecting unnecessary information that could complicate processing and storage. To keep the data manageable, I would implement a schema that organizes data into structured formats and use automation tools to clean and preprocess the data as it comes in. This could involve setting up pipelines that automatically remove duplicates, handle missing values, and ensure data integrity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1cca1",
   "metadata": {},
   "source": [
    "Question: You receive a dataset containing customer transaction data over the past year. The dataset is incomplete with numerous missing values and some duplicate entries. How would you go about cleaning this data to prepare it for analysis?\n",
    "\n",
    "Sample answer: To clean the dataset, I would first assess the extent and nature of the missing values. For categorical data, I might impute missing values using the mode or a predictive model, whereas for numerical data, I might use mean, median, or regression imputation, depending on the distribution and the amount of missing data. To address duplicates, I would identify unique transaction identifiers or a combination of variables (like date, time, and customer ID) that can confirm a transaction’s uniqueness. I would then remove duplicates based on these identifiers. After handling missing values and duplicates, I would validate the data for consistency and accuracy, ensuring that all data types are correct and that there are no illogical data entries, such as negative transaction amounts. To do this, I’d use both automated scripts for bulk cleaning and manual checks for nuanced errors. Finally, I’d document the cleaning process to allow for reproducibility and maintain a clean dataset for future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b71a3",
   "metadata": {},
   "source": [
    "Question: Could you describe a scenario where a Poisson distribution would be more appropriate to model an event than a normal distribution? How would you apply this in a data-driven decision-making process?\n",
    "\n",
    "Sample answer: A Poisson distribution is ideal for modeling the number of times an event happens in a fixed interval of time or space when these events occur with a known constant mean rate and independently of the time since the last event. For example, it could model the number of users visiting a website per minute. This differs from a normal distribution, which is used for continuous data and where we’re looking at the distribution of means rather than actual event counts. In a business context, I’d use Poisson to predict customer arrivals or fault rates in a time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3a8f9",
   "metadata": {},
   "source": [
    "Question: Imagine you’re tasked with evaluating the effectiveness of two different marketing campaigns. What statistical test would you use to determine which campaign was more successful, and why?\n",
    "\n",
    "Sample answer: To evaluate the effectiveness of two marketing campaigns, I would use a hypothesis test, specifically an independent samples t-test, if the data is normally distributed. This test compares the means of two independent groups in order to determine whether there is statistical evidence that the associated population means are significantly different. I would set up the null hypothesis to assume no difference between the campaigns’ effects, and the alternative hypothesis to indicate a significant difference. The result would inform whether any observed difference in campaign performance is statistically significant or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe3b45",
   "metadata": {},
   "source": [
    "Question: Can you walk me through how you would design an A/B test for a new product feature on a website? What steps would you take to ensure the results are statistically significant?\n",
    "\n",
    "Sample answer: When designing an A/B test for a new product feature, I would start by defining clear metrics of success, such as conversion rate or user engagement time. I would then randomly assign users to two groups, ensuring each has a similar demographic makeup. The test would run long enough to collect sufficient data, using statistical power calculations to determine this duration. Lastly, I’d analyze the results using a hypothesis test—such as a chi-square test or a t-test, depending on the distribution and nature of the data—to determine if there’s a statistically significant difference between the two groups’ performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f0ca5",
   "metadata": {},
   "source": [
    "Question: After running an A/B test on two different email marketing campaigns, Campaign A resulted in a 15% click-through rate (CTR) while Campaign B resulted in a 10% CTR. What conclusions can you draw from these results, and what would be your next steps?\n",
    "\n",
    "Sample answer: From the results of the A/B test, it appears that Campaign A performed better than Campaign B. This suggests that the elements or messaging used in Campaign A were more effective in engaging users and encouraging them to click on the links provided. My next steps would be to analyze the specific components of Campaign A to understand what drove the higher engagement, such as the email subject line, graphics, or call-to-action. I would also recommend further testing to confirm these results over multiple iterations and different user segments to ensure that the observed difference wasn’t due to external factors or variances in the audience groups. If the results remain consistent, I would consider applying the successful elements of Campaign A to other marketing materials and strategies to potentially improve overall marketing effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce27c4",
   "metadata": {},
   "source": [
    "# Audrey extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64794b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Poppler trouvé !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Pour Mac avec Homebrew (M1/M2/M3)\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/opt/homebrew/bin\"\n",
    "\n",
    "# OU pour Mac Intel\n",
    "# os.environ[\"PATH\"] += os.pathsep + \"/usr/local/bin\"\n",
    "\n",
    "# Vérifier que poppler est accessible\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['pdftoppm', '-h'], capture_output=True)\n",
    "    print(\"✅ Poppler trouvé !\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Poppler non trouvé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2137ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🚀 EXTRACTION ET INSERTION AUTOMATIQUE DES DOCUMENTS PORTFOLIO\n",
      "======================================================================\n",
      "\n",
      "📋 ÉTAPE 1: EXTRACTION DES PAGES PDF\n",
      "----------------------------------------------------------------------\n",
      "📄 Conversion du PDF 'audrey_extract/SICAF one-pager 06.11.25 v2.pdf' en images...\n",
      "  ✓ Page 1 sauvegardée: extracted_pages/page_1.png\n",
      "  ✂️  Recadrage des bords blancs: page_1.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2541)\n",
      "  ✓ Page 2 sauvegardée: extracted_pages/page_2.png\n",
      "  ✂️  Recadrage des bords blancs: page_2.png\n",
      "     → Image recadrée: (2481, 3508) → (2079, 2557)\n",
      "  ✓ Page 3 sauvegardée: extracted_pages/page_3.png\n",
      "  ✂️  Recadrage des bords blancs: page_3.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2617)\n",
      "  ✓ Page 4 sauvegardée: extracted_pages/page_4.png\n",
      "  ✂️  Recadrage des bords blancs: page_4.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 5 sauvegardée: extracted_pages/page_5.png\n",
      "  ✂️  Recadrage des bords blancs: page_5.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2539)\n",
      "  ✓ Page 6 sauvegardée: extracted_pages/page_6.png\n",
      "  ✂️  Recadrage des bords blancs: page_6.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 7 sauvegardée: extracted_pages/page_7.png\n",
      "  ✂️  Recadrage des bords blancs: page_7.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 8 sauvegardée: extracted_pages/page_8.png\n",
      "  ✂️  Recadrage des bords blancs: page_8.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2501)\n",
      "  ✓ Page 9 sauvegardée: extracted_pages/page_9.png\n",
      "  ✂️  Recadrage des bords blancs: page_9.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 10 sauvegardée: extracted_pages/page_10.png\n",
      "  ✂️  Recadrage des bords blancs: page_10.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 11 sauvegardée: extracted_pages/page_11.png\n",
      "  ✂️  Recadrage des bords blancs: page_11.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 12 sauvegardée: extracted_pages/page_12.png\n",
      "  ✂️  Recadrage des bords blancs: page_12.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 13 sauvegardée: extracted_pages/page_13.png\n",
      "  ✂️  Recadrage des bords blancs: page_13.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 14 sauvegardée: extracted_pages/page_14.png\n",
      "  ✂️  Recadrage des bords blancs: page_14.png\n",
      "     → Image recadrée: (2481, 3508) → (2088, 2590)\n",
      "  ✓ Page 15 sauvegardée: extracted_pages/page_15.png\n",
      "  ✂️  Recadrage des bords blancs: page_15.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 16 sauvegardée: extracted_pages/page_16.png\n",
      "  ✂️  Recadrage des bords blancs: page_16.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2539)\n",
      "  ✓ Page 17 sauvegardée: extracted_pages/page_17.png\n",
      "  ✂️  Recadrage des bords blancs: page_17.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 18 sauvegardée: extracted_pages/page_18.png\n",
      "  ✂️  Recadrage des bords blancs: page_18.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2558)\n",
      "  ✓ Page 19 sauvegardée: extracted_pages/page_19.png\n",
      "  ✂️  Recadrage des bords blancs: page_19.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "  ✓ Page 20 sauvegardée: extracted_pages/page_20.png\n",
      "  ✂️  Recadrage des bords blancs: page_20.png\n",
      "     → Image recadrée: (2481, 3508) → (2071, 2590)\n",
      "\n",
      "✅ 20 pages extraites avec succès!\n",
      "\n",
      "\n",
      "🔍 ÉTAPE 2: IDENTIFICATION DES SOCIÉTÉS\n",
      "----------------------------------------------------------------------\n",
      "🤖 Analyse de l'image avec Mistral: page_1.png\n",
      "  ✅ Société identifiée: ENERGY DOME\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_2.png\n",
      "  ✅ Société identifiée: CIRCULAR MATERIALS\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_3.png\n",
      "  ✅ Société identifiée: SKILLVUE\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_4.png\n",
      "  ✅ Société identifiée: TUNDR\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_5.png\n",
      "  ✅ Société identifiée: RESILCO\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_6.png\n",
      "  ✅ Société identifiée: KAMPAAY\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_7.png\n",
      "  ✅ Société identifiée: GUIDOIO\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_8.png\n",
      "  ✅ Société identifiée: INGAGE\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_9.png\n",
      "  ✅ Société identifiée: MOVOPACK\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_10.png\n",
      "  ✅ Société identifiée: NEWTWEN\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_11.png\n",
      "  ✅ Société identifiée: SOOURCE\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_12.png\n",
      "  ✅ Société identifiée: NEURONOVA\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_13.png\n",
      "  ✅ Société identifiée: JAMPY\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_14.png\n",
      "  ✅ Société identifiée: PHONONIC VIBES\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_15.png\n",
      "  ✅ Société identifiée: ZEFI\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_16.png\n",
      "  ✅ Société identifiée: ISAAC\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_17.png\n",
      "  ✅ Société identifiée: TALENTWARE\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_18.png\n",
      "  ✅ Société identifiée: VOIDLESS\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_19.png\n",
      "  ✅ Société identifiée: EQUIXLY\n",
      "\n",
      "🤖 Analyse de l'image avec Mistral: page_20.png\n",
      "  ✅ Société identifiée: CASAVO\n",
      "\n",
      "\n",
      "📊 RÉSUMÉ DES IDENTIFICATIONS:\n",
      "----------------------------------------------------------------------\n",
      "  • ENERGY DOME: page_1.png\n",
      "  • CIRCULAR MATERIALS: page_2.png\n",
      "  • SKILLVUE: page_3.png\n",
      "  • TUNDR: page_4.png\n",
      "  • RESILCO: page_5.png\n",
      "  • KAMPAAY: page_6.png\n",
      "  • GUIDOIO: page_7.png\n",
      "  • INGAGE: page_8.png\n",
      "  • MOVOPACK: page_9.png\n",
      "  • NEWTWEN: page_10.png\n",
      "  • SOOURCE: page_11.png\n",
      "  • NEURONOVA: page_12.png\n",
      "  • JAMPY: page_13.png\n",
      "  • PHONONIC VIBES: page_14.png\n",
      "  • ZEFI: page_15.png\n",
      "  • ISAAC: page_16.png\n",
      "  • TALENTWARE: page_17.png\n",
      "  • VOIDLESS: page_18.png\n",
      "  • EQUIXLY: page_19.png\n",
      "  • CASAVO: page_20.png\n",
      "\n",
      "📝 ÉTAPE 3: INSERTION DANS LE DOCUMENT WORD (1 SOCIÉTÉ PAR PAGE)\n",
      "----------------------------------------------------------------------\n",
      "📝 Ouverture du document Word: 'Reporting SICAF - Q3 2025 v3.docx'\n",
      "\n",
      "✓ Section '4.3 Current Portfolio' trouvée au paragraphe 171\n",
      "  → Sommaire détecté (paragraphe 172), IGNORÉ\n",
      "  → Zone détails détectée (paragraphe 201)\n",
      "  → Société trouvée dans détails: ENERGY DOME au paragraphe 201\n",
      "  → Société trouvée dans détails: CIRCULAR MATERIALS au paragraphe 202\n",
      "  → Société trouvée dans détails: SKILLVUE au paragraphe 203\n",
      "  → Société trouvée dans détails: TUNDR au paragraphe 204\n",
      "  → Société trouvée dans détails: RESILCO au paragraphe 205\n",
      "  → Société trouvée dans détails: KAMPAAY au paragraphe 206\n",
      "  → Société trouvée dans détails: GUIDOIO au paragraphe 207\n",
      "  → Société trouvée dans détails: INGAGE au paragraphe 208\n",
      "  → Société trouvée dans détails: MOVOPACK au paragraphe 209\n",
      "  → Société trouvée dans détails: NEWTWEN au paragraphe 210\n",
      "  → Société trouvée dans détails: SOOURCE au paragraphe 211\n",
      "  → Société trouvée dans détails: NEURONOVA au paragraphe 212\n",
      "  → Société trouvée dans détails: JAMPY au paragraphe 213\n",
      "  → Société trouvée dans détails: PHONONIC VIBES au paragraphe 214\n",
      "  → Société trouvée dans détails: ZEFI au paragraphe 215\n",
      "  → Société trouvée dans détails: ISAAC au paragraphe 216\n",
      "  → Société trouvée dans détails: TALENTWARE au paragraphe 217\n",
      "  → Société trouvée dans détails: VOIDLESS au paragraphe 218\n",
      "  → Société trouvée dans détails: EQUIXLY au paragraphe 219\n",
      "  → Société trouvée dans détails: CASAVO au paragraphe 220\n",
      "\n",
      "📊 20 sociétés trouvées dans la zone détails\n",
      "  ✅ Image insérée pour CASAVO\n",
      "     → Dernière société, pas de saut de page\n",
      "  ✅ Image insérée pour EQUIXLY\n",
      "     → Saut de page ajouté après EQUIXLY\n",
      "  ✅ Image insérée pour VOIDLESS\n",
      "     → Saut de page ajouté après VOIDLESS\n",
      "  ✅ Image insérée pour TALENTWARE\n",
      "     → Saut de page ajouté après TALENTWARE\n",
      "  ✅ Image insérée pour ISAAC\n",
      "     → Saut de page ajouté après ISAAC\n",
      "  ✅ Image insérée pour ZEFI\n",
      "     → Saut de page ajouté après ZEFI\n",
      "  ✅ Image insérée pour PHONONIC VIBES\n",
      "     → Saut de page ajouté après PHONONIC VIBES\n",
      "  ✅ Image insérée pour JAMPY\n",
      "     → Saut de page ajouté après JAMPY\n",
      "  ✅ Image insérée pour NEURONOVA\n",
      "     → Saut de page ajouté après NEURONOVA\n",
      "  ✅ Image insérée pour SOOURCE\n",
      "     → Saut de page ajouté après SOOURCE\n",
      "  ✅ Image insérée pour NEWTWEN\n",
      "     → Saut de page ajouté après NEWTWEN\n",
      "  ✅ Image insérée pour MOVOPACK\n",
      "     → Saut de page ajouté après MOVOPACK\n",
      "  ✅ Image insérée pour INGAGE\n",
      "     → Saut de page ajouté après INGAGE\n",
      "  ✅ Image insérée pour GUIDOIO\n",
      "     → Saut de page ajouté après GUIDOIO\n",
      "  ✅ Image insérée pour KAMPAAY\n",
      "     → Saut de page ajouté après KAMPAAY\n",
      "  ✅ Image insérée pour RESILCO\n",
      "     → Saut de page ajouté après RESILCO\n",
      "  ✅ Image insérée pour TUNDR\n",
      "     → Saut de page ajouté après TUNDR\n",
      "  ✅ Image insérée pour SKILLVUE\n",
      "     → Saut de page ajouté après SKILLVUE\n",
      "  ✅ Image insérée pour CIRCULAR MATERIALS\n",
      "     → Saut de page ajouté après CIRCULAR MATERIALS\n",
      "  ✅ Image insérée pour ENERGY DOME\n",
      "     → Saut de page ajouté après ENERGY DOME\n",
      "\n",
      "✅ Document sauvegardé: 'Reporting_Final_Avec_Documents_finalfinal.docx'\n",
      "✅ 20 image(s) insérée(s) dans la zone détails\n",
      "✅ Format: 1 société par page\n",
      "\n",
      "======================================================================\n",
      "✅ PROCESSUS TERMINÉ AVEC SUCCÈS!\n",
      "======================================================================\n",
      "\n",
      "📄 Document final: Reporting_Final_Avec_Documents_finalfinal.docx\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script intelligent pour extraire des pages PDF et les insérer automatiquement\n",
    "dans le document Word sous la bonne société du portfolio\n",
    "VERSION AMÉLIORÉE : avec recadrage d'images et une société par page v3\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_BREAK\n",
    "from mistralai import Mistral\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "\n",
    "# ========================================================================\n",
    "# CONFIGURATION\n",
    "# ========================================================================\n",
    "POPPLER_PATH = \"/opt/homebrew/bin\"  # Mac M1/M2/M3\n",
    "\n",
    "# Configuration Mistral\n",
    "MISTRAL_API_KEY = \"X7DpYENEsRkosAnYZJbd6exXoUDhETWy\"\n",
    "MISTRAL_MODEL = \"mistral-medium-latest\"\n",
    "MISTRAL_SERVER_URL = \"https://api.05d3a00300de.dc.mistral.ai\"\n",
    "\n",
    "# Configuration du recadrage\n",
    "CROP_MARGIN = 20  # Pixels à garder autour du contenu (pour éviter de trop couper)\n",
    "\n",
    "# Liste des sociétés du portfolio\n",
    "COMPANIES = [\n",
    "    \"CASAVO\",\n",
    "    \"SKILLVUE\",\n",
    "    \"TUNDR\",\n",
    "    \"ENERGY DOME\",\n",
    "    \"CIRCULAR MATERIALS\",\n",
    "    \"RESILCO\",\n",
    "    \"KAMPAAY\",\n",
    "    \"MOVOPACK\",\n",
    "    \"NEWTWEN\",\n",
    "    \"SOOURCE\",\n",
    "    \"NEURONOVA\",\n",
    "    \"JAMPY\",\n",
    "    \"ZEFI\",\n",
    "    \"ISAAC\",\n",
    "    \"GUIDOIO\",\n",
    "    \"TALENTWARE\",\n",
    "    \"VOIDLESS\",\n",
    "    \"EQUIXLY\",\n",
    "    \"PHONONIC VIBES\",\n",
    "    \"INGAGE\"\n",
    "]\n",
    "# ========================================================================\n",
    "\n",
    "\n",
    "def crop_white_borders(image_path, output_path=None, margin=20):\n",
    "    \"\"\"\n",
    "    Recadre les bords blancs d'une image\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin de l'image source\n",
    "        output_path: Chemin de l'image recadrée (si None, écrase l'original)\n",
    "        margin: Pixels à garder autour du contenu\n",
    "    \n",
    "    Returns:\n",
    "        Chemin de l'image recadrée\n",
    "    \"\"\"\n",
    "    print(f\"  ✂️  Recadrage des bords blancs: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    # Ouvrir l'image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Convertir en RGB si nécessaire\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    \n",
    "    # Créer un fond blanc de la même taille\n",
    "    bg = Image.new('RGB', img.size, (255, 255, 255))\n",
    "    \n",
    "    # Calculer la différence entre l'image et le fond blanc\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    \n",
    "    # Trouver la bounding box du contenu (non-blanc)\n",
    "    bbox = diff.getbbox()\n",
    "    \n",
    "    if bbox:\n",
    "        # Ajouter une marge\n",
    "        left = max(0, bbox[0] - margin)\n",
    "        top = max(0, bbox[1] - margin)\n",
    "        right = min(img.width, bbox[2] + margin)\n",
    "        bottom = min(img.height, bbox[3] + margin)\n",
    "        \n",
    "        # Recadrer l'image\n",
    "        cropped = img.crop((left, top, right, bottom))\n",
    "        \n",
    "        # Sauvegarder\n",
    "        if output_path is None:\n",
    "            output_path = image_path\n",
    "        cropped.save(output_path, 'PNG', quality=95)\n",
    "        \n",
    "        print(f\"     → Image recadrée: {img.size} → {cropped.size}\")\n",
    "    else:\n",
    "        print(f\"     → Pas de recadrage nécessaire\")\n",
    "        if output_path and output_path != image_path:\n",
    "            img.save(output_path, 'PNG', quality=95)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "def extract_pdf_pages_to_png(pdf_path, output_folder=\"extracted_pages\", poppler_path=None, crop_images=True):\n",
    "    \"\"\"Extrait chaque page d'un PDF en images PNG et les recadre\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    print(f\"📄 Conversion du PDF '{pdf_path}' en images...\")\n",
    "    \n",
    "    if poppler_path:\n",
    "        images = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "    else:\n",
    "        images = convert_from_path(pdf_path, dpi=300)\n",
    "    \n",
    "    png_paths = []\n",
    "    for i, image in enumerate(images, start=1):\n",
    "        png_path = os.path.join(output_folder, f\"page_{i}.png\")\n",
    "        image.save(png_path, \"PNG\")\n",
    "        print(f\"  ✓ Page {i} sauvegardée: {png_path}\")\n",
    "        \n",
    "        # Recadrer l'image si demandé\n",
    "        if crop_images:\n",
    "            crop_white_borders(png_path, margin=CROP_MARGIN)\n",
    "        \n",
    "        png_paths.append(png_path)\n",
    "    \n",
    "    print(f\"\\n✅ {len(png_paths)} pages extraites avec succès!\\n\")\n",
    "    return png_paths\n",
    "\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"Convertit une image en base64\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def identify_company_with_mistral(image_path, companies_list):\n",
    "    \"\"\"\n",
    "    Utilise Mistral pour identifier de quelle société il s'agit\n",
    "    \"\"\"\n",
    "    print(f\"🤖 Analyse de l'image avec Mistral: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialiser le client Mistral\n",
    "        client = Mistral(\n",
    "            server_url=MISTRAL_SERVER_URL,\n",
    "            api_key=MISTRAL_API_KEY\n",
    "        )\n",
    "        \n",
    "        # Convertir l'image en base64\n",
    "        image_base64 = image_to_base64(image_path)\n",
    "        \n",
    "        # Préparer le prompt\n",
    "        companies_str = \", \".join(companies_list)\n",
    "        prompt = f\"\"\"Analyse cette image d'un document de reporting financier d'une startup.\n",
    "\n",
    "Cette image concerne l'une de ces sociétés du portfolio : {companies_str}\n",
    "\n",
    "Ta mission : identifier précisément de quelle société il s'agit en cherchant le nom de la société dans l'image (généralement en haut du document, dans le logo, ou dans un titre).\n",
    "\n",
    "INSTRUCTIONS CRITIQUES :\n",
    "1. Cherche le nom de la société dans le document (titre, logo, en-tête)\n",
    "2. Compare-le avec la liste ci-dessus\n",
    "3. Réponds UNIQUEMENT avec le nom EXACT tel qu'il apparaît dans ma liste ci-dessus\n",
    "4. Si le nom a des espaces (exemple: \"ENERGY DOME\"), garde les espaces\n",
    "5. N'ajoute AUCUNE explication, ponctuation ou texte supplémentaire\n",
    "6. Réponds en MAJUSCULES\n",
    "\n",
    "Exemples de bonnes réponses :\n",
    "- ENERGY DOME\n",
    "- CIRCULAR MATERIALS\n",
    "- PHONONIC VIBES\n",
    "\n",
    "Si tu ne trouves aucun nom de société de la liste dans l'image, réponds uniquement \"UNKNOWN\".\"\"\"\n",
    "\n",
    "        # Appel à Mistral avec vision\n",
    "        response = client.chat.complete(\n",
    "            model=MISTRAL_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": f\"data:image/png;base64,{image_base64}\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Récupérer la réponse\n",
    "        company = response.choices[0].message.content.strip().upper()\n",
    "        \n",
    "        # Nettoyer la réponse (enlever ponctuation, espaces multiples, etc.)\n",
    "        company = company.replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").strip()\n",
    "        company = \" \".join(company.split())  # Normaliser les espaces\n",
    "        \n",
    "        # Normaliser aussi la liste des sociétés pour la comparaison\n",
    "        companies_normalized = {c.upper().replace(\" \", \"\"): c for c in companies_list}\n",
    "        company_normalized = company.replace(\" \", \"\")\n",
    "        \n",
    "        # Vérifier correspondance exacte (sans espaces)\n",
    "        if company_normalized in companies_normalized:\n",
    "            matched_company = companies_normalized[company_normalized]\n",
    "            print(f\"  ✅ Société identifiée: {matched_company}\\n\")\n",
    "            return matched_company\n",
    "        \n",
    "        # Vérifier correspondance exacte (avec espaces)\n",
    "        if company in companies_list:\n",
    "            print(f\"  ✅ Société identifiée: {company}\\n\")\n",
    "            return company\n",
    "        \n",
    "        # Correspondance partielle\n",
    "        print(f\"  ⚠️  Réponse de Mistral: '{company}' - Non reconnue dans la liste\")\n",
    "        print(f\"  ℹ️  Tentative de correspondance partielle...\")\n",
    "        \n",
    "        # Essayer de trouver une correspondance partielle (version flexible)\n",
    "        for comp in companies_list:\n",
    "            comp_normalized = comp.upper().replace(\" \", \"\")\n",
    "            # Si le nom normalisé de la société est contenu dans la réponse\n",
    "            if comp_normalized in company_normalized or company_normalized in comp_normalized:\n",
    "                print(f\"  ✅ Correspondance trouvée: {comp}\\n\")\n",
    "                return comp\n",
    "            # Essayer aussi avec les espaces\n",
    "            if comp.upper() in company or company in comp.upper():\n",
    "                print(f\"  ✅ Correspondance trouvée: {comp}\\n\")\n",
    "                return comp\n",
    "        \n",
    "        print(f\"  ❌ Aucune correspondance trouvée\\n\")\n",
    "        return \"UNKNOWN\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erreur Mistral: {str(e)}\\n\")\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "def identify_company_manual(image_path, companies_list):\n",
    "    \"\"\"\n",
    "    Méthode manuelle: demande à l'utilisateur d'identifier la société\n",
    "    \"\"\"\n",
    "    print(f\"\\n📷 Image: {image_path}\")\n",
    "    print(f\"Sociétés disponibles: {', '.join(companies_list)}\")\n",
    "    \n",
    "    while True:\n",
    "        company = input(\"Entrez le nom de la société (ou 'skip' pour ignorer): \").strip().upper()\n",
    "        if company == 'SKIP':\n",
    "            return \"UNKNOWN\"\n",
    "        if company in companies_list:\n",
    "            return company\n",
    "        print(f\"❌ '{company}' n'est pas dans la liste. Réessayez.\")\n",
    "\n",
    "\n",
    "def insert_images_by_company_one_per_page(template_path, output_path, images_mapping, width_inches=6.5):\n",
    "    \"\"\"\n",
    "    Insère les images dans le document Word : UNE SOCIÉTÉ PAR PAGE\n",
    "    Ignore le sommaire (liste à puces) et insère uniquement dans la zone détails\n",
    "    \n",
    "    Args:\n",
    "        template_path: Chemin du document Word template\n",
    "        output_path: Chemin du document de sortie\n",
    "        images_mapping: Dict {company_name: image_path}\n",
    "        width_inches: Largeur des images en pouces\n",
    "    \"\"\"\n",
    "    print(f\"📝 Ouverture du document Word: '{os.path.basename(template_path)}'\")\n",
    "    doc = Document(template_path)\n",
    "    \n",
    "    insertions_made = 0\n",
    "    section_found = False\n",
    "    sommaire_zone = False\n",
    "    detail_zone = False\n",
    "    companies_in_details = []\n",
    "    \n",
    "    # Étape 1: Identifier les zones et les sociétés dans la zone détails\n",
    "    for para_idx, paragraph in enumerate(doc.paragraphs):\n",
    "        text = paragraph.text.strip().upper()\n",
    "        \n",
    "        # Détecter la section 4.3\n",
    "        if '4.3' in text and 'PORTFOLIO' in text:\n",
    "            section_found = True\n",
    "            print(f\"\\n✓ Section '4.3 Current Portfolio' trouvée au paragraphe {para_idx}\")\n",
    "            continue\n",
    "        \n",
    "        if section_found:\n",
    "            # Détecter le début du sommaire (liste à puces)\n",
    "            is_bullet = paragraph.style.name.startswith('List')\n",
    "            is_bold = any(run.bold for run in paragraph.runs)\n",
    "            \n",
    "            if is_bullet and not sommaire_zone and not detail_zone:\n",
    "                sommaire_zone = True\n",
    "                print(f\"  → Sommaire détecté (paragraphe {para_idx}), IGNORÉ\")\n",
    "                continue\n",
    "            \n",
    "            # Dans la zone sommaire, on ignore\n",
    "            if sommaire_zone and not detail_zone:\n",
    "                if not is_bullet:\n",
    "                    # Premier paragraphe non-bullet après le sommaire = début de la zone détails\n",
    "                    # Il peut être en gras ou non, l'important c'est qu'il ne soit plus une bullet\n",
    "                    if text and len(text) < 50:\n",
    "                        # Fin du sommaire, début de la zone détails\n",
    "                        detail_zone = True\n",
    "                        sommaire_zone = False\n",
    "                        print(f\"  → Zone détails détectée (paragraphe {para_idx})\")\n",
    "                        # Ne pas continuer, traiter ce paragraphe comme un titre\n",
    "                else:\n",
    "                    continue  # On ignore le sommaire\n",
    "            \n",
    "            # Dans la zone détails, on identifie les titres de sociétés\n",
    "            if detail_zone:\n",
    "                # Arrêter si on arrive à une autre section\n",
    "                if text and any(text.startswith(str(i)) for i in range(1, 10)) and '.' in text[:5]:\n",
    "                    print(f\"  → Fin de la section détectée au paragraphe {para_idx}\")\n",
    "                    break\n",
    "                \n",
    "                # Identifier les titres de sociétés (MAJUSCULES, court, dans la liste)\n",
    "                # Note: on ne vérifie PAS le gras car tous les titres ne le sont pas\n",
    "                if text and len(text) < 50 and text in [comp.upper() for comp in COMPANIES]:\n",
    "                    company_name = text\n",
    "                    if company_name in images_mapping:\n",
    "                        companies_in_details.append({\n",
    "                            'name': company_name,\n",
    "                            'para_idx': para_idx,\n",
    "                            'paragraph': paragraph\n",
    "                        })\n",
    "                        print(f\"  → Société trouvée dans détails: {company_name} au paragraphe {para_idx}\")\n",
    "    \n",
    "    print(f\"\\n📊 {len(companies_in_details)} sociétés trouvées dans la zone détails\")\n",
    "    \n",
    "    # Étape 2: Insérer les images (en ordre inverse pour ne pas décaler les indices)\n",
    "    # Mais on garde la logique des sauts de page en ordre normal\n",
    "    for position, company_info in enumerate(reversed(companies_in_details)):\n",
    "        company_name = company_info['name']\n",
    "        para = company_info['paragraph']\n",
    "        \n",
    "        # Calculer la position réelle (non inversée) pour les sauts de page\n",
    "        real_position = len(companies_in_details) - 1 - position\n",
    "        \n",
    "        if company_name in images_mapping:\n",
    "            image_path = images_mapping[company_name]\n",
    "            \n",
    "            # Créer un nouveau paragraphe pour l'image juste après le nom\n",
    "            new_paragraph = doc.add_paragraph()\n",
    "            ref_p_element = para._element\n",
    "            new_p_element = new_paragraph._element\n",
    "            new_p_element.getparent().remove(new_p_element)\n",
    "            ref_p_element.addnext(new_p_element)\n",
    "            \n",
    "            # Ajouter l'image\n",
    "            run = new_paragraph.add_run()\n",
    "            run.add_picture(image_path, width=Inches(width_inches))\n",
    "            \n",
    "            print(f\"  ✅ Image insérée pour {company_name}\")\n",
    "            insertions_made += 1\n",
    "            \n",
    "            # Ajouter un saut de page APRÈS l'image\n",
    "            # SAUF pour la dernière société (real_position == len - 1)\n",
    "            if real_position < len(companies_in_details) - 1:\n",
    "                # Créer un paragraphe vide avec un saut de page\n",
    "                page_break_para = doc.add_paragraph()\n",
    "                pb_p_element = page_break_para._element\n",
    "                pb_p_element.getparent().remove(pb_p_element)\n",
    "                new_p_element.addnext(pb_p_element)\n",
    "                \n",
    "                # Ajouter le saut de page\n",
    "                run_pb = page_break_para.add_run()\n",
    "                run_pb.add_break(WD_BREAK.PAGE)\n",
    "                \n",
    "                print(f\"     → Saut de page ajouté après {company_name}\")\n",
    "            else:\n",
    "                print(f\"     → Dernière société, pas de saut de page\")\n",
    "    \n",
    "    # Sauvegarder le document\n",
    "    doc.save(output_path)\n",
    "    print(f\"\\n✅ Document sauvegardé: '{output_path}'\")\n",
    "    print(f\"✅ {insertions_made} image(s) insérée(s) dans la zone détails\")\n",
    "    print(f\"✅ Format: 1 société par page\")\n",
    "    \n",
    "    # Afficher les sociétés sans image\n",
    "    companies_with_images = set(images_mapping.keys())\n",
    "    companies_in_doc_names = set(c['name'] for c in companies_in_details)\n",
    "    companies_without_images = companies_in_doc_names - companies_with_images\n",
    "    if companies_without_images:\n",
    "        print(f\"\\n⚠️  Sociétés sans image: {', '.join(companies_without_images)}\")\n",
    "\n",
    "\n",
    "def main(use_mistral=True, crop_images=True):\n",
    "    \"\"\"\n",
    "    Fonction principale\n",
    "    \n",
    "    Args:\n",
    "        use_mistral: Si True, utilise Mistral pour l'identification automatique\n",
    "        crop_images: Si True, recadre les images pour enlever les bords blancs\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🚀 EXTRACTION ET INSERTION AUTOMATIQUE DES DOCUMENTS PORTFOLIO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Configuration\n",
    "    pdf_path = \"audrey_extract/SICAF one-pager 06.11.25 v2.pdf\"\n",
    "    template_word = \"audrey_extract/Reporting SICAF - Q3 2025 v3.docx\"\n",
    "    output_word = \"Reporting_Final_Avec_Documents_finalfinal.docx\"\n",
    "    \n",
    "    # Étape 1: Extraire les pages du PDF\n",
    "    print(\"\\n📋 ÉTAPE 1: EXTRACTION DES PAGES PDF\")\n",
    "    print(\"-\" * 70)\n",
    "    png_images = extract_pdf_pages_to_png(pdf_path, poppler_path=POPPLER_PATH, crop_images=crop_images)\n",
    "    \n",
    "    # Étape 2: Identifier les sociétés sur chaque image\n",
    "    print(\"\\n🔍 ÉTAPE 2: IDENTIFICATION DES SOCIÉTÉS\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    images_mapping = {}  # {company_name: image_path}\n",
    "    \n",
    "    for image_path in png_images:\n",
    "        if use_mistral:\n",
    "            company = identify_company_with_mistral(image_path, COMPANIES)\n",
    "        else:\n",
    "            company = identify_company_manual(image_path, COMPANIES)\n",
    "        \n",
    "        if company != \"UNKNOWN\":\n",
    "            images_mapping[company] = image_path\n",
    "        else:\n",
    "            print(f\"  ⏭️  Image ignorée: {os.path.basename(image_path)}\\n\")\n",
    "    \n",
    "    # Afficher le résumé\n",
    "    print(\"\\n📊 RÉSUMÉ DES IDENTIFICATIONS:\")\n",
    "    print(\"-\" * 70)\n",
    "    if images_mapping:\n",
    "        for company, image in images_mapping.items():\n",
    "            print(f\"  • {company}: {os.path.basename(image)}\")\n",
    "    else:\n",
    "        print(\"  ⚠️  Aucune image n'a été associée à une société\")\n",
    "        print(\"  💡 Conseil: Vérifiez que les noms des sociétés sont visibles dans les images\")\n",
    "        return\n",
    "    \n",
    "    # Étape 3: Insérer les images dans le document Word (1 par page)\n",
    "    print(\"\\n📝 ÉTAPE 3: INSERTION DANS LE DOCUMENT WORD (1 SOCIÉTÉ PAR PAGE)\")\n",
    "    print(\"-\" * 70)\n",
    "    insert_images_by_company_one_per_page(template_word, output_word, images_mapping, width_inches=6.5)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✅ PROCESSUS TERMINÉ AVEC SUCCÈS!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\n📄 Document final: {output_word}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Lancer avec Mistral automatique et recadrage d'images\n",
    "    main(use_mistral=True, crop_images=True)\n",
    "    \n",
    "    # OU sans recadrage:\n",
    "    # main(use_mistral=True, crop_images=False)\n",
    "    \n",
    "    # OU en mode manuel:\n",
    "    # main(use_mistral=False, crop_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "398ff58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[1, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "def solution(s):\n",
    "    voyel = ['a', 'e', 'i', 'o', 'u','y']\n",
    "    l = []\n",
    "    for i in range (len(s)):\n",
    "        if s[i].lower() in voyel:\n",
    "            l.append(i)\n",
    "    \n",
    "    return l    \n",
    "\n",
    "s = \"Hello WORLD\"\n",
    "print(len(s))\n",
    "print(solution(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4afe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Ifmmp XPSMA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def solution(s):\n",
    "    l = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    l_upper = l.upper()\n",
    "    result = []\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        if s[i] == 'z' : \n",
    "            result.append(\"a\")\n",
    "        elif s[i] == 'Z' : \n",
    "            result.append(\"A\")\n",
    "        elif s[i] in l:\n",
    "            result.append((l[l.index(s[i])+1]))\n",
    "            \n",
    "        elif s[i] in l_upper: \n",
    "            result.append((l_upper[l_upper.index(s[i])+1]))\n",
    "\n",
    "        else : \n",
    "            result.append(s[i]) \n",
    "\n",
    "    return ''.join(result)\n",
    "           \n",
    "s = \"Hello WORLZ\"\n",
    "print(len(s))\n",
    "print(solution(s))\n",
    "\n",
    "ord(char) retourne le code Unicode (un nombre entier) correspondant au caractère char.\n",
    "chr(nombre) fait l’inverse : il retourne le caractère correspondant au code Unicode donné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0dfc884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('Z')-ord('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9acbc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(input_string):\n",
    "    l = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    l_upper = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    \n",
    "    result = []\n",
    "    for element in input_string:\n",
    "        if element in l:\n",
    "            result.append(chr(ord(element)-32))\n",
    "        elif element in l_upper :\n",
    "            result.append(chr(ord(element)+32))\n",
    "        else : \n",
    "            result.append(element)\n",
    "            \n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fecb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_toeplitz(matrix: List[List[int]]) -> bool:\n",
    "   work = np.array(matrix) \n",
    "   for i in range(len(matrix)-1):\n",
    "      for j in range(len(matrix)-1):\n",
    "         if work[i,j]!=work[i+1,j+1]:\n",
    "            return False\n",
    "   return True     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51a67c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(12,1,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc5dbd",
   "metadata": {},
   "source": [
    "# Boddak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extraire_nom_prenom(dirigeant):\n",
    "    \"\"\"\n",
    "    Extrait le nom et le prénom d'une chaîne de dirigeant.\n",
    "    Formats possibles: \"Prénom Nom\", \"NOM Prénom\", \"Prénom NOM\"\n",
    "    \"\"\"\n",
    "    if pd.isna(dirigeant) or dirigeant == '':\n",
    "        return '', ''\n",
    "    \n",
    "    # Nettoyer la chaîne\n",
    "    dirigeant = str(dirigeant).strip()\n",
    "    \n",
    "    # Séparer par espaces\n",
    "    parties = dirigeant.split()\n",
    "    \n",
    "    if len(parties) == 0:\n",
    "        return '', ''\n",
    "    elif len(parties) == 1:\n",
    "        # Si un seul mot, on le met dans Surname\n",
    "        return '', parties[0]\n",
    "    else:\n",
    "        # Si plusieurs mots, on considère:\n",
    "        # - le premier mot comme prénom (Name)\n",
    "        # - le reste comme nom de famille (Surname)\n",
    "        prenom = parties[0]\n",
    "        nom = ' '.join(parties[1:])\n",
    "        return prenom, nom\n",
    "\n",
    "# Charger le CSV\n",
    "input_file = 'votre_fichier.csv'  # Remplacez par le nom de votre fichier\n",
    "output_file = 'fichier_transforme.csv'\n",
    "\n",
    "# Lire le CSV\n",
    "df = pd.read_csv(input_file, encoding='utf-8', sep=',', low_memory=False)\n",
    "\n",
    "# Extraire nom et prénom\n",
    "df['Name'] = ''\n",
    "df['Surname'] = ''\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    prenom, nom = extraire_nom_prenom(row['dirigeant'])\n",
    "    df.at[idx, 'Name'] = prenom\n",
    "    df.at[idx, 'Surname'] = nom\n",
    "\n",
    "# Créer les colonnes vides\n",
    "df['Linkedin_scaped_url'] = ''\n",
    "df['Notes'] = ''\n",
    "\n",
    "# Définir l'ordre des colonnes selon votre demande\n",
    "colonnes_finales = [\n",
    "    'siren', 'siret', 'type_etablissement', 'denomination', 'nom_commercial',\n",
    "    'nom_adressage', 'nom_enseigne', 'forme_juridique', 'statut_etablissement',\n",
    "    'statut_siege', 'risk_siege', 'risk_description', 'procedure_collective_en_cours',\n",
    "    'date_creation', 'date_cloture', 'dirigeant', 'Name', 'Surname',\n",
    "    'Linkedin_scaped_url', 'Notes', 'lien_fiche', 'dirigeant_role',\n",
    "    'dirigeant_role_date_debut', 'dirigeant_date_naissance', 'dirigeant_siren',\n",
    "    'code_ape', 'libelle_ape', 'code_convention_collective',\n",
    "    'libelle_convention_collective', 'nb_etablissements_actifs', 'rue',\n",
    "    'code_postal', 'ville', 'code_departement', 'longitude', 'lattitude',\n",
    "    'capital', 'categorie_insee', 'tva_intra'\n",
    "]\n",
    "\n",
    "# Sélectionner uniquement les colonnes qui existent dans le dataframe\n",
    "colonnes_existantes = [col for col in colonnes_finales if col in df.columns]\n",
    "\n",
    "# Créer le nouveau dataframe avec les colonnes sélectionnées\n",
    "df_final = df[colonnes_existantes]\n",
    "\n",
    "# Sauvegarder le résultat\n",
    "df_final.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Transformation terminée!\")\n",
    "print(f\"✓ Fichier sauvegardé : {output_file}\")\n",
    "print(f\"✓ Nombre de lignes : {len(df_final)}\")\n",
    "print(f\"✓ Nombre de colonnes : {len(df_final.columns)}\")\n",
    "print(f\"\\nAperçu des premières lignes :\")\n",
    "print(df_final[['dirigeant', 'Name', 'Surname']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97fb0c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263    https://ua.linkedin.com/in/Laetitiaamiault\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('name == \"Laëtitia Amiault\"')['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfaa226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>country_code</th>\n",
       "      <th>position</th>\n",
       "      <th>about</th>\n",
       "      <th>posts</th>\n",
       "      <th>current_company</th>\n",
       "      <th>experience</th>\n",
       "      <th>...</th>\n",
       "      <th>bio_links</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>input_first_name</th>\n",
       "      <th>input_last_name</th>\n",
       "      <th>error</th>\n",
       "      <th>error_code</th>\n",
       "      <th>warning</th>\n",
       "      <th>warning_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244</td>\n",
       "      <td>simon-wachter-814078225</td>\n",
       "      <td>Simon Wachter</td>\n",
       "      <td>Bordeaux, Nouvelle-Aquitaine, France</td>\n",
       "      <td>FR</td>\n",
       "      <td>Commercial en charge des boutiques en ligne - ...</td>\n",
       "      <td>Actuellement en apprentissage chez Full Ace Sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"name\":\"Full Ace Sport\",\"company_id\":\"fullace...</td>\n",
       "      <td>[{\"title\":\"Apprenti commercial\",\"location\":\"Mé...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Simon</td>\n",
       "      <td>Wachter</td>\n",
       "      <td>2025-11-05T14:15:45.901Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249</td>\n",
       "      <td>simon-wachter-6791b62bb</td>\n",
       "      <td>Simon WACHTER</td>\n",
       "      <td>Auvergne-Rhône-Alpes, France</td>\n",
       "      <td>FR</td>\n",
       "      <td>Étudiant à Lycee edgar quinet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"location\":null}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Simon</td>\n",
       "      <td>WACHTER</td>\n",
       "      <td>2025-11-05T14:15:54.653Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>simon-and-susan-wachter-3087b2142</td>\n",
       "      <td>Simon and Susan Wachter</td>\n",
       "      <td>Greater Angers Area</td>\n",
       "      <td>FR</td>\n",
       "      <td>Joint Owner at 5 Grande Rue, Chambre D'Hote</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"name\":\"5 Grande Rue, Chambre D'Hote\",\"title\"...</td>\n",
       "      <td>[{\"title\":\"Joint Owner\",\"description_html\":nul...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Simon</td>\n",
       "      <td>and Susan Wachter</td>\n",
       "      <td>2025-11-05T14:15:55.328Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262</td>\n",
       "      <td>robinlobel</td>\n",
       "      <td>Robin Lobel</td>\n",
       "      <td>Paris, Île-de-France, France</td>\n",
       "      <td>FR</td>\n",
       "      <td>Creator of audio software steinberg.net/spectr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"name\":\"TorchStudio.ai\",\"company_id\":\"torchst...</td>\n",
       "      <td>[{\"title\":\"Owner\",\"location\":\"Paris, Île-de-Fr...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Robin</td>\n",
       "      <td>Lobel</td>\n",
       "      <td>2025-11-05T14:16:03.777Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269</td>\n",
       "      <td>david-poisson-90b5962</td>\n",
       "      <td>David Poisson</td>\n",
       "      <td>Greater Paris Metropolitan Region</td>\n",
       "      <td>FR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"title\":\"Winning teams - from concept to rea...</td>\n",
       "      <td>{\"location\":null}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>David</td>\n",
       "      <td>Poisson</td>\n",
       "      <td>2025-11-05T14:16:05.095Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>272</td>\n",
       "      <td>david-poisson-a3061b5</td>\n",
       "      <td>David Poisson</td>\n",
       "      <td>Greater Paris Metropolitan Region</td>\n",
       "      <td>FR</td>\n",
       "      <td>IT BI Team Lead at Business Objects</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"link\":\"https://www.linkedin.com/company/sapb...</td>\n",
       "      <td>[{\"title\":\"IT BI Team Lead\",\"description_html\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>David</td>\n",
       "      <td>Poisson</td>\n",
       "      <td>2025-11-05T14:16:05.601Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                 id                     name  \\\n",
       "0    244            simon-wachter-814078225            Simon Wachter   \n",
       "1    249            simon-wachter-6791b62bb            Simon WACHTER   \n",
       "2    252  simon-and-susan-wachter-3087b2142  Simon and Susan Wachter   \n",
       "3    262                         robinlobel              Robin Lobel   \n",
       "4    269              david-poisson-90b5962            David Poisson   \n",
       "5    272              david-poisson-a3061b5            David Poisson   \n",
       "\n",
       "                                   city country_code  \\\n",
       "0  Bordeaux, Nouvelle-Aquitaine, France           FR   \n",
       "1          Auvergne-Rhône-Alpes, France           FR   \n",
       "2                   Greater Angers Area           FR   \n",
       "3          Paris, Île-de-France, France           FR   \n",
       "4     Greater Paris Metropolitan Region           FR   \n",
       "5     Greater Paris Metropolitan Region           FR   \n",
       "\n",
       "                                            position  \\\n",
       "0  Commercial en charge des boutiques en ligne - ...   \n",
       "1                      Étudiant à Lycee edgar quinet   \n",
       "2        Joint Owner at 5 Grande Rue, Chambre D'Hote   \n",
       "3  Creator of audio software steinberg.net/spectr...   \n",
       "4                                                NaN   \n",
       "5                IT BI Team Lead at Business Objects   \n",
       "\n",
       "                                               about  \\\n",
       "0  Actuellement en apprentissage chez Full Ace Sp...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                               posts  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  [{\"title\":\"Winning teams - from concept to rea...   \n",
       "5                                                NaN   \n",
       "\n",
       "                                     current_company  \\\n",
       "0  {\"name\":\"Full Ace Sport\",\"company_id\":\"fullace...   \n",
       "1                                  {\"location\":null}   \n",
       "2  {\"name\":\"5 Grande Rue, Chambre D'Hote\",\"title\"...   \n",
       "3  {\"name\":\"TorchStudio.ai\",\"company_id\":\"torchst...   \n",
       "4                                  {\"location\":null}   \n",
       "5  {\"link\":\"https://www.linkedin.com/company/sapb...   \n",
       "\n",
       "                                          experience  ... bio_links  \\\n",
       "0  [{\"title\":\"Apprenti commercial\",\"location\":\"Mé...  ...        []   \n",
       "1                                                NaN  ...        []   \n",
       "2  [{\"title\":\"Joint Owner\",\"description_html\":nul...  ...        []   \n",
       "3  [{\"title\":\"Owner\",\"location\":\"Paris, Île-de-Fr...  ...        []   \n",
       "4                                                NaN  ...        []   \n",
       "5  [{\"title\":\"IT BI Team Lead\",\"description_html\"...  ...        []   \n",
       "\n",
       "  first_name          last_name                 timestamp  input_first_name  \\\n",
       "0      Simon            Wachter  2025-11-05T14:15:45.901Z               NaN   \n",
       "1      Simon            WACHTER  2025-11-05T14:15:54.653Z               NaN   \n",
       "2      Simon  and Susan Wachter  2025-11-05T14:15:55.328Z               NaN   \n",
       "3      Robin              Lobel  2025-11-05T14:16:03.777Z               NaN   \n",
       "4      David            Poisson  2025-11-05T14:16:05.095Z               NaN   \n",
       "5      David            Poisson  2025-11-05T14:16:05.601Z               NaN   \n",
       "\n",
       "  input_last_name error error_code warning warning_code  \n",
       "0             NaN   NaN        NaN     NaN          NaN  \n",
       "1             NaN   NaN        NaN     NaN          NaN  \n",
       "2             NaN   NaN        NaN     NaN          NaN  \n",
       "3             NaN   NaN        NaN     NaN          NaN  \n",
       "4             NaN   NaN        NaN     NaN          NaN  \n",
       "5             NaN   NaN        NaN     NaN          NaN  \n",
       "\n",
       "[6 rows x 49 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datas/sd_mhm2y4ahta6bvw8jn.csv')\n",
    "df = df.query(\"country_code == 'FR' \").reset_index()\n",
    "df.iloc[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "956998a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [{\"title\":\"Apprenti commercial\",\"location\":\"Mé...\n",
       "1                                                    NaN\n",
       "2      [{\"title\":\"Joint Owner\",\"description_html\":nul...\n",
       "3      [{\"title\":\"Owner\",\"location\":\"Paris, Île-de-Fr...\n",
       "4                                                    NaN\n",
       "                             ...                        \n",
       "332    [{\"title\":\"Ingénieur du son\",\"description_html...\n",
       "333    [{\"title\":\"Chef d’équipe\",\"description_html\":n...\n",
       "334                                                  NaN\n",
       "335                                                  NaN\n",
       "336    [{\"title\":\"Conseillère Funéraire\",\"location\":\"...\n",
       "Name: experience, Length: 337, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5b28b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'id', 'name', 'city', 'country_code', 'position', 'about',\n",
       "       'posts', 'current_company', 'experience', 'url', 'people_also_viewed',\n",
       "       'educations_details', 'education', 'recommendations_count', 'avatar',\n",
       "       'courses', 'languages', 'certifications', 'recommendations',\n",
       "       'volunteer_experience', 'followers', 'connections',\n",
       "       'current_company_company_id', 'current_company_name', 'publications',\n",
       "       'patents', 'projects', 'organizations', 'location', 'input_url',\n",
       "       'linkedin_id', 'activity', 'linkedin_num_id', 'banner_image',\n",
       "       'honors_and_awards', 'similar_profiles', 'default_avatar',\n",
       "       'memorialized_account', 'bio_links', 'first_name', 'last_name',\n",
       "       'timestamp', 'input_first_name', 'input_last_name', 'error',\n",
       "       'error_code', 'warning', 'warning_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0006b9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://ch.linkedin.com/in/simon-wachter-81407...\n",
       "1      https://id.linkedin.com/in/Simon-wachter-6791b...\n",
       "2      https://ua.linkedin.com/in/Simon-and-susan-wac...\n",
       "3                  https://fr.linkedin.com/in/Robinlobel\n",
       "4       https://ph.linkedin.com/in/david-poisson-90b5962\n",
       "                             ...                        \n",
       "316    https://uk.linkedin.com/in/Antoine-d%E2%80%99h...\n",
       "317           https://at.linkedin.com/in/kamal-bencharki\n",
       "320         https://sg.linkedin.com/in/david-meyer-raedy\n",
       "331    https://cn.linkedin.com/in/Nicolas-pouyoune-97...\n",
       "335    https://ru.linkedin.com/in/Mohamed-addi-653276182\n",
       "Name: url, Length: 96, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['name'])\n",
    "df['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8fe06",
   "metadata": {},
   "source": [
    "# LSN pré filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a765722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/x11w534x6fx5843q4r1vdmtc0000gp/T/ipykernel_47623/1975220277.py:80: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'X' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_copy.at[idx, 'Status'] = 'X'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traité 21/99 lignes\n",
      "Traité 31/99 lignes\n",
      "Traité 41/99 lignes\n",
      "Traité 71/99 lignes\n",
      "Traité 81/99 lignes\n",
      "Classification terminée!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mistralai import Mistral\n",
    "\n",
    "df = pd.read_csv(\"/Users/justinkim/Documents/GitHub/360capital/datas/extract_LSN - Feuille 1 (17).csv\")\n",
    "\n",
    "\n",
    "def classify_company_status(df, client, model):\n",
    "    \"\"\"\n",
    "    Classifie les entreprises et met 'X' dans la colonne Status si elles ne correspondent \n",
    "    pas aux critères (France/Italie, ou Europe + climate tech, pas de consulting).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame contenant les données\n",
    "        client: Client Mistral initialisé\n",
    "        model: Nom du modèle Mistral à utiliser\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec la colonne Status mise à jour\n",
    "    \"\"\"\n",
    "    \n",
    "    def should_exclude(row):\n",
    "        \"\"\"\n",
    "        Détermine si une entreprise doit être exclue (Status = X)\n",
    "        \"\"\"\n",
    "        if pd.isna(row.get('Description')) or str(row.get('Description')).strip() == '':\n",
    "            return None\n",
    "        \n",
    "        description = str(row['Description'])\n",
    "        prompt = f\"\"\"\n",
    "\n",
    "Analyze the company’s description below and determine whether to ‘EXCLURE’ or ‘GARDER’ based on the following criteria:\n",
    "\n",
    "‘GARDER’ if:\n",
    "\n",
    "The company is based in France or Italy.\n",
    "The company operates in Europe and focuses on climate tech (renewable energy, decarbonization, etc.).\n",
    "The company uses AI to address problems, or technology such as deeptech.\n",
    "‘EXCLURE’ if:\n",
    "\n",
    "The company is involved in consulting.\n",
    "The company is non-profit or an association.\n",
    "Respond only with ‘EXCLURE’ or ‘GARDER’.\n",
    "If uncertain, choose ‘GARDER’.\n",
    "\n",
    "Description: {description}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            chat_response = client.chat.complete(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            response = chat_response.choices[0].message.content.strip().upper()\n",
    "            \n",
    "\n",
    "            if \"EXCLURE\" in response:\n",
    "                return 'X'\n",
    "            else:\n",
    "                return None  \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la classification: {e}\")\n",
    "            return None\n",
    "    \n",
    "\n",
    "    print(\"Classification en cours...\")\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        result = should_exclude(row)\n",
    "        if result == 'X':\n",
    "            df_copy.at[idx, 'Status'] = 'X'\n",
    "            if idx % 10 == 0: \n",
    "                print(f\"Traité {idx + 1}/{len(df_copy)} lignes\")\n",
    "    \n",
    "    print(\"Classification terminée!\")\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Config\n",
    "api_key = \"tLYewB74Gq1R7krnmU2fYaRVoHCx8wfl\"\n",
    "model = \"mistral-small-latest\"\n",
    "\n",
    "client = Mistral(\n",
    "    server_url=\"https://api.05d3a00300de.dc.mistral.ai\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "df_classified = classify_company_status(df, client, model)\n",
    "df_classified.to_csv('companies_classified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62add52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['CompanyName', 'Status']\n",
    "len(df_classified[col].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04050feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fizz'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Fizzbuzz(a):\n",
    "    if a%3 ==0 :\n",
    "        return \"Fizz\"\n",
    "    elif a%5 ==0 :\n",
    "        return \"Buzz\"\n",
    "    elif a%5 ==0 and a%3 ==0 :\n",
    "        return \"FizzBuzz\"\n",
    "    else :\n",
    "        return a\n",
    "        \n",
    "Fizzbuzz(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8520b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
