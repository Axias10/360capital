{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb363a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 17:27:43.410 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/justinkim/Documents/GitHub/360capital/.venv/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Charger et redimensionner le logo\n",
    "logo = Image.open(\"360_capital_vc_logo.jpeg\")\n",
    "logo = logo.resize((64, 64))\n",
    "\n",
    "\n",
    "# Configuration de la page\n",
    "st.set_page_config(\n",
    "    page_title=\"Nettoyage Données Crunchbase\",\n",
    "    page_icon=logo,\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "def get_domain(url):\n",
    "    \"\"\"Extrait le domaine d'une URL et le formate\"\"\"\n",
    "    if pd.isna(url):\n",
    "        return None\n",
    "    try:\n",
    "        domain = urlparse(url).netloc\n",
    "        domain = re.sub(r'^www\\d*\\.', '', domain).split(':')[0]\n",
    "        return domain.lower()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clean_crunchbase_data(df):\n",
    "    \"\"\"\n",
    "    Nettoie les données de levées de fonds Crunchbase\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame avec les colonnes Crunchbase\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame nettoyé avec les colonnes formatées\n",
    "    \"\"\"\n",
    "    # Créer une copie pour ne pas modifier l'original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Filtrer les types de financement non désirés\n",
    "    funding_types_to_remove = [\n",
    "        'Corporate Round',\n",
    "        'Grant',\n",
    "        'Post-IPO Debt',\n",
    "        'Equity Crowdfunding',\n",
    "        'Debt Financing',\n",
    "        'Convertible Note',\n",
    "        'Series C'\n",
    "    ]\n",
    "    \n",
    "    initial_count = len(df_clean)\n",
    "    df_clean = df_clean[~df_clean['Funding Type'].isin(funding_types_to_remove)]\n",
    "    filtered_count = initial_count - len(df_clean)\n",
    "    \n",
    "    # 2. Convertir les montants USD en devise originale\n",
    "    mask_usd = df_clean['Money Raised Currency'] == 'USD'\n",
    "    mask_has_both = pd.notna(df_clean['Money Raised']) & pd.notna(df_clean['Money Raised (in USD)'])\n",
    "    \n",
    "    # Calculer le taux de change moyen pour les lignes non-USD\n",
    "    rates = df_clean[~mask_usd & mask_has_both].apply(\n",
    "        lambda row: row['Money Raised (in USD)'] / row['Money Raised'] \n",
    "        if row['Money Raised'] != 0 else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "    avg_rate = rates.median() if len(rates) > 0 else 1.0\n",
    "    \n",
    "    # Appliquer la conversion inverse pour les montants USD\n",
    "    df_clean.loc[mask_usd & pd.isna(df_clean['Money Raised']) & pd.notna(df_clean['Money Raised (in USD)']), 'Money Raised'] = \\\n",
    "        df_clean.loc[mask_usd & pd.isna(df_clean['Money Raised']) & pd.notna(df_clean['Money Raised (in USD)']), 'Money Raised (in USD)'] / avg_rate\n",
    "    \n",
    "    # 3. Appliquer le formatage des URLs avec get_domain\n",
    "    df_clean['Website_formatted'] = df_clean['Organization Website'].apply(get_domain)\n",
    "    \n",
    "    # 3bis Changer le format des montants \n",
    "\n",
    "    df_clean['Money Raised'] = df_clean['Money Raised'].apply(lambda x: f\"€M {x:,.0f}\" if pd.notna(x) else x)  \n",
    "\n",
    "    # 4. Créer le nouveau DataFrame avec les colonnes demandées\n",
    "    df_final = pd.DataFrame({\n",
    "        'Company Name': df_clean['Organization Name'],\n",
    "        'Website 2': '',\n",
    "        'Website': df_clean['Website_formatted'],\n",
    "        'Description': df_clean['Organization Description'],\n",
    "        'Secteur': df_clean['Organization Industries'],\n",
    "        'Date annonce levée': '',\n",
    "        'Montant': df_clean['Money Raised'],\n",
    "        'Investisseurs': df_clean['Investor Names']\n",
    "    })\n",
    "    \n",
    "    # Réinitialiser l'index\n",
    "    df_final = df_final.reset_index(drop=True)\n",
    "    \n",
    "    return df_final, filtered_count\n",
    "\n",
    "\n",
    "# Interface principale\n",
    "st.title(\"Nettoyage de Données Crunchbase\")\n",
    "st.markdown(\"---\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### Instructions\n",
    "        1. Téléchargez votre fichier CSV exporté depuis Crunchbase.\n",
    "        2. Cliquez sur \"Nettoyer les données\" pour lancer le processus de nettoyage.\n",
    "        3. Téléchargez les données nettoyées au format CSV ou Excel.\n",
    "\"\"\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Upload du fichier\n",
    "uploaded_file = st.file_uploader(\n",
    "    \"Chargez votre fichier CSV Crunchbase\",\n",
    "    type=['csv'],\n",
    "    help=\"Le fichier doit contenir les colonnes standard de Crunchbase\"\n",
    ")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        # Lecture du fichier\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        \n",
    "        st.success(f\"✅ Fichier chargé : {len(df)} lignes détectées\")\n",
    "        \n",
    "        # Afficher un aperçu des données originales\n",
    "        with st.expander(\"Aperçu des données originales\"):\n",
    "            st.dataframe(df.head(10), use_container_width=True)\n",
    "        \n",
    "        # Bouton de nettoyage\n",
    "        if st.button(\"Nettoyer les données\", type=\"primary\", use_container_width=True):\n",
    "            with st.spinner(\"Nettoyage en cours...\"):\n",
    "                # Nettoyage\n",
    "                df_clean, filtered_count = clean_crunchbase_data(df)\n",
    "                \n",
    "                # Stocker dans session state\n",
    "                st.session_state['df_clean'] = df_clean\n",
    "                st.session_state['filtered_count'] = filtered_count\n",
    "        \n",
    "        # Afficher les résultats si disponibles\n",
    "        if 'df_clean' in st.session_state:\n",
    "            df_clean = st.session_state['df_clean']\n",
    "            filtered_count = st.session_state['filtered_count']\n",
    "            \n",
    "            st.markdown(\"---\")\n",
    "            st.success(\"Nettoyage terminé !\")\n",
    "            \n",
    "            # Statistiques\n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"Lignes initiales\", len(df))\n",
    "            with col2:\n",
    "                st.metric(\"Lignes filtrées\", filtered_count)\n",
    "            with col3:\n",
    "                st.metric(\"Lignes finales\", len(df_clean))\n",
    "            \n",
    "            # Aperçu des données nettoyées\n",
    "            st.subheader(\"Données nettoyées\")\n",
    "            st.dataframe(df_clean, use_container_width=True)\n",
    "            \n",
    "            # Boutons de téléchargement\n",
    "            st.markdown(\"---\")\n",
    "            st.subheader(\"Télécharger les résultats\")\n",
    "            \n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                # CSV\n",
    "                csv = df_clean.to_csv(index=False).encode('utf-8')\n",
    "                st.download_button(\n",
    "                    label=\"Télécharger en CSV\",\n",
    "                    data=csv,\n",
    "                    file_name=\"crunchbase_cleaned.csv\",\n",
    "                    mime=\"text/csv\",\n",
    "                    use_container_width=True\n",
    "                )\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        st.error(f\"❌ Erreur lors du traitement du fichier : {str(e)}\")\n",
    "        st.info(\"Vérifiez que votre fichier contient bien toutes les colonnes requises.\")\n",
    "\n",
    "else:\n",
    "    st.info(\"Charger un fichier CSV\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <div style='text-align: center; color: gray;'>\n",
    "    Outil de nettoyage de données Crunchbase 360 Capital \n",
    "    </div>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "14250b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'olleh'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom(str : str):\n",
    "    n = len(str)\n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        l.append(str[i])\n",
    "        print(str[i])\n",
    "    l.reverse()\n",
    "    return((''.join(l)).strip())\n",
    "\n",
    "custom('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "de153688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aezaezaaoala\n"
     ]
    }
   ],
   "source": [
    "# check palyndrome\n",
    "\n",
    "def palyiin(str):\n",
    "    if str[::-1] == str:\n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "\n",
    "str = 'alaoaazeazea'\n",
    "print(str[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19aa56be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 3})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "l = [1,1,1]\n",
    "\n",
    "print(Counter(l))\n",
    "\n",
    "# Pour un dataframe\n",
    "\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29978ad",
   "metadata": {},
   "source": [
    "Find indices of two numbers that add up to a specific target in an array.\n",
    "\n",
    "First we create a dictionary to store numbers and their indices as you iterate through the array. For each number, check if its complement (target minus the number) exists in the dictionary. If it does, return their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "adf65f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2]]\n"
     ]
    }
   ],
   "source": [
    "def sum(a, target):\n",
    "    test = a[0]\n",
    "    index = []\n",
    "    for i, value in enumerate(a):\n",
    "        if test + value == target:\n",
    "            index.append([a.index(test), i])\n",
    "        else :\n",
    "            test = value\n",
    "    return(index)\n",
    "\n",
    "print(sum([2, 7, 3, 15], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271a7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5]\n"
     ]
    }
   ],
   "source": [
    "# faire la sum de deux array numpy \n",
    "import numpy as np\n",
    "arr1 = np.array([1, 2])\n",
    "arr2 = np.array([4, 5])\n",
    "result = np.add(arr1, arr2)\n",
    "\n",
    "# extract diag \n",
    "import numpy as np\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(np.diagonal(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b32215",
   "metadata": {},
   "source": [
    "Create a Class to Represent a Person with Basic Attributes.\n",
    "\n",
    "__init__(self, name, age) initializes the Person object with a name and age.\n",
    "birthday(self) increases the person's age by 1.\n",
    "__str__(self) provides a human-readable string representation of the Person object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1448707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : Alice and Age : 12\n",
      "Name : Alice and Age : 13\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, age, name):\n",
    "        self.age = age\n",
    "        self.name = name\n",
    "    \n",
    "    def birthday(self):\n",
    "        self.age += 1\n",
    "\n",
    "    def str(self):\n",
    "        return(f\"Name : {self.name} and Age : {self.age}\")\n",
    "    \n",
    "perso = Person(12, \"Alice\")\n",
    "print(perso.str())\n",
    "perso.birthday()\n",
    "print(perso.str())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c487b9e2",
   "metadata": {},
   "source": [
    "Implement a sliding window to find the maximum sum of a subarray of a given size k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9788107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def subarray(arr, k):\n",
    "    max = 0\n",
    "    for i in range(len(arr)):\n",
    "        if max < sum(arr[i:i+k]):\n",
    "            max = sum(arr[i:i+k])\n",
    "\n",
    "    return(max)\n",
    "\n",
    "print(subarray([2, 1, 5, 1, 3, 2], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb99cb4",
   "metadata": {},
   "source": [
    " Calculate the confidence interval for a given dataset (assume normal distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55a5417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in ./.venv/lib/python3.9/site-packages (from scipy) (1.26.3)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "057a680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.614096175650322, 4.385903824349678)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    mean, std = np.mean(data), np.std(data, ddof=1)\n",
    "    z = norm.ppf((1 + confidence) / 2)\n",
    "    margin_of_error = z * (std / np.sqrt(len(data)))\n",
    "    return mean - margin_of_error, mean + margin_of_error\n",
    "\n",
    "\n",
    "print(confidence_interval([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d141d9f6",
   "metadata": {},
   "source": [
    " Implement the Chi-squared test for independence on a contingency table.\n",
    "\n",
    "Calculate the Chi-squared statistic by comparing observed and expected frequencies in the contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a021a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_squared_test(contingency_table):\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    return chi2, p\n",
    "\n",
    "\n",
    "table = [[10, 20], [20, 40]]\n",
    "print(chi_squared_test(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c900c",
   "metadata": {},
   "source": [
    "Write a function to handle missing data using multiple imputation.\n",
    "\n",
    "we use Simple Imputer to replace missing values with the mean or another strategy. Below is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5495a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.6.1 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38ae409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [1. 3.]\n",
      " [7. 6.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "def impute_missing_data(data):\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    return imputer.fit_transform(data)\n",
    "\n",
    "data = np.array([[1, 2], [np.nan, 3], [7, 6]])\n",
    "print(impute_missing_data(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee7ee8",
   "metadata": {},
   "source": [
    " Group a dataset by a column and calculate the rolling average for another column.\n",
    "\n",
    "Use pandas.groupby and rolling to calculate rolling averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a293d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Group  Value  Score\n",
      "0     A     10    1.5\n",
      "1     A     20    2.5\n",
      "2     B     30    3.5\n",
      "3     B     40    4.5\n",
      "4     C     50    5.5\n",
      "  Group  Score\n",
      "0     A    1.0\n",
      "1     B    1.0\n",
      "2     C    0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Group': ['A', 'A', 'B', 'B', 'C'],\n",
    "    'Value': [10, 20, 30, 40, 50],\n",
    "    'Score': [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "result = df.groupby('Group').agg({\n",
    "    'Score': lambda x: x.max() - x.min().min() # la colonne doit exister \n",
    "}).reset_index() # à toujours rajouter\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca3a161c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Value</th>\n",
       "      <th>Averages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group  Value  Averages\n",
       "0     A     10      10.0\n",
       "1     A     20      15.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1485680b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Value</th>\n",
       "      <th>Averages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>30</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>40</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group  Value  Averages\n",
       "0     A     10      10.0\n",
       "1     A     20      15.0\n",
       "2     B     30      30.0\n",
       "3     B     40      35.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Averages'] = df.groupby('Group')['Value'].rolling(window=2, min_periods=1).mean().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ddc45",
   "metadata": {},
   "source": [
    "Create a pivot table from raw transactional data.\n",
    "\n",
    "Use pandas.pivot_table to summarize data into a pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c011db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type         X     Y\n",
      "Category            \n",
      "A         10.0  20.0\n",
      "B         30.0   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_pivot_table(df, index, columns, values, aggfunc):\n",
    "    return pd.pivot_table(df, index=index, columns=columns, values=values, aggfunc=aggfunc)\n",
    "\n",
    "data = {'Category': ['A', 'A', 'B'], 'Type': ['X', 'Y', 'X'], 'Value': [10, 20, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "pivot_table = create_pivot_table(df, index='Category', columns='Type', values='Value', aggfunc='sum')\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60bd4c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First_name Last_name  Age      City\n",
      "0       Liam     Smith   42  New York\n",
      "1       Emma     Brown   52     Paris\n",
      "2       Noah     Davis   36    Berlin\n",
      "3     Olivia    Wilson   21    Madrid\n",
      "4        Ava    Taylor   23      Rome\n",
      "  First_name Last_name  Age      City Qualification\n",
      "0       Liam     Smith   42  New York           MBA\n",
      "1       Emma     Brown   52     Paris           PhD\n",
      "2       Noah     Davis   36    Berlin           LLB\n",
      "3     Olivia    Wilson   21    Madrid        B.Tech\n",
      "4        Ava    Taylor   23      Rome            MD\n",
      "  First_name Last_name  Age      City Qualification\n",
      "0      Lucas     Smith   42  New York           MBA\n",
      "1       Emma     Brown   52     Paris           PhD\n",
      "2     Nathan     Davis   36    Berlin           LLB\n",
      "3      Olive    Wilson   21    Madrid        B.Tech\n",
      "4        Ava    Taylor   23      Rome            MD\n",
      "  First_name Last_name  Age      City Qualification\n",
      "0      Lukas     Smith   42  New York           MBA\n",
      "1       Emma     Brown   52     Paris           PhD\n",
      "2    Nicolas     Davis   36    Berlin           LLB\n",
      "3     Sophia    Wilson   21    Madrid        B.Tech\n",
      "4        Ava    Taylor   23      Rome            MD\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = { 'First_name': ['Liam', 'Emma', 'Noah', 'Olivia', 'Ava'],\n",
    "         'Last_name': ['Smith', 'Brown', 'Davis', 'Wilson', 'Taylor'],\n",
    "         'Age': [42, 52, 36, 21, 23],\n",
    "         'City': ['New York', 'Paris', 'Berlin', 'Madrid', 'Rome'] }\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "new_vals = {\"Liam\": \"MBA\", \"Emma\": \"PhD\", \"Noah\": \"LLB\", \"Olivia\": \"B.Tech\", \"Ava\": \"MD\"}\n",
    "df[\"Qualification\"] = df[\"First_name\"].map(new_vals)\n",
    "print(df)\n",
    "\n",
    "new_vals = {\"Liam\": \"Lucas\", \"Noah\": \"Nathan\", \"Olivia\": \"Olive\"}\n",
    "df_replaced = df.replace({\"First_name\": new_vals})\n",
    "print(df_replaced)\n",
    "\n",
    "new_vals = {0: \"Lukas\", 2: \"Nicolas\", 3: \"Sophia\"}\n",
    "df[\"First_name\"].update(pd.Series(new_vals))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30576342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name            Team  Number Position   Age Height  Weight  \\\n",
      "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
      "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
      "2   John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
      "3    R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
      "4  Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
      "\n",
      "             College     Salary  \n",
      "0              Texas  7730337.0  \n",
      "1          Marquette  6796117.0  \n",
      "2  Boston University        NaN  \n",
      "3      Georgia State  1148640.0  \n",
      "4                NaN  5000000.0  \n",
      "Index(['Name', 'Team', 'Number', 'Position', 'Age', 'Height', 'Weight',\n",
      "       'College', 'Salary'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zip at 0x16a122f00>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# making dataframe\n",
    "df = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\")\n",
    "\n",
    "# it was print the first 5-rows\n",
    "print(df.head())\n",
    "\n",
    "# reshape the dataframe using stack() method\n",
    "df_stacked = df.stack()\n",
    "\n",
    "print(df_stacked[0].keys())\n",
    "df_stacked[0].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5794ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Name\n",
      "1 Team\n",
      "2 Number\n",
      "3 Position\n",
      "4 Age\n",
      "5 Height\n",
      "6 Weight\n",
      "7 College\n",
      "8 Salary\n",
      "            Name            Team Number Position   Age Height Weight  \\\n",
      "0  Avery Bradley  Boston Celtics    0.0       PG  25.0    6-2  180.0   \n",
      "1    Jae Crowder  Boston Celtics   99.0       SF  25.0    6-6  235.0   \n",
      "2   John Holland  Boston Celtics   30.0       SG  27.0    6-5  205.0   \n",
      "3    R.J. Hunter  Boston Celtics   28.0       SG  22.0    6-5  185.0   \n",
      "4  Jonas Jerebko  Boston Celtics    8.0       PF  29.0   6-10  231.0   \n",
      "5   Amir Johnson  Boston Celtics   90.0       PF  29.0    6-9  240.0   \n",
      "6  Jordan Mickey  Boston Celtics   55.0       PF  21.0    6-8  235.0   \n",
      "7   Kelly Olynyk  Boston Celtics   41.0        C  25.0    7-0  238.0   \n",
      "8   Terry Rozier  Boston Celtics   12.0       PG  22.0    6-2  190.0   \n",
      "9   Marcus Smart  Boston Celtics   36.0       PG  22.0    6-4  220.0   \n",
      "\n",
      "             College      Salary  \n",
      "0              Texas   7730337.0  \n",
      "1          Marquette   6796117.0  \n",
      "2  Boston University         NaN  \n",
      "3      Georgia State   1148640.0  \n",
      "4                NaN   5000000.0  \n",
      "5                NaN  12000000.0  \n",
      "6                LSU   1170960.0  \n",
      "7            Gonzaga   2165160.0  \n",
      "8         Louisville   1824360.0  \n",
      "9     Oklahoma State   3431040.0  \n"
     ]
    }
   ],
   "source": [
    "for key, element in enumerate(df):\n",
    "    print(key, element)\n",
    "# unstack() method\n",
    "df_unstacked = df_stacked.unstack()\n",
    "print(df_unstacked.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5b2416da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>7730337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Shelvin Mack</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-3</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Butler</td>\n",
       "      <td>2433333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Raul Neto</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>25.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6-1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "0    Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "3      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "4    Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "453   Shelvin Mack       Utah Jazz     8.0       PG  26.0    6-3   203.0   \n",
       "454      Raul Neto       Utah Jazz    25.0       PG  24.0    6-1   179.0   \n",
       "455   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "456    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College     Salary  \n",
       "0                Texas  7730337.0  \n",
       "1            Marquette  6796117.0  \n",
       "2    Boston University        NaN  \n",
       "3        Georgia State  1148640.0  \n",
       "4                  NaN  5000000.0  \n",
       "..                 ...        ...  \n",
       "453             Butler  2433333.0  \n",
       "454                NaN   900000.0  \n",
       "455                NaN  2900000.0  \n",
       "456             Kansas   947276.0  \n",
       "457                NaN        NaN  \n",
       "\n",
       "[458 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f45a9682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name            Team  Number Position   Age Height  Weight  \\\n",
      "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
      "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
      "2   John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
      "3    R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
      "4  Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
      "5   Amir Johnson  Boston Celtics    90.0       PF  29.0    6-9   240.0   \n",
      "6  Jordan Mickey  Boston Celtics    55.0       PF  21.0    6-8   235.0   \n",
      "7   Kelly Olynyk  Boston Celtics    41.0        C  25.0    7-0   238.0   \n",
      "8   Terry Rozier  Boston Celtics    12.0       PG  22.0    6-2   190.0   \n",
      "9   Marcus Smart  Boston Celtics    36.0       PG  22.0    6-4   220.0   \n",
      "\n",
      "             College      Salary  \n",
      "0              Texas   7730337.0  \n",
      "1          Marquette   6796117.0  \n",
      "2  Boston University         NaN  \n",
      "3      Georgia State   1148640.0  \n",
      "4                NaN   5000000.0  \n",
      "5                NaN  12000000.0  \n",
      "6                LSU   1170960.0  \n",
      "7            Gonzaga   2165160.0  \n",
      "8         Louisville   1824360.0  \n",
      "9     Oklahoma State   3431040.0  \n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "df_copy = df_copy.query('Age < 25')\n",
    "df_copy\n",
    "\n",
    "indices_to_drop = df_copy[df_copy['Weight'] < 185].index # récupérer les index\n",
    "df.drop(indices_to_drop, inplace=True)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a516d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name           Jae Crowder\n",
       "Team        Boston Celtics\n",
       "Number                99.0\n",
       "Position                SF\n",
       "Age                   25.0\n",
       "Height                 6-6\n",
       "Weight               235.0\n",
       "College          Marquette\n",
       "Salary           6796117.0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "433c782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>7730337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name            Team  Number Position   Age Height  Weight  \\\n",
       "0  Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
       "1    Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "\n",
       "     College     Salary  \n",
       "0      Texas  7730337.0  \n",
       "1  Marquette  6796117.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0:1] # ici les index sont des nombres mais la différence c'est qu'on peut utiliser les noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aecf7543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amir Johnson</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>90.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Chris Johnson</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>981348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Trey Lyles</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>41.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2239800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "3      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "4    Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
       "5     Amir Johnson  Boston Celtics    90.0       PF  29.0    6-9   240.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "451  Chris Johnson       Utah Jazz    23.0       SF  26.0    6-6   206.0   \n",
       "452     Trey Lyles       Utah Jazz    41.0       PF  20.0   6-10   234.0   \n",
       "455   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "456    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College      Salary  \n",
       "1            Marquette   6796117.0  \n",
       "2    Boston University         NaN  \n",
       "3        Georgia State   1148640.0  \n",
       "4                  NaN   5000000.0  \n",
       "5                  NaN  12000000.0  \n",
       "..                 ...         ...  \n",
       "451             Dayton    981348.0  \n",
       "452           Kentucky   2239800.0  \n",
       "455                NaN   2900000.0  \n",
       "456             Kansas    947276.0  \n",
       "457                NaN         NaN  \n",
       "\n",
       "[366 rows x 9 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('Position != \"PG\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "29994409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amir Johnson</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>90.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6-9</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Chris Johnson</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>981348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Trey Lyles</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>41.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2239800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "3      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "4    Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
       "5     Amir Johnson  Boston Celtics    90.0       PF  29.0    6-9   240.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "451  Chris Johnson       Utah Jazz    23.0       SF  26.0    6-6   206.0   \n",
       "452     Trey Lyles       Utah Jazz    41.0       PF  20.0   6-10   234.0   \n",
       "455   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "456    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College      Salary  \n",
       "1            Marquette   6796117.0  \n",
       "2    Boston University         NaN  \n",
       "3        Georgia State   1148640.0  \n",
       "4                  NaN   5000000.0  \n",
       "5                  NaN  12000000.0  \n",
       "..                 ...         ...  \n",
       "451             Dayton    981348.0  \n",
       "452           Kentucky   2239800.0  \n",
       "455                NaN   2900000.0  \n",
       "456             Kansas    947276.0  \n",
       "457                NaN         NaN  \n",
       "\n",
       "[366 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Position'] != 'PG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33df9337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 9)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0], df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f17b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Avery Bradley', 'Boston Celtics', 0.0, 'PG', 25.0, '6-2', 180.0, 'Texas', 7730337.0]\n"
     ]
    }
   ],
   "source": [
    "row = []\n",
    "for i in range(df.shape[0]):\n",
    "    row.append(list(df.iloc[i,:]))\n",
    "\n",
    "print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafdb89f",
   "metadata": {},
   "source": [
    "insérer des élements à n'importe quel endroit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26498c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>7730337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jae Cr</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6796117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1148640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Trey Lyles</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>41.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-10</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2239800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Shelvin Mack</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6-3</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Butler</td>\n",
       "      <td>2433333.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>C</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "0    Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
       "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
       "2           Jae Cr  Boston Celtics    99.0       SF  25.0      0   235.0   \n",
       "3     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
       "4      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "446     Trey Lyles       Utah Jazz    41.0       PF  20.0   6-10   234.0   \n",
       "447   Shelvin Mack       Utah Jazz     8.0       PG  26.0    6-3   203.0   \n",
       "448   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
       "449    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
       "450            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College     Salary  \n",
       "0                Texas  7730337.0  \n",
       "1            Marquette  6796117.0  \n",
       "2            Marquette  6796117.0  \n",
       "3    Boston University        NaN  \n",
       "4        Georgia State  1148640.0  \n",
       "..                 ...        ...  \n",
       "446           Kentucky  2239800.0  \n",
       "447             Butler  2433333.0  \n",
       "448                NaN  2900000.0  \n",
       "449             Kansas   947276.0  \n",
       "450                NaN        NaN  \n",
       "\n",
       "[451 rows x 9 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row2 = ['Jae Cr','Boston Celtics',\t99.0,\t'SF'\t,25.0,\t6-6,\t235.0\t,'Marquette',\t6796117.0]\n",
    "\n",
    "# Copy original DataFrame\n",
    "df2 = df.copy()\n",
    "\n",
    "# Insert row at position 1\n",
    "df2.loc[1.5] = new_row2\n",
    "df2 = df2.sort_index().reset_index(drop=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "df516ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Rashad Vaughn</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>20.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>202.0</td>\n",
       "      <td>UNLV</td>\n",
       "      <td>1733040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Devin Booker</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2127840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Dante Exum</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3777720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-5</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>5103120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Tyus Jones</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6-2</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1282080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>15.0</td>\n",
       "      <td>SG</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>220.0</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>4088019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Andre Miller</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>24.0</td>\n",
       "      <td>PG</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6-3</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>250750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Kevin Garnett</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>21.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Tim Duncan</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>21.0</td>\n",
       "      <td>C</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>5250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                    Team  Number Position   Age Height  \\\n",
       "226     Rashad Vaughn         Milwaukee Bucks    20.0       SG  19.0    6-6   \n",
       "122      Devin Booker            Phoenix Suns     1.0       SG  19.0    6-6   \n",
       "445        Dante Exum               Utah Jazz    11.0       PG  20.0    6-6   \n",
       "116  D'Angelo Russell      Los Angeles Lakers     1.0       PG  20.0    6-5   \n",
       "401        Tyus Jones  Minnesota Timberwolves     1.0       PG  20.0    6-2   \n",
       "..                ...                     ...     ...      ...   ...    ...   \n",
       "261      Vince Carter       Memphis Grizzlies    15.0       SG  39.0    6-6   \n",
       "304      Andre Miller       San Antonio Spurs    24.0       PG  40.0    6-3   \n",
       "400     Kevin Garnett  Minnesota Timberwolves    21.0       PF  40.0   6-11   \n",
       "298        Tim Duncan       San Antonio Spurs    21.0        C  40.0   6-11   \n",
       "457               NaN                     NaN     NaN      NaN   NaN    NaN   \n",
       "\n",
       "     Weight         College     Salary  \n",
       "226   202.0            UNLV  1733040.0  \n",
       "122   206.0        Kentucky  2127840.0  \n",
       "445   190.0             NaN  3777720.0  \n",
       "116   195.0      Ohio State  5103120.0  \n",
       "401   195.0            Duke  1282080.0  \n",
       "..      ...             ...        ...  \n",
       "261   220.0  North Carolina  4088019.0  \n",
       "304   200.0            Utah   250750.0  \n",
       "400   240.0             NaN  8500000.0  \n",
       "298   250.0     Wake Forest  5250000.0  \n",
       "457     NaN             NaN        NaN  \n",
       "\n",
       "[450 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df.sort_values(by=['Age', 'Weight'], ascending=True)  \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9864d61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Kobe Bryant</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6-6</td>\n",
       "      <td>212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6-8</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22970500.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6-8</td>\n",
       "      <td>240.0</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>22875000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Dwight Howard</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>12.0</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22359364.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Chris Bosh</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6-11</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>22192730.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                 Team  Number Position   Age Height  \\\n",
       "109      Kobe Bryant   Los Angeles Lakers    24.0       SF  37.0    6-6   \n",
       "169     LeBron James  Cleveland Cavaliers    23.0       SF  31.0    6-8   \n",
       "33   Carmelo Anthony      New York Knicks     7.0       SF  32.0    6-8   \n",
       "251    Dwight Howard      Houston Rockets    12.0        C  30.0   6-11   \n",
       "339       Chris Bosh           Miami Heat     1.0       PF  32.0   6-11   \n",
       "\n",
       "     Weight       College      Salary  Rank  \n",
       "109   212.0           NaN  25000000.0   1.0  \n",
       "169   250.0           NaN  22970500.0   2.0  \n",
       "33    240.0      Syracuse  22875000.0   3.0  \n",
       "251   265.0           NaN  22359364.0   4.0  \n",
       "339   235.0  Georgia Tech  22192730.0   5.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rank'] = df['Salary'].rank(method='average', ascending=False) # pour rank par rapport à une features \n",
    "df.sort_values(by='Rank').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713eea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fizzbuzz(a):\n",
    "    if a%3 ==0 :\n",
    "        return \"Fizz\"\n",
    "    elif a%5 ==0 :\n",
    "        return \"Buzz\"\n",
    "    elif a%5 ==0 and a%3 ==0 :\n",
    "        return \"FizzBuzz\"\n",
    "    else :\n",
    "        return a\n",
    "        \n",
    "Fizzbuzz(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b4ba9",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "02ac99fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-4.0.1.tar.gz (434.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.2/434.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.9 (from pyspark)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-4.0.1-py2.py3-none-any.whl size=434813860 sha256=b5c5785be07adfcdddeae573b9a2b18bb5347becc5ed9da341396bacd0d7e69f\n",
      "  Stored in directory: /Users/justinkim/Library/Caches/pip/wheels/10/e6/6b/c50eb601fa827dd56a5272db5d5db360e559e527a80a665b1d\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pyspark]m1/2\u001b[0m [pyspark]\n",
      "\u001b[1A\u001b[2KSuccessfully installed py4j-0.10.9.9 pyspark-4.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, when, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# 1. Initialisation de la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExempleDataFrameSpark\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2. Définition d'un schéma pour le DataFrame (optionnel, pour un contrôle précis)\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"nom\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"salaire\", DoubleType(), True),\n",
    "    StructField(\"ville\", StringType(), True)\n",
    "])\n",
    "\n",
    "# 3. Création d'un DataFrame à partir de données brutes (si pas de fichier CSV)\n",
    "data = [\n",
    "    (1, \"Alice\", 25, 50000.0, \"Paris\"),\n",
    "    (2, \"Bob\", 30, 60000.0, \"Lyon\"),\n",
    "    (3, \"Charlie\", 35, 75000.0, \"Marseille\"),\n",
    "    (4, \"David\", 28, 55000.0, \"Paris\"),\n",
    "    (5, \"Emma\", 40, 80000.0, None)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Alternativement, charger un DataFrame depuis un fichier CSV\n",
    "# df = spark.read.csv(\"path/to/data.csv\", header=True, schema=schema)\n",
    "\n",
    "# 4. Afficher le schéma du DataFrame\n",
    "print(\"Schéma du DataFrame :\")\n",
    "df.printSchema()\n",
    "\n",
    "# 5. Afficher les premières lignes\n",
    "print(\"Aperçu des données :\")\n",
    "df.show(5, truncate=False)\n",
    "\n",
    "# 6. Exemple de transformations\n",
    "# a. Filtrer les lignes où l'âge est supérieur à 30\n",
    "df_filtre = df.filter(col(\"age\") > 30)\n",
    "print(\"Personnes de plus de 30 ans :\")\n",
    "df_filtre.show()\n",
    "\n",
    "# b. Ajouter une nouvelle colonne basée sur une condition\n",
    "df = df.withColumn(\"categorie_age\", \n",
    "                   when(col(\"age\") < 30, \"Jeune\")\n",
    "                   .when(col(\"age\") <= 35, \"Adulte\")\n",
    "                   .otherwise(\"Senior\"))\n",
    "print(\"DataFrame avec nouvelle colonne :\")\n",
    "df.show()\n",
    "\n",
    "# c. Grouper et agréger : calculer le salaire moyen par ville\n",
    "df_agg = df.groupBy(\"ville\").agg(\n",
    "    avg(\"salaire\").alias(\"salaire_moyen\"),\n",
    "    count(\"id\").alias(\"nombre_personnes\")\n",
    ")\n",
    "print(\"Salaire moyen et nombre de personnes par ville :\")\n",
    "df_agg.show()\n",
    "\n",
    "# 7. Gestion des valeurs manquantes\n",
    "# Remplacer les valeurs nulles dans la colonne 'ville' par 'Inconnu'\n",
    "df = df.na.fill({\"ville\": \"Inconnu\"})\n",
    "print(\"DataFrame après remplacement des valeurs nulles :\")\n",
    "df.show()\n",
    "\n",
    "# 8. Jointure avec un autre DataFrame\n",
    "# Création d'un DataFrame pour les départements\n",
    "data_dep = [(1, \"Paris\", \"Île-de-France\"), (2, \"Lyon\", \"Auvergne-Rhône-Alpes\"), (3, \"Inconnu\", \"Inconnu\")]\n",
    "schema_dep = StructType([\n",
    "    StructField(\"id_dep\", IntegerType(), False),\n",
    "    StructField(\"ville\", StringType(), True),\n",
    "    StructField(\"region\", StringType(), True)\n",
    "])\n",
    "df_dep = spark.createDataFrame(data_dep, schema_dep)\n",
    "\n",
    "# Jointure sur la colonne 'ville'\n",
    "df_joined = df.join(df_dep, \"ville\", \"left\")\n",
    "print(\"DataFrame après jointure :\")\n",
    "df_joined.show()\n",
    "\n",
    "# 9. Sauvegarde des résultats\n",
    "# Sauvegarder le DataFrame transformé en format Parquet\n",
    "df.write.mode(\"overwrite\").parquet(\"output/transformed_data\")\n",
    "\n",
    "# Sauvegarder les résultats agrégés en CSV\n",
    "df_agg.write.mode(\"overwrite\").csv(\"output/aggregated_data\", header=True)\n",
    "\n",
    "# 10. Utilisation de SQL avec Spark\n",
    "# Créer une vue temporaire pour exécuter des requêtes SQL\n",
    "df.createOrReplaceTempView(\"personnes\")\n",
    "result_sql = spark.sql(\"\"\"\n",
    "    SELECT ville, AVG(salaire) as salaire_moyen, COUNT(*) as nombre\n",
    "    FROM personnes\n",
    "    GROUP BY ville\n",
    "    HAVING COUNT(*) > 1\n",
    "\"\"\")\n",
    "print(\"Résultat de la requête SQL :\")\n",
    "result_sql.show()\n",
    "\n",
    "# 11. Arrêter la session Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5958a93",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc1015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eeda66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "304947b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Driver  Points  Age\n",
      "0    Hamilton     408   33\n",
      "1      Vettel     320   31\n",
      "2   Raikkonen     251   39\n",
      "3  Verstappen     249   21\n",
      "4      Bottas     247   29\n",
      "5   Ricciardo     170   29\n",
      "6  Hulkenberg      69   31\n",
      "7       Perez      62   28\n",
      "8   Magnussen      56   26\n",
      "9       Sainz      53   24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data of 2018 drivers world championship\n",
    "dict1 = {'Driver': ['Hamilton', 'Vettel', 'Raikkonen',\n",
    "                    'Verstappen', 'Bottas', 'Ricciardo',\n",
    "                    'Hulkenberg', 'Perez', 'Magnussen',\n",
    "                    'Sainz', 'Alonso', 'Ocon', 'Leclerc',\n",
    "                    'Grosjean', 'Gasly', 'Vandoorne',\n",
    "                    'Ericsson', 'Stroll', 'Hartley', 'Sirotkin'],\n",
    "\n",
    "         'Points': [408, 320, 251, 249, 247, 170, 69, 62, 56,\n",
    "                    53, 50, 49, 39, 37, 29, 12, 9, 6, 4, 1],\n",
    "\n",
    "         'Age': [33, 31, 39, 21, 29, 29, 31, 28, 26, 24, 37,\n",
    "                 22, 21, 32, 22, 26, 28, 20, 29, 23]}\n",
    "\n",
    "# creating dataframe using DataFrame constructor\n",
    "df = pd.DataFrame(dict1)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "df28d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     408\n",
       "1     320\n",
       "2     251\n",
       "3     249\n",
       "4     247\n",
       "5     170\n",
       "6      69\n",
       "7      62\n",
       "8      56\n",
       "9      53\n",
       "10     50\n",
       "11     49\n",
       "12     39\n",
       "13     37\n",
       "14     29\n",
       "15     12\n",
       "16      9\n",
       "17      6\n",
       "18      4\n",
       "19      1\n",
       "Name: Points, dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Points'] \n",
    "df.Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "a7e49550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Driver</th>\n",
       "      <th>Points</th>\n",
       "      <th>Age</th>\n",
       "      <th>Nul</th>\n",
       "      <th>Statut</th>\n",
       "      <th>stat</th>\n",
       "      <th>Score Normalisé par age</th>\n",
       "      <th>Autre point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Stroll</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Verstappen</td>\n",
       "      <td>249</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>8.517241</td>\n",
       "      <td>-3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leclerc</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ocon</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gasly</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A le droit</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Driver  Points  Age  Nul Statut        stat  Score Normalisé par age  \\\n",
       "17      Stroll       6   20    0    Yes  A le droit                 0.300000   \n",
       "3   Verstappen     249   21    0    Yes  A le droit                 8.517241   \n",
       "12     Leclerc      39   21    0    Yes  A le droit                 1.351351   \n",
       "11        Ocon      49   22    0    Yes  A le droit                 1.857143   \n",
       "14       Gasly      29   22    0    Yes  A le droit                 1.156250   \n",
       "\n",
       "    Autre point  \n",
       "17         19.4  \n",
       "3          -3.9  \n",
       "12         17.1  \n",
       "11         17.1  \n",
       "14         19.1  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nsmallest(5, ['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 21, 22, 23, 24, 26, 28, 29, 31, 32, 33, 37, 39]\n",
      "13\n",
      "Age\n",
      "29    3\n",
      "31    2\n",
      "21    2\n",
      "28    2\n",
      "26    2\n",
      "22    2\n",
      "33    1\n",
      "39    1\n",
      "24    1\n",
      "37    1\n",
      "32    1\n",
      "20    1\n",
      "23    1\n",
      "Name: count, dtype: int64\n",
      "3\n",
      "17 20\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k4/x11w534x6fx5843q4r1vdmtc0000gp/T/ipykernel_51836/211200575.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;31m# Select une colonne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/360capital/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Points'"
     ]
    }
   ],
   "source": [
    "# Select une colonne \n",
    "df.Points\n",
    "df['Points']\n",
    "\n",
    "# Select une row\n",
    "df.iloc[1]\n",
    "# Select plusieurs rows\n",
    "df.iloc[0:3]\n",
    "\n",
    "# Select randomly rows\n",
    "sampled_df = df.sample(frac=0.5).reset_index().drop('index', axis=1)\n",
    "\n",
    "# Select row that contains a certain string \n",
    "\n",
    "#print(df[df[\"Driver\"].str.contains(\"ami\")]) # on peut mettre un OR contient result = df[df[\"Team\"].str.contains(\"Boston\") | df[\"College\"].str.contains(\"MIT\")] \n",
    "\n",
    "# Create a list, a dict from rows\n",
    "\n",
    "#print(df.value_counts())\n",
    "#print(df.values.tolist())\n",
    "#print(df.to_numpy().tolist())\n",
    "#print(df.to_dict(orient='records')) # list of dict\n",
    "#print([list(row) for row in df.itertuples(index=False)]) # pour les grandes base de données\n",
    "\n",
    "# Drop une colonne \n",
    "#df = df.drop(df.iloc[:, 1:3], axis=1)\n",
    "#df = df.drop('Points', axis=1)\n",
    "#df.pop('col')\n",
    "# Drop columns with more than 50% missing values\n",
    "#threshold = len(df) * 0.5\n",
    "#df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Créer une colonne \n",
    "l_a_rajouter = [0 for i in range(len(df))]\n",
    "df['Nul'] = l_a_rajouter\n",
    "\n",
    "# Pour itérer sur une colonne et en créer une nouvelle avec un statut, High salary par exemple\n",
    "statut = []\n",
    "for age in df['Age']:\n",
    "    if age>18:\n",
    "        statut.append('Yes')\n",
    "df['Statut'] = statut\n",
    "\n",
    "bins = [0,18,40]\n",
    "lab = ['Non', 'A le droit']\n",
    "df['stat'] = pd.cut(df['Age'], bins = bins, labels = lab) # possible de le faire avce binning\n",
    "\n",
    "# pour itérer sur le nom des colonnes \n",
    "\n",
    "#for col in df.columns:\n",
    "    #print(col)\n",
    "\n",
    "\n",
    "# Récupérer le nom des colonnes\n",
    "\n",
    "#print(df.columns.to_list())\n",
    "#print(sorted(df.columns.values))\n",
    "#print(df.keys())\n",
    "\n",
    "# récupérer les values unique d'une colonne \n",
    "print(sorted(df['Age'].unique()))\n",
    "print(df['Age'].nunique())\n",
    "print(df['Age'].value_counts())\n",
    "print(df['Age'].value_counts().max())\n",
    "df.groupby('Age').size()\n",
    "pd.crosstab(index=df['Age'], columns='count')\n",
    "\n",
    "\n",
    "# Modifier index avec une colonne\n",
    "d = df.copy()\n",
    "d.index = d.pop(\"Driver\")\n",
    "#df.set_index('Age')\n",
    "#print(d)\n",
    "\n",
    "# Get l'index du max dans un dataframe\n",
    "\n",
    "i_min , min = 0, df['Age'][0]\n",
    "for i in range(len(df)):\n",
    "    if df['Age'][i]<min:\n",
    "        min = df['Age'][i]\n",
    "        i_min = i\n",
    "print(i_min, min)\n",
    "\n",
    "df.min()\n",
    "df[df.Points == df.Points.min()]\n",
    "\n",
    "df[['Age']].idxmax() # PLUS SIMPLE POUR LINDEX DU MAX\n",
    "df.nlargest(5, ['Age']) # Pour avoir accès au n value les plus grandes\n",
    "df.nsmallest(5, ['Age'])\n",
    "\n",
    "# Rename les colonnes \n",
    "\n",
    "df_co = df.copy()\n",
    "df_co.rename(columns={'Driver' : 'A', 'Points' : 'B' , 'Age': 'C',  'Nul': 'D',  'Statut': 'E',  'stat': 'F'}, inplace=True)\n",
    "\n",
    "l = [i for i in range(len(df_co.columns.to_list()))]\n",
    "df_co.columns = l\n",
    "\n",
    "#df_co.add_prefix('new_') \n",
    "\n",
    "# Duplicates \n",
    "df['Age'].drop_duplicates()\n",
    "unique_set = set(df['Age'])\n",
    "print(unique_set)\n",
    "\n",
    "# Créer une nouvelle colonne fonction des autres\n",
    "max = df['Points'].max() \n",
    "df[\"Score Normalisé par age\"] = df.apply(lambda x : x['Points']/x['Age'], axis = 1  )\n",
    "sorted(df[\"Score Normalisé par age\"].to_numpy(), reverse=True)\n",
    "df[\"Score Normalisé par age\"] = sorted(df[\"Score Normalisé par age\"].to_numpy(), reverse=True)\n",
    "\n",
    "df['Autre point'] = df['Age'] - (0.1 * df['Points'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "011d7d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item 1', 'Item 2']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df = pd.DataFrame({'Date':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'],\n",
    "                   'Product':['Umbrella', 'Mattress', 'Badminton', 'Shuttle'],\n",
    "                   'Last Price':[1200, 1500, 1600, 352],\n",
    "                   'Updated Price':[1250, 1450, 1550, 400],\n",
    "                   'Discount':[10, 10, 10, 10]})\n",
    "df\n",
    "\n",
    "Final_cost = []\n",
    "for element in df['Updated Price']:\n",
    "    if element != 'NaN' :\n",
    "        Final_cost.append(element*(0.9))\n",
    "df['Final Price'] = Final_cost\n",
    "df\n",
    "\n",
    "# Check si la colonne est présente \n",
    "if {'Updated Price', 'Discount'}.issubset(df.columns):\n",
    "    df['Final cost'] = df['Updated Price'] - (df['Updated Price']*0.1)\n",
    "\n",
    "elif {'Last Price', 'Discount'}.issubset(df.columns):\n",
    "    df['Final cost'] = df['Last Price'] - (df['Last Price']*0.1)\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame({'Date':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'],\n",
    "                   'Product':['Umbrella', 'Mattress', 'Badminton', 'Shuttle'],\n",
    "                   'Last_Price':[1200, 1500, 1600, 352],\n",
    "                   'Updated_Price':[1250, 1450, 1550, 400],\n",
    "                   'Discount':[10, 10, 10, 10]})\n",
    "\n",
    "# Create the indexes\n",
    "df.index =[f'Item {i}' for i in range(len(df))]\n",
    "\n",
    "# recherche dans les index qui satisfait une condition \n",
    "df\n",
    "df.query('Updated_Price > 1250').index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name  Age\n",
      "0    John Larter   32\n",
      "1  Robert Junior   34\n",
      "2     Jonny Depp   36\n"
     ]
    }
   ],
   "source": [
    "# Pour remplacer des valeurs dans une colonne \n",
    "# Define an incomplete dictionary\n",
    "df = pd.DataFrame({'Date':['10/2/2011', '11/2/2011', '12/2/2011', '13/2/2011'],\n",
    "                    'Event':['Music', 'Poetry', 'Theatre', 'Comedy'],\n",
    "                    'Cost':[10000, 5000, 15000, 2000]})\n",
    "d = {'Music': 'M', 'Poetry': 'P'}\n",
    "\n",
    "# Apply map() and handle missing values\n",
    "df['Event'] = df['Event'].map(d).fillna('Unknown')\n",
    "\n",
    "# split des tring colonnes\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['John Larter', 'Robert Junior', 'Jonny Depp'],\n",
    "    'Age': [32, 34, 36]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fbfba",
   "metadata": {},
   "source": [
    "# Time series manip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "6b9c6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac47c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-06 00:00:00\n",
      "               City    Event   Cost\n",
      "2018-01-06   Lisbon    Music  10000\n",
      "2018-04-06  Parague   Poetry   5000\n",
      "2018-07-06    Macao  Theatre  15000\n",
      "2018-10-06   Venice   Comedy   2000\n",
      "Before Conversion:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    3 non-null      object\n",
      " 1   Event   3 non-null      object\n",
      " 2   Cost    3 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 200.0+ bytes\n",
      "None\n",
      "\n",
      "After Conversion:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    3 non-null      datetime64[ns]\n",
      " 1   Event   3 non-null      object        \n",
      " 2   Cost    3 non-null      int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 200.0+ bytes\n",
      "None\n",
      "Before Conversion:\n",
      "    Dates  Patients\n",
      "0  200712     50000\n",
      "1  200714     51000\n",
      "2  200716     51500\n",
      "3  200719     53000\n",
      "4  200721     54000\n",
      "5  200724     55000\n",
      "6  200729     57000\n",
      "Dates       object\n",
      "Patients     int64\n",
      "dtype: object\n",
      "\n",
      "After Conversion:\n",
      "       Dates  Patients\n",
      "0 2020-07-12     50000\n",
      "1 2020-07-14     51000\n",
      "2 2020-07-16     51500\n",
      "3 2020-07-19     53000\n",
      "4 2020-07-21     54000\n",
      "5 2020-07-24     55000\n",
      "6 2020-07-29     57000\n",
      "Dates       datetime64[ns]\n",
      "Patients             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# range_date\n",
    "rd = pd.date_range(start ='1/1/2019', end ='1/08/2019', freq ='Min')\n",
    "df = pd.DataFrame(rd, columns =['date'])\n",
    "df['data'] = np.random.randint(0, 100, size =(len(rd)))\n",
    "\n",
    "# string_data\n",
    "s = [str(x) for x in rd]\n",
    "#print(s[1:11])\n",
    "\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "filtered_df = df.loc['2019-01-05']  \n",
    "#print(filtered_df.iloc[1:11])\n",
    "\n",
    "# Creating the timestamp\n",
    "ts = pd.Timestamp('02-06-2018')\n",
    "\n",
    "# Print the timestamp\n",
    "print(ts)\n",
    "\n",
    "# Let's create a dataframe\n",
    "df = pd.DataFrame({'City':['Lisbon', 'Parague', 'Macao', 'Venice'],\n",
    "                    'Event':['Music', 'Poetry', 'Theatre', 'Comedy'],\n",
    "                    'Cost':[10000, 5000, 15000, 2000]})\n",
    "\n",
    "\n",
    "# Let's create an index using Timestamps\n",
    "index_ = [pd.Timestamp('01-06-2018'), pd.Timestamp('04-06-2018'),\n",
    "          pd.Timestamp('07-06-2018'), pd.Timestamp('10-06-2018')]\n",
    "\n",
    "# Let's set the index of the dataframe\n",
    "df.index = index_\n",
    "\n",
    "# Let's visualize the dataframe\n",
    "print(df)\n",
    "\n",
    "# convert column to datetime \n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Date': ['11/8/2011', '04/23/2008', '10/2/2019'],\n",
    "    'Event': ['Music', 'Poetry', 'Theatre'],\n",
    "    'Cost': [10000, 5000, 15000]\n",
    "})\n",
    "\n",
    "# Display initial data types\n",
    "print(\"Before Conversion:\")\n",
    "print(df.info())\n",
    "\n",
    "# Converting 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Display data types after conversion\n",
    "print(\"\\nAfter Conversion:\")\n",
    "print(df.info())\n",
    "\n",
    "# Initializing the dataset\n",
    "player_list = [\n",
    "    ['200712', 50000],\n",
    "    ['200714', 51000],\n",
    "    ['200716', 51500],\n",
    "    ['200719', 53000],\n",
    "    ['200721', 54000],\n",
    "    ['200724', 55000],\n",
    "    ['200729', 57000]\n",
    "]\n",
    "\n",
    "# Creating a pandas DataFrame\n",
    "df = pd.DataFrame(player_list, columns=['Dates', 'Patients'])\n",
    "\n",
    "# Displaying the DataFrame and its data types before conversion\n",
    "print(\"Before Conversion:\")\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Converting 'Dates' from 'yymmdd' to datetime format\n",
    "df['Dates'] = pd.to_datetime(df['Dates'], format='%y%m%d')\n",
    "\n",
    "# Displaying the DataFrame and its data types after conversion\n",
    "print(\"\\nAfter Conversion:\")\n",
    "print(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e105e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Conversion:\n",
      "  Treatment_start  No_of_Patients Treatment_end\n",
      "0        20200712           50000      20200812\n",
      "1        20200714           51000      20200814\n",
      "2        20200716           51500      20200816\n",
      "3        20200719           53000      20200819\n",
      "4        20200721           54000      20200821\n",
      "5        20200724           55000      20200824\n",
      "6        20200729           57000      20200824\n",
      "Treatment_start    object\n",
      "No_of_Patients      int64\n",
      "Treatment_end      object\n",
      "dtype: object\n",
      "\n",
      "After Conversion:\n",
      "  Treatment_start  No_of_Patients Treatment_end\n",
      "0      2020-07-12           50000    2020-08-12\n",
      "1      2020-07-14           51000    2020-08-14\n",
      "2      2020-07-16           51500    2020-08-16\n",
      "3      2020-07-19           53000    2020-08-19\n",
      "4      2020-07-21           54000    2020-08-21\n",
      "5      2020-07-24           55000    2020-08-24\n",
      "6      2020-07-29           57000    2020-08-24\n",
      "Treatment_start    datetime64[ns]\n",
      "No_of_Patients              int64\n",
      "Treatment_end      datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initializing the dataset\n",
    "player_list = [\n",
    "    ['20200712', 50000, '20200812'],\n",
    "    ['20200714', 51000, '20200814'],\n",
    "    ['20200716', 51500, '20200816'],\n",
    "    ['20200719', 53000, '20200819'],\n",
    "    ['20200721', 54000, '20200821'],\n",
    "    ['20200724', 55000, '20200824'],\n",
    "    ['20200729', 57000, '20200824']\n",
    "]\n",
    "\n",
    "# Creating a pandas DataFrame\n",
    "df = pd.DataFrame(player_list, columns=['Treatment_start', 'No_of_Patients', 'Treatment_end'])\n",
    "\n",
    "# Displaying the DataFrame and its data types before conversion\n",
    "print(\"Before Conversion:\")\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Converting 'Treatment_start' and 'Treatment_end' to datetime format\n",
    "df['Treatment_start'] = pd.to_datetime(df['Treatment_start'], format='%Y%m%d')\n",
    "df['Treatment_end'] = pd.to_datetime(df['Treatment_end'], format='%Y%m%d')\n",
    "\n",
    "# Displaying the DataFrame and its data types after conversion\n",
    "print(\"\\nAfter Conversion:\")\n",
    "print(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce27c4",
   "metadata": {},
   "source": [
    "# Boddak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0e0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Transformation terminée!\n",
      "✓ Fichier sauvegardé : datas_societe_info/fichier_transforme.csv\n",
      "✓ Nombre de lignes : 291\n",
      "✓ Nombre de colonnes : 33\n",
      "\n",
      "Aperçu des premières lignes :\n",
      "               dirigeant      Name          Surname\n",
      "0         Romain SAVOURÉ    Romain          SAVOURÉ\n",
      "1         Cédric FRENOIS    Cédric          FRENOIS\n",
      "2  Maher TAWFIK ROILETTE     Maher  TAWFIK ROILETTE\n",
      "3        Aurélien PERCOT  Aurélien           PERCOT\n",
      "4            Léa KASSABI       Léa          KASSABI\n",
      "5      Pierre SIERPINSKI    Pierre       SIERPINSKI\n",
      "6       Laëtitia AMIAULT  Laëtitia          AMIAULT\n",
      "7                KERNOUX                    KERNOUX\n",
      "8         Patrick GUÉRIN   Patrick           GUÉRIN\n",
      "9         PECLOZ HOLDING    PECLOZ          HOLDING\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extraire_nom_prenom(dirigeant):\n",
    "    \"\"\"\n",
    "    Extrait le nom et le prénom d'une chaîne de dirigeant.\n",
    "    Formats possibles: \"Prénom Nom\", \"NOM Prénom\", \"Prénom NOM\"\n",
    "    \"\"\"\n",
    "    if pd.isna(dirigeant) or dirigeant == '':\n",
    "        return '', ''\n",
    "    \n",
    "    # Nettoyer la chaîne\n",
    "    dirigeant = str(dirigeant).strip()\n",
    "    \n",
    "    # Séparer par espaces\n",
    "    parties = dirigeant.split()\n",
    "    \n",
    "    if len(parties) == 0:\n",
    "        return '', ''\n",
    "    elif len(parties) == 1:\n",
    "        # Si un seul mot, on le met dans Surname\n",
    "        return '', parties[0]\n",
    "    else:\n",
    "        # Si plusieurs mots, on considère:\n",
    "        # - le premier mot comme prénom (Name)\n",
    "        # - le reste comme nom de famille (Surname)\n",
    "        prenom = parties[0]\n",
    "        nom = ' '.join(parties[1:])\n",
    "        return prenom, nom\n",
    "\n",
    "# Charger le CSV\n",
    "input_file = '/Users/justinkim/Documents/GitHub/360capital/datas_societe_info/export-20251103-133731.csv'  # Remplacez par le nom de votre fichier\n",
    "societe_info = 'datas_societe_info/fichier_transforme.csv'\n",
    "\n",
    "# Lire le CSV\n",
    "df = pd.read_csv(input_file, encoding='utf-8', sep=';', low_memory=False)\n",
    "\n",
    "# Extraire nom et prénom\n",
    "df['Name'] = ''\n",
    "df['Surname'] = ''\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    prenom, nom = extraire_nom_prenom(row['dirigeant'])\n",
    "    df.at[idx, 'Name'] = prenom\n",
    "    df.at[idx, 'Surname'] = nom\n",
    "\n",
    "# Créer les colonnes vides\n",
    "df['Linkedin_scaped_url'] = ''\n",
    "df['Notes'] = ''\n",
    "df['ca_dernier'] = ''\n",
    "df['ca_dernier_annee'] = ''\n",
    "df['ca_dernier_estime'] = ''\n",
    "df['employes_dernier'] = ''\n",
    "df['employes_dernier_annee'] = ''\n",
    "df['employes_dernier_estime'] = ''\n",
    "df['tel'] = ''\n",
    "df['site_web'] = ''\n",
    "df['email'] = ''\n",
    "df['twitter'] = ''\n",
    "df['facebook'] = ''\n",
    "df['linkedin'] = ''\n",
    "\n",
    "# Définir l'ordre des colonnes selon votre demande\n",
    "colonnes_finales = [\n",
    "    'siren', 'siret', 'type_etablissement', 'denomination', 'dirigeant', 'Name', 'Surname', 'Linkedin_scaped_url', 'Notes',\n",
    "    'lien_fiche', 'dirigeant_role', 'dirigeant_role_date_debut', 'dirigeant_date_naissance',\n",
    "    'code_postal', 'ville', 'code_departement', 'longitude', 'lattitude',\n",
    "    'capital', 'categorie_insee', \n",
    "    'ca_dernier',\t'ca_dernier_annee',\t'ca_dernier_estime', 'employes_dernier', 'employes_dernier_annee', 'employes_dernier_estime', 'tel', 'site_web', 'email', 'twitter', 'facebook', 'linkedin' , \n",
    "    'tva_intra'\n",
    "]\n",
    "\n",
    "# Sélectionner uniquement les colonnes qui existent dans le dataframe\n",
    "colonnes_existantes = [col for col in colonnes_finales if col in df.columns]\n",
    "\n",
    "# Créer le nouveau dataframe avec les colonnes sélectionnées\n",
    "df_final = df[colonnes_existantes]\n",
    "\n",
    "# Sauvegarder le résultat\n",
    "df_final.to_csv(societe_info, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Transformation terminée!\")\n",
    "print(f\"✓ Fichier sauvegardé : {societe_info}\")\n",
    "print(f\"✓ Nombre de lignes : {len(df_final)}\")\n",
    "print(f\"✓ Nombre de colonnes : {len(df_final.columns)}\")\n",
    "print(f\"\\nAperçu des premières lignes :\")\n",
    "print(df_final[['dirigeant', 'Name', 'Surname']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406eefd",
   "metadata": {},
   "source": [
    "# Audrey extract excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae243e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import base64\n",
    "import openpyxl\n",
    "import xlwings as xw\n",
    "from PIL import Image, ImageGrab\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from mistralai import Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5afaea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTION + OCR MISTRAL (mistral-ocr-latest)\n",
      "============================================================\n",
      "\n",
      "[1/3] Capture Excel → Image (applescript)...\n",
      "Exécution du script AppleScript...\n",
      "Échec : image non créée\n",
      "Échec capture image\n"
     ]
    }
   ],
   "source": [
    "class ExcelToImageWithMistral:\n",
    "    def __init__(self, mistral_api_key, server_url=\"https://api.05d3a00300de.dc.mistral.ai\"):\n",
    "        self.mistral_api_key = mistral_api_key\n",
    "        self.server_url = server_url\n",
    "        self.client = Mistral(server_url=server_url, api_key=mistral_api_key)\n",
    "\n",
    "    def capture_excel_range_macos(self, excel_file, output_image='tableau_extrait.png', \n",
    "                                   cell_range='K17:V68', sheet_name=None):\n",
    "        excel_file = os.path.abspath(excel_file)\n",
    "        output_image = os.path.abspath(output_image)\n",
    "        \n",
    "        applescript = f'''\n",
    "        tell application \"Microsoft Excel\"\n",
    "            activate\n",
    "            open \"{excel_file}\"\n",
    "            \n",
    "            set theWorkbook to active workbook\n",
    "            set theSheet to active sheet of theWorkbook\n",
    "            \n",
    "            select range \"{cell_range}\" of theSheet\n",
    "            copy range \"{cell_range}\" of theSheet\n",
    "            delay 1\n",
    "            close theWorkbook saving no\n",
    "            quit\n",
    "        end tell\n",
    "        '''\n",
    "        \n",
    "        try:\n",
    "            print(\"Exécution du script AppleScript...\")\n",
    "            subprocess.run(['osascript', '-e', applescript], capture_output=True, text=True, timeout=30)\n",
    "            \n",
    "            capture_script = f'''\n",
    "            set theFile to POSIX file \"{output_image}\"\n",
    "            try\n",
    "                set imageData to (the clipboard as «class PNGf»)\n",
    "                set fileRef to open for access theFile with write permission\n",
    "                write imageData to fileRef\n",
    "                close access fileRef\n",
    "                return \"success\"\n",
    "            on error errMsg\n",
    "                return \"error: \" & errMsg\n",
    "            end try\n",
    "            '''\n",
    "            \n",
    "            result = subprocess.run(['osascript', '-e', capture_script], capture_output=True, text=True, timeout=10)\n",
    "            \n",
    "            if os.path.exists(output_image):\n",
    "                img = Image.open(output_image)\n",
    "                print(f\"Image capturée : {output_image} ({img.size[0]}x{img.size[1]})\")\n",
    "                return output_image\n",
    "            else:\n",
    "                print(\"Échec : image non créée\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur capture : {e}\")\n",
    "            return None\n",
    "\n",
    "    def capture_excel_range_screenshot(self, excel_file, output_image='tableau_extrait.png',\n",
    "                                       cell_range='K17:V68', sheet_name=None):\n",
    "        try:\n",
    "            app = xw.App(visible=False)\n",
    "            book = app.books.open(excel_file)\n",
    "            sheet = book.sheets[0] if not sheet_name else book.sheets[sheet_name]\n",
    "            rng = sheet.range(cell_range)\n",
    "            rng.copy_picture()\n",
    "            img = ImageGrab.grabclipboard()\n",
    "            if img:\n",
    "                img.save(output_image)\n",
    "                print(f\"Image capturée avec xlwings : {output_image}\")\n",
    "                book.close()\n",
    "                app.quit()\n",
    "                return output_image\n",
    "            book.close()\n",
    "            app.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"xlwings échoué : {e}\")\n",
    "        return None\n",
    "\n",
    "    # --- NOUVEAU : Encodage image ---\n",
    "    def encode_image(self, image_path):\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # --- NOUVEAU : Encodage PDF ---\n",
    "    def encode_pdf(self, pdf_path):\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "    # --- NOUVELLE MÉTHODE OCR MISTRAL ---\n",
    "    def analyze_with_mistral_ocr(self, image_path=None, pdf_path=None, include_image_base64=False):\n",
    "        \"\"\"\n",
    "        Utilise mistral-ocr-latest pour extraire le texte d'une image ou PDF\n",
    "        \"\"\"\n",
    "        print(\"\\nEnvoi à Mistral OCR (mistral-ocr-latest)...\")\n",
    "\n",
    "        try:\n",
    "            if pdf_path:\n",
    "                base64_doc = self.encode_pdf(pdf_path)\n",
    "                mime_type = \"application/pdf\"\n",
    "            elif image_path:\n",
    "                base64_doc = self.encode_image(image_path)\n",
    "                mime_type = \"image/png\"\n",
    "            else:\n",
    "                raise ValueError(\"image_path ou pdf_path requis\")\n",
    "\n",
    "            response = self.client.ocr.process(\n",
    "                model=\"mistral-ocr-latest\",\n",
    "                document={\n",
    "                    \"type\": \"document_url\",\n",
    "                    \"document_url\": f\"data:{mime_type};base64,{base64_doc}\"\n",
    "                },\n",
    "                include_image_base64=include_image_base64\n",
    "            )\n",
    "\n",
    "            extracted_text = response.text\n",
    "            print(\"Analyse OCR Mistral reçue\")\n",
    "            return extracted_text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur OCR Mistral : {e}\")\n",
    "            return None\n",
    "\n",
    "    def create_word_document(self, image_path=None, ocr_text=None, word_file='document_avec_tableau.docx'):\n",
    "        try:\n",
    "            from docx import Document\n",
    "            doc = Document()\n",
    "            doc.add_heading('Tableau extrait d\\'Excel', 0)\n",
    "\n",
    "            if image_path and os.path.exists(image_path):\n",
    "                doc.add_heading('Image du tableau', level=1)\n",
    "                doc.add_picture(image_path, width=Inches(6.5))\n",
    "\n",
    "            if ocr_text:\n",
    "                doc.add_page_break()\n",
    "                doc.add_heading('Texte extrait (OCR Mistral)', level=1)\n",
    "                p = doc.add_paragraph(ocr_text)\n",
    "                p.style.font.size = Pt(10)\n",
    "\n",
    "            doc.save(word_file)\n",
    "            print(f\"Document Word créé : {word_file}\")\n",
    "        except ImportError:\n",
    "            print(\"Installez python-docx : pip install python-docx\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur création Word : {e}\")\n",
    "\n",
    "    def process_excel_to_word(self, excel_file, output_image='tableau_extrait.png',\n",
    "                              cell_range='K17:V68', sheet_name=None,\n",
    "                              word_file='document_avec_ocr.docx',\n",
    "                              method='applescript', use_pdf=False, pdf_path=None):\n",
    "        print(\"=\" * 60)\n",
    "        print(\"EXTRACTION + OCR MISTRAL (mistral-ocr-latest)\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        image_path = None\n",
    "        ocr_text = None\n",
    "\n",
    "        # Étape 1 : Capture image\n",
    "        if not use_pdf:\n",
    "            print(f\"\\n[1/3] Capture Excel → Image ({method})...\")\n",
    "            if method == 'applescript':\n",
    "                image_path = self.capture_excel_range_macos(excel_file, output_image, cell_range, sheet_name)\n",
    "            else:\n",
    "                image_path = self.capture_excel_range_screenshot(excel_file, output_image, cell_range, sheet_name)\n",
    "\n",
    "            if not image_path:\n",
    "                print(\"Échec capture image\")\n",
    "                return None\n",
    "        else:\n",
    "            image_path = None\n",
    "            print(f\"\\n[1/3] Utilisation du PDF : {pdf_path}\")\n",
    "\n",
    "        # Étape 2 : OCR avec Mistral\n",
    "        print(\"\\n[2/3] Analyse OCR avec mistral-ocr-latest...\")\n",
    "        ocr_text = self.analyze_with_mistral_ocr(\n",
    "            image_path=image_path,\n",
    "            pdf_path=pdf_path if use_pdf else None\n",
    "        )\n",
    "\n",
    "        if ocr_text:\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"RÉSULTAT OCR MISTRAL :\")\n",
    "            print(\"=\" * 60)\n",
    "            print(ocr_text.strip())\n",
    "            print(\"=\" * 60)\n",
    "        else:\n",
    "            print(\"Échec OCR\")\n",
    "\n",
    "        # Étape 3 : Créer Word\n",
    "        print(f\"\\n[3/3] Création document Word...\")\n",
    "        self.create_word_document(\n",
    "            image_path=image_path,\n",
    "            ocr_text=ocr_text,\n",
    "            word_file=word_file\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image_path,\n",
    "            'pdf': pdf_path,\n",
    "            'ocr_text': ocr_text,\n",
    "            'word_doc': word_file\n",
    "        }\n",
    "\n",
    "\n",
    "# ========================\n",
    "# EXEMPLE D'UTILISATION\n",
    "# ========================\n",
    "if __name__ == \"__main__\":\n",
    "    # CONFIG\n",
    "    MISTRAL_API_KEY = \"X7DpYENEsRkosAnYZJbd6exXoUDhETWy\"  # Ta clé OCR\n",
    "    SERVER_URL = \"https://api.05d3a00300de.dc.mistral.ai\"\n",
    "\n",
    "    excel_file = \"audrey_extract/digitaly_one-pager_-_version_justin.xlsx\"\n",
    "    pdf_file = \"votre_tableau.pdf\"  # Optionnel\n",
    "\n",
    "    extractor = ExcelToImageWithMistral(MISTRAL_API_KEY, SERVER_URL)\n",
    "\n",
    "    # === OPTION 1 : Depuis Excel (image) ===\n",
    "    result = extractor.process_excel_to_word(\n",
    "        excel_file=excel_file,\n",
    "        output_image=\"tableau_extrait.png\",\n",
    "        cell_range=\"K17:V68\",\n",
    "        word_file=\"resultat_ocr.docx\",\n",
    "        method=\"applescript\",  # ou 'xlwings'\n",
    "        use_pdf=False\n",
    "    )\n",
    "\n",
    "    # === OPTION 2 : Depuis PDF ===\n",
    "    # result = extractor.process_excel_to_word(\n",
    "    #     excel_file=None,\n",
    "    #     word_file=\"resultat_pdf_ocr.docx\",\n",
    "    #     use_pdf=True,\n",
    "    #     pdf_path=pdf_file\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e1232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST OCR MISTRAL SUR CAPTURE EXCEL\n",
      "============================================================\n",
      "Capture de la plage Excel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281:301: execution error: Erreur dans Microsoft Excel : \"K17:V68\" ne comprend pas le message « copy range ». (-1708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Échec : image non générée\n",
      "ERREUR\n",
      "\n",
      "Arrêt : impossible de capturer l'image\n",
      "\n",
      "Envoi à Mistral OCR (mistral-ocr-latest)...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m     exit()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Étape 2 : OCR\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m ocr_text \u001b[38;5;241m=\u001b[39m \u001b[43mocr_with_mistral\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ocr_text:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m, in \u001b[0;36mocr_with_mistral\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m client \u001b[38;5;241m=\u001b[39m Mistral(server_url\u001b[38;5;241m=\u001b[39mSERVER_URL, api_key\u001b[38;5;241m=\u001b[39mMISTRAL_API_KEY)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnvoi à Mistral OCR (mistral-ocr-latest)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m base64_image \u001b[38;5;241m=\u001b[39m \u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mocr\u001b[38;5;241m.\u001b[39mprocess(\n\u001b[1;32m     77\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral-ocr-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m         document\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m         include_image_base64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# On veut juste le texte\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[1], line 66\u001b[0m, in \u001b[0;36mencode_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode_image\u001b[39m(image_path):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m base64\u001b[38;5;241m.\u001b[39mb64encode(f\u001b[38;5;241m.\u001b[39mread())\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/360capital/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# test_ocr_mistral_excel.py\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import base64\n",
    "from PIL import Image\n",
    "from mistralai import Mistral\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "MISTRAL_API_KEY = \"X7DpYENEsRkosAnYZJbd6exXoUDhETWy\"  # Ta clé OCR\n",
    "SERVER_URL = \"https://api.05d3a00300de.dc.mistral.ai\"\n",
    "\n",
    "EXCEL_FILE = \"/Users/justinkim/Documents/GitHub/360capital/audrey_extract/digitaly_one-pager_-_version_justin.xlsx\"        # Remplace par ton fichier\n",
    "CELL_RANGE = \"K17:V68\"                   # Plage à capturer\n",
    "OUTPUT_IMAGE = \"capture_tableau.png\"     # Image temporaire\n",
    "# ================================================\n",
    "\n",
    "def capture_excel_to_image(excel_file, cell_range, output_image):\n",
    "    \"\"\"Capture une plage Excel via AppleScript (macOS)\"\"\"\n",
    "    excel_file = os.path.abspath(excel_file)\n",
    "    output_image = os.path.abspath(output_image)\n",
    "\n",
    "    applescript = f'''\n",
    "    tell application \"Microsoft Excel\"\n",
    "        activate\n",
    "        open \"{excel_file}\"\n",
    "        delay 2\n",
    "        tell active sheet of active workbook\n",
    "            select range \"{cell_range}\"\n",
    "            copy range \"{cell_range}\"\n",
    "        end tell\n",
    "        delay 1\n",
    "        close active workbook saving no\n",
    "    end tell\n",
    "    quit application \"Microsoft Excel\"\n",
    "    '''\n",
    "\n",
    "    print(\"Capture de la plage Excel...\")\n",
    "    subprocess.run(['osascript', '-e', applescript], timeout=30)\n",
    "\n",
    "    # Sauvegarde du presse-papier comme image\n",
    "    save_script = f'''\n",
    "    set theFile to POSIX file \"{output_image}\"\n",
    "    try\n",
    "        set imageData to (the clipboard as «class PNGf»)\n",
    "        set fileRef to open for access theFile with write permission\n",
    "        write imageData to fileRef\n",
    "        close access fileRef\n",
    "        return \"OK\"\n",
    "    on error\n",
    "        return \"ERREUR\"\n",
    "    end try\n",
    "    '''\n",
    "\n",
    "    result = subprocess.run(['osascript', '-e', save_script], capture_output=True, text=True)\n",
    "    if os.path.exists(output_image):\n",
    "        img = Image.open(output_image)\n",
    "        print(f\"Image capturée : {output_image} ({img.width}x{img.height})\")\n",
    "        return output_image\n",
    "    else:\n",
    "        print(\"Échec : image non générée\")\n",
    "        print(result.stdout)\n",
    "        return None\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode('utf-8')\n",
    "\n",
    "def ocr_with_mistral(image_path):\n",
    "    client = Mistral(server_url=SERVER_URL, api_key=MISTRAL_API_KEY)\n",
    "    \n",
    "    print(\"\\nEnvoi à Mistral OCR (mistral-ocr-latest)...\")\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    try:\n",
    "        response = client.ocr.process(\n",
    "            model=\"mistral-ocr-latest\",\n",
    "            document={\n",
    "                \"type\": \"document_url\",\n",
    "                \"document_url\": f\"data:image/png;base64,{base64_image}\"\n",
    "            },\n",
    "            include_image_base64=False  # On veut juste le texte\n",
    "        )\n",
    "        print(\"OCR terminé !\\n\")\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur OCR : {e}\")\n",
    "        return None\n",
    "\n",
    "# ====================== TEST ======================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TEST OCR MISTRAL SUR CAPTURE EXCEL\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Étape 1 : Capture\n",
    "    image_path = capture_excel_to_image(EXCEL_FILE, CELL_RANGE, OUTPUT_IMAGE)\n",
    "    if not image_path:\n",
    "        print(\"Arrêt : impossible de capturer l'image\")\n",
    "        exit()\n",
    "\n",
    "    # Étape 2 : OCR\n",
    "    ocr_text = ocr_with_mistral(image_path)\n",
    "\n",
    "    if ocr_text:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"RÉSULTAT OCR (Mistral) :\")\n",
    "        print(\"=\" * 60)\n",
    "        print(ocr_text)\n",
    "        print(\"=\" * 60)\n",
    "    else:\n",
    "        print(\"Échec de l'OCR\")\n",
    "\n",
    "    # Nettoyage optionnel\n",
    "    # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8fe06",
   "metadata": {},
   "source": [
    "# LSN pré filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1a765722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/x11w534x6fx5843q4r1vdmtc0000gp/T/ipykernel_51836/3923341234.py:80: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'X' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_copy.at[idx, 'Status'] = 'X'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traité 11/110 lignes\n",
      "Traité 21/110 lignes\n",
      "Traité 31/110 lignes\n",
      "Traité 41/110 lignes\n",
      "Traité 71/110 lignes\n",
      "Traité 91/110 lignes\n",
      "Traité 101/110 lignes\n",
      "Classification terminée!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mistralai import Mistral\n",
    "\n",
    "df = pd.read_csv(\"/Users/justinkim/Documents/GitHub/360capital/datas/extract_LSN - Feuille 1 (16).csv\")\n",
    "\n",
    "\n",
    "def classify_company_status(df, client, model):\n",
    "    \"\"\"\n",
    "    Classifie les entreprises et met 'X' dans la colonne Status si elles ne correspondent \n",
    "    pas aux critères (France/Italie, ou Europe + climate tech, pas de consulting).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame contenant les données\n",
    "        client: Client Mistral initialisé\n",
    "        model: Nom du modèle Mistral à utiliser\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec la colonne Status mise à jour\n",
    "    \"\"\"\n",
    "    \n",
    "    def should_exclude(row):\n",
    "        \"\"\"\n",
    "        Détermine si une entreprise doit être exclue (Status = X)\n",
    "        \"\"\"\n",
    "        if pd.isna(row.get('Description')) or str(row.get('Description')).strip() == '':\n",
    "            return None\n",
    "        \n",
    "        description = str(row['Description'])\n",
    "        prompt = f\"\"\"\n",
    "\n",
    "Analyze the company’s description below and determine whether to ‘EXCLURE’ or ‘GARDER’ based on the following criteria:\n",
    "\n",
    "‘GARDER’ if:\n",
    "\n",
    "The company is based in France or Italy.\n",
    "The company operates in Europe and focuses on climate tech (renewable energy, decarbonization, etc.).\n",
    "The company uses AI to address problems, or technology such as deeptech.\n",
    "‘EXCLURE’ if:\n",
    "\n",
    "The company is involved in consulting.\n",
    "The company is non-profit or an association.\n",
    "Respond only with ‘EXCLURE’ or ‘GARDER’.\n",
    "If uncertain, choose ‘GARDER’.\n",
    "\n",
    "Description: {description}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            chat_response = client.chat.complete(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            response = chat_response.choices[0].message.content.strip().upper()\n",
    "            \n",
    "\n",
    "            if \"EXCLURE\" in response:\n",
    "                return 'X'\n",
    "            else:\n",
    "                return None  \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la classification: {e}\")\n",
    "            return None\n",
    "    \n",
    "\n",
    "    print(\"Classification en cours...\")\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    for idx, row in df_copy.iterrows():\n",
    "        result = should_exclude(row)\n",
    "        if result == 'X':\n",
    "            df_copy.at[idx, 'Status'] = 'X'\n",
    "            if idx % 10 == 0: \n",
    "                print(f\"Traité {idx + 1}/{len(df_copy)} lignes\")\n",
    "    \n",
    "    print(\"Classification terminée!\")\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "# Config\n",
    "api_key = \"tLYewB74Gq1R7krnmU2fYaRVoHCx8wfl\"\n",
    "model = \"mistral-small-latest\"\n",
    "\n",
    "client = Mistral(\n",
    "    server_url=\"https://api.05d3a00300de.dc.mistral.ai\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "df_classified = classify_company_status(df, client, model)\n",
    "df_classified.to_csv('companies_classified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62add52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['CompanyName', 'Status']\n",
    "len(df_classified[col].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04050feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fizz'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8520b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
